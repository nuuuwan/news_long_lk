{
  "url": "https://www.technologyreview.com/2025/08/05/1121052/a-glimpse-into-openais-largest-ambitions/",
  "title": "A glimpse into OpenAI\u2019s largest ambitions",
  "ut": 1754350200.0,
  "body_paragraphs": [
    "OpenAI has given itself a dual mandate. On the one hand, it\u2019s a tech giant rooted in products, including of course ChatGPT, which people around the world reportedly send 2.5 billion requests to each day. But its original mission is to serve as a research lab that will not only create \u201cartificial general intelligence\u201d but ensure that it benefits all of humanity.\u00a0 My colleague Will Douglas Heaven recently sat down for an exclusive conversation with the two figures at OpenAI most responsible for pursuing the latter ambitions: chief research officer Mark Chen and chief scientist Jakub Pachocki. If you haven\u2019t already, you must read his piece.  It provides a rare glimpse into how the company thinks beyond marginal improvements to chatbots and contemplates the biggest unknowns in AI: whether it could someday reason like a human, whether it should, and how tech companies conceptualize the societal implications.\u00a0 The whole story is worth reading for all it reveals\u2014about how OpenAI thinks about the safety of its products, what AGI actually means, and more\u2014but here\u2019s one thing that stood out to me.",
    "Related StoryInside OpenAI\u2019s empire: A conversation with Karen Hao",
    "In a Roundtables event for\u00a0MIT Technology Review\u00a0subscribers, the author of\u00a0Empire of AI\u00a0explains how everyone has a stake in AI\u2019s development.",
    "As Will points out, there were two recent wins for OpenAI in its efforts to build AI that outcompetes humans. Its models took second place at a top-level coding competition and\u2014alongside those from Google DeepMind\u2014achieved gold-medal-level results in the 2025 International Math Olympiad. People who believe that AI doesn\u2019t pose genuine competition to human-level intelligence might actually take some comfort in that. AI is good at the mathematical and analytical, which are on full display in olympiads and coding competitions. That doesn\u2019t mean it\u2019s any good at grappling with the messiness of human emotions, making hard decisions, or creating art that resonates with anyone.",
    "But that distinction\u2014between machine-like reasoning and the ability to think creatively\u2014is not one OpenAI\u2019s heads of research are inclined to make.\u00a0 \u201cWe\u2019re talking about programming and math here,\u201d said Pachocki. \u201cBut it\u2019s really about creativity, coming up with novel ideas, connecting ideas from different places.\u201d That\u2019s why, the researchers say, these testing grounds for AI will produce models that have an increasing ability to reason like a person, one of the most important goals OpenAI is working toward. Reasoning models break problems down into more discrete steps, but even the best have limited ability to chain pieces of information together and approach problems logically.\u00a0 OpenAI is throwing a massive amount of money and talent at that problem not because its researchers think it will result in higher scores at math contests, but because they believe it will allow their AI models to come closer to human intelligence.\u00a0 As Will recalls in the piece, he said he thought maybe it\u2019s fine for AI to excel at math and coding, but the idea of having an AI acquire people skills and replace politicians is perhaps not. Chen pulled a face and looked up at the ceiling: \u201cWhy not?\u201d Read the full story from Will Douglas Heaven. This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. hide"
  ]
}