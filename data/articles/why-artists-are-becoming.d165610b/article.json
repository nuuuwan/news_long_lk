{
  "url": "https://www.technologyreview.com/2024/06/18/1093998/why-artists-becoming-less-scared-of-ai/",
  "title": "Why artists are becoming less scared of AI",
  "ut": 1718672335.0,
  "body_paragraphs": [
    "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. Knock, knock.\u00a0  Who\u2019s there?\u00a0 An AI with generic jokes. Researchers from Google DeepMind asked 20 professional comedians to use popular AI language models to write jokes and comedy performances. Their results were mixed.",
    "The comedians said that the tools were useful in helping them produce an initial \u201cvomit draft\u201d that they could iterate on, and helped them structure their routines. But the AI was not able to produce anything that was original, stimulating, or, crucially, funny. My colleague Rhiannon Williams\u00a0has the full story. As Tuhin Chakrabarty, a computer science researcher at Columbia University who specializes in AI and creativity, told Rhiannon, humor often relies on being surprising and incongruous. Creative writing requires its creator to deviate from the norm, whereas LLMs can only mimic it.",
    "And that is becoming pretty clear in the way artists are approaching AI today. I\u2019ve just come back from Hamburg, which hosted one of the\u00a0largest events for creatives in Europe, and the message I got from those I spoke to was that AI is too glitchy and unreliable to fully replace humans and is best used instead as a tool to augment human creativity.\u00a0 Right now, we are in a moment where we are deciding how much creative power we are comfortable giving AI companies and tools. After the boom first started in 2022, when DALL-E 2 and Stable Diffusion first entered the scene, many artists raised concerns that AI companies were scraping their copyrighted work without consent or compensation. Tech companies argue that anything on the public internet falls under fair use, a legal doctrine that allows the reuse of copyrighted-protected material in certain circumstances. Artists, writers, image companies, and the\u00a0New York Times have filed lawsuits against these companies, and it will likely take years until we have a clear-cut answer as to who is right.\u00a0 Meanwhile, the court of public opinion has shifted a lot in the past two years. Artists I have interviewed recently say they were harassed and ridiculed for protesting AI companies\u2019 data-scraping practices two years ago. Now, the general public is more aware of the harms associated with AI. In just two years, the public has gone from being blown away by AI-generated images to sharing viral social media posts about how to opt out of AI scraping\u2014a concept that was alien to most laypeople until very recently. Companies have benefited from this shift too. Adobe has been successful in pitching its\u00a0AI offerings\u00a0as an \u201cethical\u201d way to use the technology without having to worry about copyright infringement.\u00a0 There are also several grassroots efforts to shift the power structures of AI and give artists more agency over their data. I\u2019ve written about\u00a0Nightshade, a tool created by researchers at the University of Chicago, which lets users add an invisible poison attack to their images so that they break AI models when scraped. The same team is behind Glaze, a tool that lets artists mask their personal style from AI copycats. Glaze has been integrated into Cara, a buzzy new art portfolio site and social media platform, which has seen a surge of interest from artists. Cara pitches itself as a platform for art created by people; it filters out AI-generated content. It got nearly a million new users in a few days.\u00a0 This all should be reassuring news for any creative people worried that they could lose their job to a computer program. And the DeepMind study is a great example of how AI can actually be\u00a0helpful for creatives. It can take on some of the boring, mundane, formulaic aspects of the creative process, but it can\u2019t replace the magic and originality that humans bring. AI models are limited to their training data and will forever only reflect the zeitgeist at the moment of their training. That gets old pretty quickly.  Now read the rest of The Algorithm Deeper Learning Apple is promising personalized AI in a private cloud. Here\u2019s how that will work. Last week, Apple unveiled its vision for supercharging its product lineup with artificial intelligence. The key feature, which will run across virtually all of its product line, is Apple Intelligence, a suite of AI-based capabilities that promises to deliver personalized AI services while keeping sensitive data secure.\u00a0 Why this matters:\u00a0Apple says its privacy-focused system will first attempt to fulfill AI tasks locally on the device itself. If any data is exchanged with cloud services, it will be encrypted and then deleted afterward. It\u2019s a pitch that offers an implicit contrast with the likes of Alphabet, Amazon, or Meta, which collect and store enormous amounts of personal data.\u00a0Read more from James O\u2019Donnell here.",
    "Bits and Bytes How to opt out of Meta\u2019s AI trainingIf you post or interact with chatbots on Facebook, Instagram, Threads, or WhatsApp, Meta can use your data to train its generative AI models. Even if you don\u2019t use any of Meta\u2019s platforms, it can still scrape data such as photos of you if someone else posts them. Here\u2019s our quick guide on how to opt out. (MIT Technology Review)\u00a0 Microsoft\u2019s Satya Nadella is building an AI empireNadella is going all in on AI. His $13 billion investment in OpenAI was just the beginning. Microsoft has become an \u201cthe world\u2019s most aggressive amasser of AI talent, tools, and technology\u201d and has started building an in-house OpenAI competitor. (The Wall Street Journal) OpenAI has hired an army of lobbyistsAs countries around the world mull AI legislation, OpenAI is on a lobbyist hiring spree to protect its interests. The AI company has expanded its global affairs team from three lobbyists at the start of 2023 to 35 and intends to have up to 50 by the end of this year. (Financial Times)\u00a0\u00a0 UK rolls out Amazon-powered emotion recognition AI cameras on trainsPeople traveling through some of the UK\u2019s biggest train stations have likely had their faces scanned by Amazon software without their knowledge during an AI trial. London stations such as Euston and Waterloo have tested CCTV cameras with AI to reduce crime and detect people\u2019s emotions. Emotion recognition technology is extremely controversial. Experts say it is unreliable and simply does not work.\u00a0(Wired)\u00a0 Clearview AI used your face. Now you may get a stake in the company.The facial recognition company, which has been under fire for scraping images of people\u2019s faces from the web and social media without their permission, has agreed to an unusual settlement in a class action against it. Instead of paying cash, it is offering a 23% stake in the company for Americans whose faces are in its data sets. (The New York Times)\u00a0 Elephants call each other by their namesThis is so cool! Researchers used AI to analyze the calls of two herds of African savanna elephants in Kenya. They found that elephants use specific vocalizations for each individual and recognize when they are being addressed by other elephants. (The Guardian)\u00a0 hide"
  ]
}