# Why artists are becoming less scared of AI

## Summary ü§ñ

Facts:
- Researchers from Google DeepMind asked 20 professional comedians to utilize popular AI language models for writing jokes.
- The AI models were found to be useful for producing initial drafts and structuring routines, but were unable to generate original or funny content.
- A computer science researcher at Columbia University noted that creative writing often requires deviation from norms which AI models can't accomplish.
- Artists and other creatives are seeing AI as a tool to augment human creativity rather than replace it.
- There have been lawsuits filed against AI companies for using copyrighted work without permission or compensation.
- Companies like Adobe are marketing their AI offerings as an ethical alternative that doesn't infringe on copyrights.
- The University of Chicago researchers have created tools like Nightshade and Glaze to counter AI data scraping and copying.
- A new art portfolio platform, Cara, has gained popularity by excluding AI-generated content and protecting artists' styles.
- Apple has launched a suite of AI-based capabilities, called Apple Intelligence, that promises to deliver personalized (and secure) AI services.
- Meta uses data from users of its platforms to train its generative AI models.
- Microsoft is focusing heavily on AI, described as the world's most aggressive gatherer of AI talent, technologies, and tools.
- OpenAI has hired many lobbyists as AI legislation is being considered globally.
- The UK has tested AI-powered CCTV cameras in some of the largest train stations.
- Clearview AI agreed to an unusual settlement in a class-action lawsuit, offering a 23% stake in the company to Americans whose faces are in its databases.

Opinions:
- The tools developed by University of Chicago researchers, designed to protect artist's data from being stolen by AI, are seen as grassroots efforts to shift power structures in the AI field.
- Currently, society is deciding how much creative power should be given to AI tools.
- Over two years, public opinion has shifted towards greater caution against potential harms of AI, as evidenced by social media posts about opting out of AI scraping.
- The DeepMind study provides a good example of how AI can assist creatives but can't replace human originality.
- AI models will always be limited to their training data, and quickly become outdated.
- Apple's use of AI to offer personalized services, while ensuring data security, is seen as a contrast to other tech giants.
- Emotion recognition technology, used in the UK's train station AI trials, is criticized as unreliable and ineffective.

## Follow-up Questions ü§ñ

1. How can AI tools aid in the creation of comedy? 
2. Why do some professional comedians find AI tools useful in joke creation, but not in delivering original content?
3. What are the most common criticisms artists have regarding AI?
4. What legal actions have artists, writers, and image companies taken against tech companies for their use of AI?
5. How has the public opinion on AI shifted in recent years?
6. Can you elaborate on the ways companies like Adobe are using AI responsibly or ethically?
7. What tools exist to give artists more control over their data in relation to AI?
8. How can AI and humans work together in the creative process?
9. Could you explain more about Apple's plan for personalized AI in a private cloud?
10. What strategies does Meta use to train its AI models, and how can users opt out?
11. How is Microsoft positioning itself in the AI landscape?
12. Why are there concerns about the use of emotion recognition AI cameras on trains in the UK?
13. How might the class action settlement against Clearview AI impact privacy and data rights for users in the future?
14. Could you elaborate on the research about elephants using specific vocalizations to address each other?

## Full Text

[https://www.technologyreview.com/2024/06/18/1093998/why-artists-becoming-less-scared-of-ai/](https://www.technologyreview.com/2024/06/18/1093998/why-artists-becoming-less-scared-of-ai/)

*06:28 AM, Tuesday, June 18, 2024*

This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. Knock, knock.¬†  Who‚Äôs there?¬† An AI with generic jokes. Researchers from Google DeepMind asked 20 professional comedians to use popular AI language models to write jokes and comedy performances. Their results were mixed.

The comedians said that the tools were useful in helping them produce an initial ‚Äúvomit draft‚Äù that they could iterate on, and helped them structure their routines. But the AI was not able to produce anything that was original, stimulating, or, crucially, funny. My colleague Rhiannon Williams¬†has the full story. As Tuhin Chakrabarty, a computer science researcher at Columbia University who specializes in AI and creativity, told Rhiannon, humor often relies on being surprising and incongruous. Creative writing requires its creator to deviate from the norm, whereas LLMs can only mimic it.

And that is becoming pretty clear in the way artists are approaching AI today. I‚Äôve just come back from Hamburg, which hosted one of the¬†largest events for creatives in Europe, and the message I got from those I spoke to was that AI is too glitchy and unreliable to fully replace humans and is best used instead as a tool to augment human creativity.¬† Right now, we are in a moment where we are deciding how much creative power we are comfortable giving AI companies and tools. After the boom first started in 2022, when DALL-E 2 and Stable Diffusion first entered the scene, many artists raised concerns that AI companies were scraping their copyrighted work without consent or compensation. Tech companies argue that anything on the public internet falls under fair use, a legal doctrine that allows the reuse of copyrighted-protected material in certain circumstances. Artists, writers, image companies, and the¬†New York Times have filed lawsuits against these companies, and it will likely take years until we have a clear-cut answer as to who is right.¬† Meanwhile, the court of public opinion has shifted a lot in the past two years. Artists I have interviewed recently say they were harassed and ridiculed for protesting AI companies‚Äô data-scraping practices two years ago. Now, the general public is more aware of the harms associated with AI. In just two years, the public has gone from being blown away by AI-generated images to sharing viral social media posts about how to opt out of AI scraping‚Äîa concept that was alien to most laypeople until very recently. Companies have benefited from this shift too. Adobe has been successful in pitching its¬†AI offerings¬†as an ‚Äúethical‚Äù way to use the technology without having to worry about copyright infringement.¬† There are also several grassroots efforts to shift the power structures of AI and give artists more agency over their data. I‚Äôve written about¬†Nightshade, a tool created by researchers at the University of Chicago, which lets users add an invisible poison attack to their images so that they break AI models when scraped. The same team is behind Glaze, a tool that lets artists mask their personal style from AI copycats. Glaze has been integrated into Cara, a buzzy new art portfolio site and social media platform, which has seen a surge of interest from artists. Cara pitches itself as a platform for art created by people; it filters out AI-generated content. It got nearly a million new users in a few days.¬† This all should be reassuring news for any creative people worried that they could lose their job to a computer program. And the DeepMind study is a great example of how AI can actually be¬†helpful for creatives. It can take on some of the boring, mundane, formulaic aspects of the creative process, but it can‚Äôt replace the magic and originality that humans bring. AI models are limited to their training data and will forever only reflect the zeitgeist at the moment of their training. That gets old pretty quickly.  Now read the rest of The Algorithm Deeper Learning Apple is promising personalized AI in a private cloud. Here‚Äôs how that will work. Last week, Apple unveiled its vision for supercharging its product lineup with artificial intelligence. The key feature, which will run across virtually all of its product line, is Apple Intelligence, a suite of AI-based capabilities that promises to deliver personalized AI services while keeping sensitive data secure.¬† Why this matters:¬†Apple says its privacy-focused system will first attempt to fulfill AI tasks locally on the device itself. If any data is exchanged with cloud services, it will be encrypted and then deleted afterward. It‚Äôs a pitch that offers an implicit contrast with the likes of Alphabet, Amazon, or Meta, which collect and store enormous amounts of personal data.¬†Read more from James O‚ÄôDonnell here.

Bits and Bytes How to opt out of Meta‚Äôs AI trainingIf you post or interact with chatbots on Facebook, Instagram, Threads, or WhatsApp, Meta can use your data to train its generative AI models. Even if you don‚Äôt use any of Meta‚Äôs platforms, it can still scrape data such as photos of you if someone else posts them. Here‚Äôs our quick guide on how to opt out. (MIT Technology Review)¬† Microsoft‚Äôs Satya Nadella is building an AI empireNadella is going all in on AI. His $13 billion investment in OpenAI was just the beginning. Microsoft has become an ‚Äúthe world‚Äôs most aggressive amasser of AI talent, tools, and technology‚Äù and has started building an in-house OpenAI competitor. (The Wall Street Journal) OpenAI has hired an army of lobbyistsAs countries around the world mull AI legislation, OpenAI is on a lobbyist hiring spree to protect its interests. The AI company has expanded its global affairs team from three lobbyists at the start of 2023 to 35 and intends to have up to 50 by the end of this year. (Financial Times)¬†¬† UK rolls out Amazon-powered emotion recognition AI cameras on trainsPeople traveling through some of the UK‚Äôs biggest train stations have likely had their faces scanned by Amazon software without their knowledge during an AI trial. London stations such as Euston and Waterloo have tested CCTV cameras with AI to reduce crime and detect people‚Äôs emotions. Emotion recognition technology is extremely controversial. Experts say it is unreliable and simply does not work.¬†(Wired)¬† Clearview AI used your face. Now you may get a stake in the company.The facial recognition company, which has been under fire for scraping images of people‚Äôs faces from the web and social media without their permission, has agreed to an unusual settlement in a class action against it. Instead of paying cash, it is offering a 23% stake in the company for Americans whose faces are in its data sets. (The New York Times)¬† Elephants call each other by their namesThis is so cool! Researchers used AI to analyze the calls of two herds of African savanna elephants in Kenya. They found that elephants use specific vocalizations for each individual and recognize when they are being addressed by other elephants. (The Guardian)¬† hide

