{
  "url": "https://www.technologyreview.com/2024/10/04/1104972/law-california-protects-brain-data-doesnt-go-far-enough/",
  "title": "A new law in California protects consumers\u2019 brain data. Some think it doesn\u2019t go far enough.",
  "ut": 1727998200.0,
  "body_paragraphs": [
    "This article first appeared in The Checkup,\u00a0MIT Technology Review\u2019s\u00a0weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,\u00a0sign up here. On September 28, California became the second US state to officially recognize the importance of mental privacy in state law. That pink, jelly-like, throbbing mass under your skull\u2014a.k.a. your brain\u2014contains all your thoughts, memories, and ideas. It controls your feelings and actions. Measuring brain activity can reveal a lot about a person\u2014and that\u2019s why neural data needs to be protected.  Regular Checkup readers will be familiar with some of the burgeoning uses of \u201cmind-reading\u201d technologies. We can track brain activity with all sorts of devices, some of which measure brain waves while others track electrical activity or blood flow. Scientists have been able to translate this data into signals to help paralyzed people move their limbs or even communicate by thought alone. Related StoryA brain implant changed her life. Then it was removed against her will.Her case highlights why we need to enshrine neuro rights in law.",
    "But this data also has uses beyond health care. Today, consumers can buy headsets that allow them to learn more about how their brains work and help them feel calm. Employers use devices to monitor how alert their employees are, and schools use them to check if students are paying attention.",
    "Brain data is precious. It\u2019s not the same as thought, but it can be used to work out how we\u2019re thinking and feeling, and reveal our innermost preferences and desires. So let\u2019s look at how California\u2019s law might protect mental privacy\u2014and how far we still have to go. The new bill amends the California Consumer Privacy Act of 2018, which grants consumers rights over personal information that is collected by businesses. The term \u201cpersonal information\u201d already included biometric data (such as your face, voice, or fingerprints). Now it also explicitly includes neural data.",
    "The bill defines neural data as \u201cinformation that is generated by measuring the activity of a consumer\u2019s central or peripheral nervous system, and that is not inferred from nonneural information.\u201d In other words, data collected from a person\u2019s brain or nerves. The law prevents companies from selling or sharing a person\u2019s data and requires them to make efforts to deidentify the data. It also gives consumers the right to know what information is collected and the right to delete it. \u201cThis new law in California will make the lives of consumers safer while sending a clear signal to the fast-growing neurotechnology industry there are high expectations that companies will provide robust protections for mental privacy of consumers,\u201d Jared Genser, general counsel to the Neurorights Foundation, which cosponsored the bill, said in a statement. \u201cThat said, there is much more work ahead.\u201d Genser hopes the California law will pave the way for national and international legislation that protects the mental privacy of individuals all over the world. California is a good place to start\u2014the state is home to plenty of neurotechnology companies, so there\u2019s a good chance we\u2019ll see the effects of the bill ripple out from there. Related StoryTech that aims to read your mind and probe your memories is already hereWe need new rules to protect our cognitive liberty, says futurist and legal ethicist Nita Farahany.",
    "But some proponents of mental privacy aren\u2019t satisfied that the law does enough to protect neural data. \u201cWhile it introduces important safeguards, significant ambiguities leave room for loopholes that could undermine privacy protections, especially regarding inferences from neural data,\u201d Marcello Ienca, an ethicist at the Technical University of Munich, posted on X. One such ambiguity concerns the meaning of \u201cnonneural information,\u201d according to Nita Farahany, a futurist and legal ethicist at Duke University in Durham, North Carolina. \u201cThe bill\u2019s language suggests that raw data [collected from a person\u2019s brain] may be protected, but inferences or conclusions\u2014where privacy risks are most profound\u2014might not be,\u201d Farahany wrote in a post on LinkedIn. Ienca and Farahany are coauthors of a recent paper on mental privacy. In it, they and Patrick Magee, also at Duke University, argue for broadening the definition of neural data to what they call \u201ccognitive biometrics.\u201d This category could include physiological and behavioral information along with brain data\u2014in other words, pretty much anything that could be picked up by biosensors and used to infer a person\u2019s mental state. After all, it\u2019s not just your brain activity that gives away how you\u2019re feeling. An uptick in heart rate might indicate excitement or stress, for example. Eye-tracking devices might help give away your intentions, such as a choice you\u2019re likely to make or a product you might opt to buy. These kinds of data are already being used to reveal information that might otherwise be extremely private. Recent research has used EEG data to predict volunteers\u2019 sexual orientation or whether they use recreational drugs. And others have used eye-tracking devices to infer personality traits.",
    "Given all that, it\u2019s vital we get it right when it comes to protecting mental privacy. As Farahany, Ienca, and Magee put it: \u201cBy choosing whether, when, and how to share their cognitive biometric data, individuals can contribute to advancements in technology and medicine while maintaining control over their personal information.\u201d  Now read the rest of The Checkup Read more from MIT Technology Review's archive Nita Farahany detailed her thoughts on tech that aims to read our minds and probe our memories in a fascinating Q&A last year. Targeted dream incubation, anyone?\u00a0 There are lots of ways that your brain data could be used against you (or potentially exonerate you). Law enforcement officials have already started asking neurotech companies for data from people\u2019s brain implants. In one case, a person had been accused of assaulting a police officer but, as brain data proved, was just having a seizure at the time. EEG, the technology that allows us to measure brain waves, has been around for 100 years. Neuroscientists are wondering how it might be used to read thoughts, memories, and dreams within the next 100 years. Electrodes implanted in or on the brain can provide us with the most detailed insights into how our minds work. They can also provide us with amazing imagery, like this video that essentially shows what a thought looks like as it is being formed. What exactly is going on in our brains, anyway? When neuroscientists used electrodes implanted deep in the brains of people being treated for epilepsy, they found order and chaos.\u00a0 From around the web Infections are responsible for 13% of cancers. Here\u2019s how to protect against four of them. (New York Times) Scientists have created the first map of the neurons in a fruit fly\u2019s brain. All 139,225 of them. (Nature)",
    "Oropouche fever is surging in South America. Disturbingly, there are increasing reports of the virus harming pregnant women and their babies. (Viruses) Women in heterosexual relationships already do more housework and household organization than their partners. Is technology making things worse? (BBC Future) Do you sigh during your sleep? It could be a sign of something serious. (Nature) hide"
  ]
}