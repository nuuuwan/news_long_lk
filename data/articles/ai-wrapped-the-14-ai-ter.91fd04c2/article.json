{
  "url": "https://www.technologyreview.com/2025/12/25/1130298/ai-wrapped-the-14-ai-terms-you-couldnt-avoid-in-2025/",
  "title": "AI Wrapped: The 14 AI terms you couldn\u2019t avoid in 2025",
  "ut": 1766619000.0,
  "body_paragraphs": [
    "If the past 12 months have taught us anything, it\u2019s that the AI hype train is showing no signs of slowing. It\u2019s hard to believe that at the beginning of the year, DeepSeek had yet to turn the entire industry on its head, Meta was better known for trying (and failing) to make the metaverse cool than for its relentless quest to dominate superintelligence, and vibe coding wasn\u2019t a thing. If that\u2019s left you feeling a little confused, fear not. As we near the end of 2025, our writers have taken a look back over the AI terms that dominated the year, for better or worse.   Make sure you take the time to brace yourself for what promises to be another bonkers year. \u2014Rhiannon Williams",
    "1. Superintelligence  As long as people have been\u00a0hyping\u00a0AI, they have been coming up with names for a future, ultra-powerful form of the technology that could bring about utopian or\u00a0dystopian\u00a0consequences for humanity. \u201cSuperintelligence\u201d is that latest hot term. Meta\u00a0announced\u00a0in July that it would form an AI team to pursue superintelligence, and it was reportedly offering nine-figure compensation packages to AI experts from the company\u2019s competitors to join.  In December, Microsoft\u2019s head of AI\u00a0followed suit, saying the company would be spending big sums, perhaps hundreds of billions, on the pursuit of superintelligence. If you think superintelligence is as vaguely defined as artificial general intelligence, or AGI,\u00a0you\u2019d be right!\u00a0While it\u2019s conceivable that these sorts of technologies will be feasible in humanity\u2019s long run, the question is really\u00a0when, and whether today\u2019s AI is good enough to be treated as a stepping stone toward something like superintelligence. Not that that will stop the hype kings.\u00a0\u2014James O\u2019Donnell",
    "2. Vibe coding  Thirty years ago, Steve Jobs said everyone in America should\u00a0learn how to program a computer. Today, people with zero knowledge of how to code can knock up an app, game, or website in no time at all thanks to\u00a0vibe coding\u2014a catch-all phrase coined by OpenAI cofounder Andrej Karpathy. To vibe-code, you simply prompt generative AI models\u2019 coding assistants to create the digital object of your desire and accept pretty much everything they spit out. Will the result work? Possibly not. Will it be secure? Almost definitely not, but the technique\u2019s biggest champions aren\u2019t letting those minor details stand in their way. Also\u2014it sounds fun!\u00a0\u2014 Rhiannon Williams 3. Chatbot psychosis  One of the biggest AI stories over the past year has been how prolonged interactions with chatbots can cause vulnerable people to experience delusions and, in some extreme cases, can either cause or worsen psychosis. Although \u201cchatbot psychosis\u201d is not a recognized medical term, researchers are paying close attention to the\u00a0growing anecdotal evidence\u00a0from users who say it\u2019s happened to them or someone they know. Sadly, the\u00a0increasing number of lawsuits\u00a0filed against AI companies by the families of people who died following their conversations with chatbots demonstrate the technology\u2019s potentially deadly consequences.\u00a0\u2014Rhiannon Williams 4. Reasoning  Few things kept the AI hype train going this year more than so-called reasoning models, LLMs that can break down a problem into multiple steps and work through them one by one. OpenAI released its first reasoning models, o1 and o3, a year ago.  A month later, the Chinese firm DeepSeek\u00a0took everyone by surprise with a very fast follow, putting out R1, the first open-source reasoning model. In no time, reasoning models became the industry standard: All major mass-market chatbots now come in flavors backed by this tech. Reasoning models have pushed the envelope of what LLMs can do, matching top human performances in prestigious math and coding competitions. On the flip side, all the buzz about LLMs that could \u201creason\u201d reignited old debates about\u00a0how smart LLMs really are and how they really work. Like \u201cartificial intelligence\u201d itself, \u201creasoning\u201d is technical jargon dressed up with marketing sparkle. Choo choo!\u00a0\u2014Will Douglas Heaven  5. World models\u00a0  For all their uncanny facility with language, LLMs have very little common sense. Put simply, they don\u2019t have any grounding in how the world works. Book learners in the most literal sense, LLMs can wax lyrical about everything under the sun and then fall flat with a howler about how many elephants you could fit into an Olympic swimming pool (exactly one, according to one of Google DeepMind\u2019s LLMs).  World models\u2014a broad church encompassing various technologies\u2014aim to give AI some basic common sense about how stuff in the world actually fits together. In their most vivid form, world models like Google DeepMind\u2019s Genie 3 and Marble, the much-anticipated new tech from Fei-Fei Li\u2019s startup World Labs, can generate detailed and realistic virtual worlds for robots to train in and more. Yann LeCun, Meta\u2019s former chief scientist, is also working on world models. He has been trying to give AI a sense of how the world works for years, by training models to predict what happens next in videos. This year he quit Meta to focus on this approach in a new start up called Advanced Machine Intelligence Labs. If all goes well, world models could be the next thing.\u00a0\u2014Will Douglas Heaven 6. Hyperscalers  Have you heard about all the people saying no thanks,\u00a0we actually don\u2019t want a giant data center\u00a0plopped in our backyard? The data centers in question\u2014which tech companies want to built everywhere, including\u00a0space\u2014are typically referred to as hyperscalers: massive buildings purpose-built for AI operations and used by the likes of OpenAI and Google to build bigger and more powerful AI models. Inside such buildings, the world\u2019s best chips hum away training and fine-tuning models, and they\u2019re built to be modular and grow according to needs. It\u2019s been a big year for hyperscalers. OpenAI announced, alongside President Donald Trump, its Stargate project, a $500 billion joint venture to pepper the country with the largest data centers ever. But it leaves almost everyone else asking: What exactly do we get out of it? Consumers worry the new data centers will\u00a0raise their power bills. Such buildings\u00a0generally\u00a0struggle\u00a0to run on renewable energy. And they don\u2019t tend to create all that many\u00a0jobs. But hey, maybe these massive, windowless buildings could at least give a moody, sci-fi vibe to your community.\u00a0\u2014James O\u2019Donnell",
    "7. Bubble  The lofty promises of AI are levitating the economy. AI companies are raising eye-popping sums of money and watching their valuations soar into the stratosphere. They\u2019re pouring hundreds of billions of dollars into chips and data centers, financed increasingly by debt and eyebrow-raising\u00a0circular deals. Meanwhile, the companies leading the gold rush, like OpenAI and Anthropic, might\u00a0not turn a profit\u00a0for years, if ever. Investors are betting big that AI will usher in a new era of riches, yet no one knows how transformative the technology will actually be.  Most organizations using AI aren\u2019t yet seeing the payoff, and AI work slop is everywhere. There\u2019s scientific uncertainty about whether scaling LLMs will deliver superintelligence or whether new breakthroughs need to pave the way. But unlike their predecessors in the dot-com bubble, AI companies are showing strong\u00a0revenue growth, and some are even deep-pocketed tech titans like Microsoft, Google, and Meta. Will the manic dream\u00a0ever burst?\u00a0\u2014Michelle Kim 8. Agentic  This year,\u00a0AI agents\u00a0were everywhere. Every new feature announcement, model drop, or security report throughout 2025 was peppered with mentions of them, even though plenty of AI companies and experts disagree on exactly what counts as being truly \u201cagentic,\u201d a vague term if ever there was one. No matter that it\u2019s virtually impossible to guarantee that an AI acting on your behalf out in the wide web will always do exactly what it\u2019s supposed to do\u2014it seems as though agentic AI is here to stay for the foreseeable. Want to sell something? Call it agentic!\u00a0\u2014Rhiannon Williams 9. Distillation  Early this year, DeepSeek unveiled its new model DeepSeek R1, an open-source reasoning model that matches top Western models but costs a fraction of the price. Its launch freaked Silicon Valley out, as many suddenly realized for the first time that huge scale and resources were not necessarily the key to high-level AI models. Nvidia stock plunged by 17% the day after R1 was released.  The key to R1\u2019s success was distillation, a technique that makes AI models more efficient. It works by getting a bigger model to tutor a smaller model: You run the teacher model on a lot of examples and record the answers, and reward the student model as it copies those responses as closely as possible, so that it gains a compressed version of the teacher\u2019s knowledge.\u00a0\u00a0\u2014Caiwei Chen 10. Sycophancy  As people across the world spend increasing amounts of time\u00a0interacting with chatbots\u00a0like ChatGPT, chatbot makers are struggling to work out the kind of tone and \u201cpersonality\u201d the models should adopt. Back in April, OpenAI admitted it\u2019d struck the wrong balance between helpful and sniveling, saying a new update had rendered GPT-4o\u00a0too sycophantic. Having it suck up to you isn\u2019t just irritating\u2014it can mislead users by reinforcing their incorrect beliefs and spreading misinformation. So consider this your reminder to take everything\u2014yes, everything\u2014LLMs produce with a pinch of salt. \u2014Rhiannon Williams 11. Slop  If there is one AI-related term that has fully escaped the nerd enclosures and entered public consciousness, it\u2019s \u201cslop.\u201d The word itself is old (think pig feed), but \u201cslop\u201d is now commonly used to refer to low-effort, mass-produced content generated by AI, often optimized for online traffic. A lot of people even use it as a shorthand for any AI-generated content. It has felt inescapable in the past year: We have been marinated in it, from\u00a0fake biographies\u00a0to\u00a0shrimp Jesus\u00a0images to\u00a0surreal human-animal hybrid\u00a0videos.  But people are also having fun with it. The term\u2019s sardonic flexibility has made it easy for internet users to slap it on all kinds of words as a suffix to describe anything that lacks substance and is absurdly mediocre: think \u201cwork slop\u201d or \u201cfriend slop.\u201d As the hype cycle resets, \u201cslop\u201d marks a cultural reckoning about what we trust, what we value as creative labor, and what it means to be surrounded by stuff that was made for engagement rather than expression.\u00a0\u2014Caiwei Chen",
    "12. Physical intelligence   Did you come across the hypnotizing\u00a0video\u00a0from earlier this year of a humanoid robot putting away dishes in a bleak, gray-scale kitchen? That pretty much embodies the idea of physical intelligence: the idea that advancements in AI can help robots better move around the physical world.\u00a0 It\u2019s true that robots have been able to learn new tasks\u00a0faster\u00a0than ever before, everywhere from\u00a0operating rooms\u00a0to\u00a0warehouses. Self-driving-car companies have seen improvements in how they\u00a0simulate\u00a0the roads, too. That said, it\u2019s still wise to be skeptical that AI has revolutionized the field. Consider, for example, that many robots advertised as butlers in your home are doing the majority of their tasks thanks to\u00a0remote operators in the Philippines.",
    "The road ahead for physical intelligence is also sure to be weird. Large language models train on text, which is abundant on the internet, but robots learn more from videos of people doing things. That\u2019s why the robot company Figure suggested in September that it would\u00a0pay people\u00a0to film themselves in their apartments doing chores. Would you sign up?\u00a0\u2014James O'Donnell 13. Fair use   AI models are trained by devouring millions of words and images across the internet, including copyrighted work by artists and writers. AI companies argue this is \u201cfair use\u201d\u2014a legal doctrine that lets you use copyrighted material without permission if you transform it into something new that doesn\u2019t compete with the original. Courts are starting to weigh in. In June, Anthropic\u2019s training of its AI model Claude on a library of books was ruled fair use because the technology was \u201cexceedingly transformative.\u201d  That same month, Meta scored a\u00a0similar win, but only because the authors couldn\u2019t show that the company\u2019s literary buffet cut into their paychecks. As copyright battles brew, some creators are cashing in on the feast. In December, Disney signed a\u00a0splashy deal\u00a0with OpenAI to let users of Sora, the AI video platform, generate videos featuring more than 200 characters from Disney's franchises. Meanwhile, governments around the world are\u00a0rewriting copyright rules\u00a0for the content-guzzling machines. Is training AI on copyrighted work fair use? As with any billion-dollar legal question,\u00a0it depends.\u00a0\u2014Michelle Kim 14.\u00a0GEO  Just a few short years ago, an entire industry was built around helping websites rank highly in search results (okay, just in Google). Now search engine optimization (SEO), is giving way to GEO\u2014generative engine optimization\u2014as the AI boom forces brands and businesses to scramble to maximize their visibility in AI, whether that\u2019s in AI-enhanced search results like Google\u2019s\u00a0AI Overviews\u00a0or within responses from LLMs. It\u2019s no wonder they\u2019re freaked out. We already know that news companies have experienced a\u00a0colossal drop\u00a0in\u00a0search-driven web traffic, and AI companies are working on ways to cut out the middleman and allow their users to visit sites from directly within their platforms. It\u2019s time to adapt or die.\u00a0\u2014Rhiannon Williams hide"
  ]
}