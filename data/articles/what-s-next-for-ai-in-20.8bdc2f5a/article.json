{
  "url": "https://www.technologyreview.com/2026/01/05/1130662/whats-next-for-ai-in-2026/",
  "title": "What\u2019s next for AI in 2026",
  "ut": 1767573286.0,
  "body_paragraphs": [
    "MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here. In an industry in constant flux, sticking your neck out to predict what\u2019s coming next may seem reckless. (AI bubble? What AI bubble?) But for the last few years we\u2019ve done just that\u2014and we\u2019re doing it again.\u00a0  How did we do last time? We picked five hot AI trends to look out for in 2025, including what we called generative virtual playgrounds, a.k.a world models (check: From Google DeepMind\u2019s Genie 3 to World Labs\u2019s Marble, tech that can generate realistic virtual environments on the fly keeps getting better and better); so-called reasoning models (check: Need we say more? Reasoning models have fast become the new paradigm for best-in-class problem solving); a boom in AI for science (check: OpenAI is now following Google DeepMind by setting up a dedicated team to focus on just that); AI companies that are cozier with national security (check: OpenAI reversed position on the use of its technology for warfare to sign a deal with the defense-tech startup Anduril to help it take down battlefield drones); and legitimate competition for Nvidia (check, kind of: China is going all in on developing advanced AI chips, but Nvidia\u2019s dominance still looks unassailable\u2014for now at least).\u00a0 So what\u2019s coming in 2026? Here are our big bets for the next 12 months.",
    "More Silicon Valley products will be built on Chinese LLMs The last year shaped up as a big one for Chinese open-source models. In January, DeepSeek released R1, its open-source reasoning model, and shocked the world with what a relatively small firm in China could do with limited resources. By the end of the year, \u201cDeepSeek moment\u201d had become a phrase frequently tossed around by AI entrepreneurs, observers, and builders\u2014an aspirational benchmark of sorts.\u00a0 It was the first time many people realized they could get a taste of top-tier AI performance without going through OpenAI, Anthropic, or Google.",
    "Open-weight models like R1 allow anyone to download a model and run it on their own hardware. They are also more customizable, letting teams tweak models through techniques like distillation and pruning. This stands in stark contrast to the \u201cclosed\u201d models released by major American firms, where core capabilities remain proprietary and access is often expensive. As a result, Chinese models have become an easy choice. Reports by CNBC and Bloomberg suggest that startups in the US have increasingly recognized and embraced what they can offer. One popular group of models is Qwen, created by Alibaba, the company behind China\u2019s largest e-commerce platform, Taobao. Qwen2.5-1.5B-Instruct alone has 8.85 million downloads, making it one of the most widely used pretrained LLMs. The Qwen family spans a wide range of model sizes alongside specialized versions tuned for math, coding, vision, and instruction-following, a breadth that has helped it become an open-source powerhouse. Other Chinese AI firms that were previously unsure about committing to open source are following DeepSeek\u2019s playbook. Standouts include Zhipu\u2019s GLM and Moonshot\u2019s Kimi. The competition has also pushed American firms to open up, at least in part. In August, OpenAI released its first open-source model. In November, the Allen Institute for AI, a Seattle-based nonprofit, released its latest open-source model, Olmo 3.\u00a0  Even amid growing US-China antagonism, Chinese AI firms\u2019 near-unanimous embrace of open source has earned them goodwill in the global AI community and a long-term trust advantage. In 2026, expect more Silicon Valley apps to quietly ship on top of Chinese open models, and look for the lag between Chinese releases and the Western frontier to keep shrinking\u2014from months to weeks, and sometimes less. \u2014Caiwei Chen The US will face another year of regulatory tug-of-war T\u200b\u200bhe battle over regulating artificial intelligence is heading for a showdown. On December 11, President Donald Trump signed an executive order aiming to neuter state AI laws, a move meant to handcuff states from keeping the growing industry in check. In 2026, expect more political warfare. The White House and states will spar over who gets to govern the booming technology, while AI companies wage a fierce lobbying campaign to crush regulations, armed with the narrative that a patchwork of state laws will smother innovation and hobble the US in the AI arms race against China. Under Trump\u2019s executive order, states may fear being sued or starved federal funding if they clash with his vision for light-touch regulation. Big Democratic states like California\u2014which just enacted the nation\u2019s first frontier AI law requiring companies to publish safety testing for their AI models\u2014will take the fight to court, arguing that only Congress can override state laws. But states that can\u2019t afford to lose federal funding, or fear getting in Trump\u2019s crosshairs, might fold. Still, expect to see more state lawmaking on hot-button issues, especially where Trump\u2019s order gives states a green light to legislate. With chatbots accused of triggering teen suicides and data centers sucking up more and more energy, states will face mounting public pressure to push for guardrails.",
    "In place of state laws, Trump promises to work with Congress to establish a federal AI law. Don\u2019t count on it. Congress failed to pass a moratorium on state legislation twice in 2025, and we aren\u2019t holding out hope that it will deliver its own bill this year.\u00a0 AI companies like OpenAI and Meta will continue to deploy powerful super-PACs to support political candidates who back their agenda and target those who stand in their way. On the other side, super-PACs supporting AI regulation will build their own war chests to counter. Watch them duke it out at next year\u2019s midterm elections. The further AI advances, the more people will fight to steer its course, and 2026 will be another year of regulatory tug-of-war\u2014with no end in sight. \u2014Michelle Kim  Chatbots will change the way we shop Imagine a world in which you have a personal shopper at your disposal 24-7\u2014an expert who can instantly recommend a gift for even the trickiest-to-buy-for friend or relative, or trawl the web to draw up a list of the best bookcases available within your tight budget. Better yet, they can analyze a kitchen appliance\u2019s strengths and weaknesses, compare it with its seemingly identical competition, and find you the best deal. Then once you\u2019re happy with their suggestion, they\u2019ll take care of the purchasing and delivery details too.But this ultra-knowledgeable shopper isn\u2019t a clued-up human at all\u2014it\u2019s a chatbot. This is no distant prediction, either. Salesforce recently said it anticipates that AI will drive $263 billion in online purchases this holiday season. That\u2019s some 21% of all orders. And experts are betting on AI-enhanced shopping becoming even bigger business within the next few years. By 2030, between $3 trillion and $5 trillion annually will be made from agentic commerce, according to research from the consulting firm McKinsey.\u00a0 Unsurprisingly, AI companies are already heavily invested in making purchasing through their platforms as frictionless as possible. Google\u2019s Gemini app can now tap into the company\u2019s powerful Shopping Graph data set of products and sellers, and can even use its agentic technology to call stores on your behalf. Meanwhile, back in November, OpenAI announced a ChatGPT shopping feature capable of rapidly compiling buyer\u2019s guides, and the company has struck deals with Walmart, Target, and Etsy to allow shoppers to buy products directly within chatbot interactions.\u00a0 Expect plenty more of these kinds of deals to be struck within the next year as consumer time spent chatting with AI keeps on rising, and web traffic from search engines and social media continues to plummet.\u00a0 \u2014Rhiannon Williams",
    "An LLM will make an important new discovery I\u2019m going to hedge here, right out of the gate. It\u2019s no secret that large language models spit out a lot of nonsense. Unless it\u2019s with monkeys-and-typewriters luck, LLMs won\u2019t discover anything by themselves. But LLMs do still have the potential to extend the bounds of human knowledge. We got a glimpse of how this could work in May, when Google DeepMind revealed AlphaEvolve, a system that used the firm\u2019s Gemini LLM to come up with new algorithms for solving unsolved problems. The breakthrough was to combine Gemini with an evolutionary algorithm that checked its suggestions, picked the best ones, and fed them back into the LLM to make them even better.",
    "Google DeepMind used AlphaEvolve to come up with more efficient ways to manage power consumption by data centers and Google\u2019s TPU chips. Those discoveries are significant but not game-changing. Yet. Researchers at Google DeepMind are now pushing their approach to see how far it will go. And others have been quick to follow their lead. A week after AlphaEvolve came out, Asankhaya Sharma, an AI engineer in Singapore, shared OpenEvolve, an open-source version of Google DeepMind\u2019s tool. In September, the Japanese firm Sakana AI released a version of the software called SinkaEvolve. And in November, a team of US and Chinese researchers revealed AlphaResearch, which they claim improves on one of AlphaEvolve\u2019s already better-than-human math solutions. There are alternative approaches too. For example, researchers at the University of Colorado Denver are trying to make LLMs more inventive by tweaking the way so-called reasoning models work. They have drawn on what cognitive scientists know about creative thinking in humans to push reasoning models toward solutions that are more outside the box than their typical safe-bet suggestions. Hundreds of companies are spending billions of dollars looking for ways to get AI to crack unsolved math problems, speed up computers, and come up with new drugs and materials. Now that AlphaEvolve has shown what\u2019s possible with LLMs, expect activity on this front to ramp up fast.\u00a0\u00a0\u00a0\u00a0 \u2014Will Douglas Heaven Legal fights heat up For a while, lawsuits against AI companies were pretty predictable: Rights holders like authors or musicians would sue companies that trained AI models on their work, and the courts generally found in favor of the tech giants. AI\u2019s upcoming legal battles will be far messier.",
    "The fights center on thorny, unresolved questions: Can AI companies be held liable for what their chatbots encourage people to do, as when they help teens plan suicides? If a chatbot spreads patently false information about you, can its creator be sued for defamation? If companies lose these cases, will insurers shun AI companies as clients? In 2026, we\u2019ll start to see the answers to these questions, in part because some notable cases will go to trial (the family of a teen who died by suicide will bring OpenAI to court in November). At the same time, the legal landscape will be further complicated by President Trump\u2019s executive order from December\u2014see Michelle\u2019s item above for more details on the brewing regulatory storm. No matter what, we\u2019ll see a dizzying array of lawsuits in all directions (not to mention some judges even turning to AI amid the deluge). \u2014James O\u2019Donnell hide"
  ]
}