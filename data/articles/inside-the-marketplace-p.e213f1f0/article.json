{
  "url": "https://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/",
  "title": "Inside the marketplace powering bespoke AI deepfakes of real women",
  "ut": 1769752951.0,
  "body_paragraphs": [
    "Civitai\u2014an online marketplace for buying and selling AI-generated content, backed by the venture capital firm Andreessen Horowitz\u2014is letting users buy custom instruction files for generating celebrity deepfakes. Some of these files were specifically designed to make pornographic images banned by the site, a new analysis has found. The study, from researchers at Stanford and Indiana University, looked at people\u2019s requests for content on the site, called \u201cbounties.\u201d The researchers found that between mid-2023 and the end of 2024, most bounties asked for animated content\u2014but a significant portion were for deepfakes of real people, and 90% of these deepfake requests targeted women. (Their findings have not yet been peer reviewed.)  The debate around deepfakes, as illustrated by the recent backlash to explicit images on the X-owned chatbot Grok, has revolved around what platforms should do to block such content. Civitai\u2019s situation is a little more complicated. Its marketplace includes actual images, videos, and models, but it also lets individuals buy and sell instruction files called LoRAs that can coach mainstream AI models like Stable Diffusion into generating content they were not trained to produce. Users can then combine these files with other tools to make deepfakes that are graphic or sexual. The researchers found that 86% of deepfake requests on Civitai were for LoRAs. In these bounties, users requested \u201chigh quality\u201d models to generate images of public figures like the influencer Charli D\u2019Amelio or the singer Gracie Abrams, often linking to their social media profiles so their images could be grabbed from the web. Some requests specified a desire for models that generated the individual\u2019s entire body, accurately captured their tattoos, or allowed hair color to be changed. Some requests targeted several women in specific niches, like artists who record ASMR videos. One request was for a deepfake of a woman said to be the user\u2019s wife. Anyone on the site could offer up AI models they worked on for the task, and the best submissions received payment\u2014anywhere from $0.50 to $5. And nearly 92% of the deepfake bounties were awarded.",
    "Neither Civitai nor Andreessen Horowitz responded to requests for comment. It\u2019s possible that people buy these LoRAs to make deepfakes that aren\u2019t sexually explicit (though they\u2019d still violate Civitai\u2019s terms of use, and they\u2019d still be ethically fraught). But Civitai also offers educational resources on how to use external tools to further customize the outputs of image generators\u2014for example, by changing someone\u2019s pose. The site also hosts user-written articles with details on how to instruct models to generate pornography. The researchers found that the amount of porn on the platform has gone up, and that the majority of requests each week are now for NSFW content.",
    "\u201cNot only does Civitai provide the infrastructure that facilitates these issues; they also explicitly teach their users how to utilize them,\u201d says Matthew DeVerna, a postdoctoral researcher at Stanford\u2019s Cyber Policy Center and one of the study\u2019s leaders.\u00a0 The company used to ban only sexually explicit deepfakes of real people, but in May 2025 it announced it would ban all deepfake content. Nonetheless, countless requests for deepfakes submitted before this ban now remain live on the site, and many of the winning submissions fulfilling those requests remain available for purchase, MIT Technology Review confirmed. Related StoryAn AI companion site is hosting sexually charged conversations with underage celebrity botsRead next \u201cI believe the approach that they\u2019re trying to take is to sort of do as little as possible, such that they can foster as much\u2014I guess they would call it\u2014creativity on the platform,\u201d DeVerna says. Users buy LoRAs with the site\u2019s online currency, called Buzz, which is purchased with real money. In May 2025, Civita\u2019s credit card processor cut off the company because of its ongoing problem with nonconsensual content. To pay for explicit content, users must now use gift cards or cryptocurrency to buy Buzz; the company offers a different scrip for non-explicit content.\u00a0 Civitai automatically tags bounties requesting deepfakes and lists a way for the person featured in the content to manually request its takedown. This system means that Civitai has a reasonably successful way of knowing which bounties are for deepfakes, but it\u2019s still leaving moderation to the general public rather than carrying it out proactively.\u00a0 A company\u2019s legal liability for what its users do isn\u2019t totally clear. Generally, tech companies have broad legal protections against such liability for their content under Section 230 of the Communications Decency Act, but those protections aren\u2019t limitless. For example, \u201cyou cannot knowingly facilitate illegal transactions on your website,\u201d says Ryan Calo, a professor specializing in technology and AI at the University of Washington\u2019s law school. (Calo wasn\u2019t involved in this new study.) Civitai joined OpenAI, Anthropic, and other AI companies in 2024 in adopting design principles to guard against the creation and spread of AI-generated child sexual abuse material . This move followed a 2023 report from the Stanford Internet Observatory, which found that the vast majority of AI models named in child sexual abuse communities were Stable Diffusion\u2013based models \u201cpredominantly obtained via Civitai.\u201d But adult deepfakes have not gotten the same level of attention from content platforms or the venture capital firms that fund them. \u201cThey are not afraid enough of it. They are overly tolerant of it,\u201d Calo says. \u201cNeither law enforcement nor civil courts adequately protect against it. It is night and day.\u201d Civitai received a $5 million investment from Andreessen Horowitz (a16z) in November 2023. In a video shared by a16z, Civitai cofounder and CEO Justin Maier described his goal of building the main place where people find and share AI models for their own individual purposes. \u201cWe\u2019ve aimed to make this space that\u2019s been very, I guess, niche and engineering-heavy more and more approachable to more and more people,\u201d he said.\u00a0 Civitai is not the only company with a deepfake problem in a16z\u2019s investment portfolio; in February, MIT Technology Review first reported that another company, Botify AI, was hosting AI companions resembling real actors that stated their age as under 18, engaged in sexually charged conversations, offered \u201chot photos,\u201d and in some instances described age-of-consent laws as \u201carbitrary\u201d and \u201cmeant to be broken.\u201d hide"
  ]
}