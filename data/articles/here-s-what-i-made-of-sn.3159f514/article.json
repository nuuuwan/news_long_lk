{
  "url": "https://www.technologyreview.com/2024/09/17/1104025/snap-spectacles-ar-glasses/",
  "title": "Here\u2019s what I made of Snap\u2019s new augmented-reality Spectacles",
  "ut": 1726562082.0,
  "body_paragraphs": [
    "Before I get to Snap\u2019s new Spectacles, a confession: I have a long history of putting goofy new things on my face and liking it. Back in 2011, I tried on Sony\u2019s head-mounted 3D glasses and, apparently, enjoyed them. Sort of. At the beginning of 2013, I was enamored with a Kickstarter project I saw at CES called Oculus Rift. I then spent the better part of the year with Google\u2019s ridiculous Glass on my face and thought it was the future. Microsoft HoloLens? Loved it. Google Cardboard? Totally normal. Apple Vision Pro? A breakthrough, baby.\u00a0 Anyway. Snap announced a new version of its Spectacles today. These are AR glasses that could finally deliver on the promises devices like Magic Leap, or HoloLens, or even Google Glass, made many years ago. I got to try them out a couple of weeks ago. They are pretty great! (But also: See above) These fifth-generation Spectacles can display visual information and applications directly on their see-through lenses, making objects appear as if they are in the real world. The interface is powered by the company\u2019s new operating system, Snap OS. Unlike typical VR headsets or spatial computing devices, these augmented-reality (AR) lenses don\u2019t obscure your vision and re-create it with cameras. There is no screen covering your field of view. Instead, images appear to float and exist in three dimensions in the world around you, hovering in the air or resting on tables and floors. Snap CTO Bobby Murphy described the intended result to MIT Technology Review as \u201ccomputing overlaid on the world that enhances our experience of the people in the places that are around us, rather than isolating us or taking us out of that experience.\u201d",
    "In my demo, I was able to stack Lego pieces on a table, smack an AR golf ball into a hole across the room (at least a triple bogey), paint flowers and vines across the ceilings and walls using my hands, and ask questions about the objects I was looking at and receive answers from Snap\u2019s virtual AI chatbot. There was even a little purple virtual doglike creature from Niantic, a Peridot, that followed me around the room and outside onto a balcony.\u00a0 But look up from the table and you see a normal room. The golf ball is on the floor, not a virtual golf course. The Peridot perches on a real balcony railing. Crucially, this means you can maintain contact\u2014including eye contact\u2014with the people around you in the room.",
    "To accomplish all this, Snap packed a lot of tech into the frames. There are two processors embedded inside, so all the compute happens in the glasses themselves. Cooling chambers in the sides did an effective job of dissipating heat in my demo. Four cameras capture the world around you, as well as the movement of your hands for gesture tracking. The images are displayed via micro-projectors, similar to those found in pico projectors, that do a nice job of presenting those three-dimensional images right in front of your eyes without requiring a lot of initial setup. It creates a tall, deep field of view\u2014Snap claims it is similar to a 100-inch display at 10 feet\u2014in a relatively small, lightweight device (226 grams).\u00a0What\u2019s more, they automatically darken when you step outside, so they work well not just in your home but out in the world. You control all this with a combination of voice and hand gestures, most of which came pretty naturally to me. You can pinch to select objects and drag them around, for example. The AI chatbot could respond to questions posed in natural language (\u201cWhat\u2019s that ship I see in the distance?\u201d). Some of the interactions require a phone, but for the most part Spectacles are a standalone device.\u00a0 It doesn\u2019t come cheap. Snap isn\u2019t selling the glasses directly to consumers but requires you to agree to at least one year of paying $99 per month for a Spectacles Developer Program account that gives you access to them. I was assured that the company has a very open definition of who can develop for the platform. Snap also announced a new partnership with OpenAI that takes advantage of its multimodal capabilities, which it says will help developers create experiences with real-world context about the things people see or hear (or say).  It me. Having said that, it all worked together impressively well. The three-dimensional objects maintained a sense of permanence in the spaces where you placed them\u2014meaning you can move around and they stay put. The AI assistant correctly identified everything I asked it to. There were some glitches here and there\u2014Lego bricks collapsing into each other, for example\u2014but for the most part this was a solid little device.\u00a0 It is not, however, a low-profile one. No one will mistake these for a normal pair of glasses or sunglasses. A colleague described them as beefed-up 3D glasses, which seems about right. They are not the silliest computer I have put on my face, but they didn\u2019t exactly make me feel like a cool guy, either. Here\u2019s a photo of me trying them out. Draw your own conclusions. hide"
  ]
}