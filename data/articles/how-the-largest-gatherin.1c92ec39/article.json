{
  "url": "https://www.technologyreview.com/2024/11/19/1106979/how-the-largest-gathering-of-us-police-chiefs-is-talking-about-ai/",
  "title": "How the largest gathering of US police chiefs is talking about AI",
  "ut": 1731972600.0,
  "body_paragraphs": [
    "This story is from The Algorithm, our weekly newsletter on AI. To get it in your inbox first,\u00a0sign up here. It can be tricky for reporters to get past certain doors, and the door to the International Association of Chiefs of Police conference is one that\u2019s almost perpetually shut to the media. Thus, I was pleasantly surprised when I was able to attend for a day in Boston last month.\u00a0  It bills itself as the largest gathering of police chiefs in the United States, where leaders from many of the country\u2019s 18,000 police departments and even some from abroad convene for product demos, discussions, parties, and awards.\u00a0 I went along to see how artificial intelligence was being discussed, and the message to police chiefs seemed crystal clear: If your department is slow to adopt AI, fix that now. The future of policing will rely on it in all its forms.",
    "In the event\u2019s expo hall, the vendors (of which there were more than 600) offered a glimpse into the ballooning industry of police-tech suppliers. Some had little to do with AI\u2014booths showcased body armor, rifles, and prototypes of police-branded Cybertrucks, and others displayed new types of gloves promising to protect officers from needles during searches. But one needed only to look to where the largest crowds gathered to understand that AI was the major draw.\u00a0 The hype focused on three uses of AI in policing.\u00a0The flashiest was virtual reality, exemplified by the booth from V-Armed, which sells VR systems for officer training. On the expo floor, V-Armed built an arena complete with VR goggles, cameras, and sensors, not unlike the one the company recently installed at the headquarters of the Los Angeles Police Department. Attendees could don goggles and go through training exercises on responding to active shooter situations. Many competitors of V-Armed were also at the expo, selling systems they said were cheaper, more effective, or simpler to maintain.",
    "The pitch on VR training is that in the long run, it can be cheaper and more engaging to use than training with actors or in a classroom. \u201cIf you\u2019re enjoying what you\u2019re doing, you\u2019re more focused and you remember more than when looking at a PDF and nodding your head,\u201d V-Armed CEO Ezra Kraus told me.\u00a0 The effectiveness of VR training systems has yet to be fully studied, and they can\u2019t completely replicate the nuanced interactions police have in the real world. AI is not yet great at the soft skills required for interactions with the public. At a different company\u2019s booth, I tried out a VR system focused on deescalation training, in which officers were tasked with calming down an AI character in distress. It suffered from lag and was generally quite awkward\u2014the character\u2019s answers felt overly scripted and programmatic.\u00a0 The second focus was on the changing way police departments are collecting and interpreting data.\u00a0Rather than buying a gunshot detection tool from one company and a license plate reader or drone from another, police departments are increasingly using expanding suites of sensors, cameras, and so on from a handful of leading companies that promise to integrate the data collected and make it useful.\u00a0 Police chiefs attended classes on how to build these systems, like one taught by Microsoft and the NYPD about the Domain Awareness System, a web of license plate readers, cameras, and other data sources used to track and monitor crime in New York City. Crowds gathered at massive, high-tech booths from Axon and Flock, both sponsors of the conference. Flock sells a suite of cameras, license plate readers, and drones, offering AI to analyze the data coming in and trigger alerts. These sorts of tools have come in for heavy criticism from civil liberties groups, which see them\u00a0as an assault on privacy\u00a0that does little to help the public.\u00a0 Related StoryWhat\u2019s next for dronesPolice drones, rapid deliveries of blood, tech-friendly regulations, and autonomous weapons are all signs that drone technology is changing quickly.",
    "Finally, as in other industries, AI is also coming for the drudgery of administrative tasks and reporting.\u00a0Many companies at the expo, including Axon, offer generative AI products to help police officers write their reports. Axon\u2019s offering, called Draft One, ingests footage from body cameras, transcribes it, and creates a first draft of a report for officers.\u00a0 \u201cWe\u2019ve got this thing on an officer\u2019s body, and it\u2019s recording all sorts of great stuff about the incident,\u201d Bryan Wheeler, a senior vice president at Axon, told me at the expo. \u201cCan we use it to give the officer a head start?\u201d On the surface, it\u2019s a writing task well suited for AI, which can quickly summarize information and write in a formulaic way. It could also save lots of time officers currently spend on writing reports.\u00a0But given that AI is prone to \u201challucination,\u201d there\u2019s an unavoidable truth: Even if officers are the final authors of their reports, departments adopting these sorts of tools risk injecting errors into some of the most critical documents in the justice system.\u00a0 \u201cPolice reports are sometimes the only memorialized account of an incident,\u201d wrote Andrew Ferguson, a professor of law at American University, in July in the first\u00a0law review article\u00a0about the serious challenges posed by police reports written with AI. \u201cBecause criminal cases can take months or years to get to trial, the accuracy of these reports are critically important.\u201d Whether certain details were included or left out can affect the outcomes of everything from bail amounts to verdicts.",
    "By showing an officer a generated version of a police report, the tools also expose officers to details from their body camera recordings\u00a0before\u00a0they complete their report, a document intended to capture the officer\u2019s memory of the incident. That poses a problem.\u00a0 \u201cThe police certainly would never show video to a bystander eyewitness before they ask the eyewitness about what took place, as that would just be investigatory malpractice,\u201d says Jay Stanley, a senior policy analyst with the ACLU Speech, Privacy, and Technology Project, who will soon publish work on the subject.\u00a0 A spokesperson for Axon says this concern \u201cisn\u2019t reflective of how the tool is intended to work,\u201d and that Draft One has robust features to make sure officers read the reports closely, add their own information, and edit the reports for accuracy before submitting them. My biggest takeaway from the conference was simply that the way US police are adopting AI is inherently chaotic.\u00a0There is no one agency governing how they use the technology, and the roughly 18,000 police departments in the United States\u2014the precise figure is not even known\u2014have remarkably high levels of autonomy to decide which AI tools they\u2019ll buy and deploy. The police-tech companies that serve them will build the tools police departments find attractive, and it\u2019s unclear if anyone will draw proper boundaries for ethics, privacy, and accuracy.\u00a0  That will only be made more apparent in an upcoming Trump administration. In a policing\u00a0agenda\u00a0released last year during his campaign, Trump encouraged more aggressive tactics like \u201cstop and frisk,\u201d deeper cooperation with immigration agencies, and increased liability protection for officers accused of wrongdoing. The Biden administration is now\u00a0reportedly\u00a0attempting to lock in some of its proposed policing reforms before January.\u00a0 Without federal regulation on how police departments can and cannot use AI, the lines will be drawn by departments and police-tech companies themselves. \u201cUltimately, these are for-profit companies, and their customers are law enforcement,\u201d says Stanley. \u201cThey do what their customers want, in the absence of some very large countervailing threat to their business model.\u201d  Now read the rest of The Algorithm Deeper Learning The AI lab waging a guerrilla war over exploitative AI",
    "When generative AI tools landed on the scene, artists were immediately concerned, seeing them as a new kind of theft. Computer security researcher Ben Zhao jumped into action in response, and his lab at the University of Chicago started building tools like Nightshade and Glaze to help artists keep their work from being scraped up by AI models. My colleague Melissa Heikkil\u00e4 spent time with Zhao and his team to look at the ongoing effort to make these tools strong enough to stop AI\u2019s relentless hunger for more images, art, and data to train on.\u00a0\u00a0 Why this matters: The current paradigm in AI is to build bigger and bigger models, and these require vast data sets to train on. Tech companies argue that anything on the public internet is fair game, while artists demand compensation or the right to refuse. Settling this fight in the courts or through regulation could take years, so tools like Nightshade and Glaze are what artists have for now. If the tools disrupt AI companies\u2019 efforts to make better models, that could push them to the negotiating table to bargain over licensing and fair compensation. But it\u2019s a big \u201cif.\u201d\u00a0Read more from Melissa Heikkil\u00e4.",
    "Bits and Bytes Tech elites are lobbying Elon Musk for jobs in Trump\u2019s administration Elon Musk is the tech leader who most has Trump\u2019s ear. As such, he\u2019s reportedly the conduit through which AI and tech insiders are pushing to have an influence in the incoming administration. (The New York Times) OpenAI is getting closer to launching an AI agent to automate your tasks AI agents\u2014models that can do tasks for you on your behalf\u2014are all the rage. OpenAI is reportedly closer to releasing one, news that comes a few weeks after Anthropic\u00a0announced\u00a0its own. (Bloomberg) How this grassroots effort could make AI voices more diverse A massive volunteer-led effort to collect training data in more languages, from people of more ages and genders, could help make the next generation of voice AI more inclusive and less exploitative. (MIT Technology Review)",
    "Google DeepMind has a new way to look inside an AI\u2019s \u201cmind\u201d Autoencoders let us peer into the black box of artificial intelligence. They could help us create AI that is better understood and more easily controlled. (MIT Technology Review) Musk has expanded his legal assault on OpenAI to target Microsoft Musk has expanded his federal lawsuit against OpenAI, which alleges that the company has abandoned its nonprofit roots and obligations. He\u2019s now going after Microsoft too, accusing it of antitrust violations in its work with OpenAI. (The Washington Post) hide"
  ]
}