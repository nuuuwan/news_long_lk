{
  "url": "https://www.technologyreview.com/2026/01/26/1131726/why-chatbots-are-starting-to-check-your-age/",
  "title": "Why chatbots are starting to check your age",
  "ut": 1769409300.0,
  "body_paragraphs": [
    "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,\u00a0sign up here. How do tech companies check if their users are kids?  This question has taken on new urgency recently thanks to growing concern about the dangers that can arise when children talk to AI chatbots. For years Big Tech asked for birthdays (that one could make up) to avoid violating child privacy laws, but they weren\u2019t required to moderate content accordingly. Two developments over the last week show how quickly things are changing in the US and how this issue is becoming a new battleground, even among parents and child-safety advocates. In one corner is the Republican Party, which has supported laws passed in several states that require sites with adult content to verify users\u2019 ages. Critics say this provides cover to block anything deemed \u201charmful to minors,\u201d which could include sex education. Other states, like California, are coming after AI companies with laws to protect kids who talk to chatbots (by requiring them to verify who\u2019s a kid). Meanwhile, President Trump is attempting to keep AI regulation a national issue rather than allowing states to make their own rules. Support for various bills in Congress is constantly in flux.",
    "So what might happen? The debate is quickly moving away from whether age verification is necessary and toward who will be responsible for it. This responsibility is a hot potato that no company wants to hold. In a blog post last Tuesday, OpenAI revealed that it plans to roll out automatic age prediction. In short, the company will apply a model that uses factors like the time of day, among others, to predict whether a person chatting is under 18. For those identified as teens or children, ChatGPT will apply filters to \u201creduce exposure\u201d to content like graphic violence or sexual role-play. YouTube launched something similar last year.",
    "If you support age verification but are concerned about privacy, this might sound like a win. But there's a catch. The system is not perfect, of course, so it could classify a child as an adult or vice versa. People who are wrongly labeled under 18 can verify their identity by submitting a selfie or government ID to a company called Persona.\u00a0 Selfie verifications have issues: They fail more often for people of color and those with certain disabilities. Sameer Hinduja, who co-directs the Cyberbullying Research Center, says the fact that Persona will need to hold millions of government IDs and masses of biometric data is another weak point. \u201cWhen those get breached, we\u2019ve exposed massive populations all at once,\u201d he says.\u00a0 Hinduja instead advocates for device-level verification, where a parent specifies a child\u2019s age when setting up the child\u2019s phone for the first time. This information is then kept on the device and shared securely with apps and websites.\u00a0 That\u2019s more or less what Tim Cook, the CEO of Apple, recently lobbied US lawmakers to call for. Cook was fighting lawmakers who wanted to require app stores to verify ages, which would saddle Apple with lots of liability.\u00a0 Related StoryAn AI companion site is hosting sexually charged conversations with underage celebrity botsRead nextMore signals of where this is all headed will come on Wednesday, when the Federal Trade Commission\u2014the agency that would be responsible for enforcing these new laws\u2014is holding an all-day workshop on age verification. Apple\u2019s head of government affairs, Nick Rossi, will be there. He\u2019ll be joined by higher-ups in child safety at Google and Meta, as well as a company that specializes in marketing to children. The FTC has become increasingly politicized under President Trump (his firing of the sole Democratic commissioner was struck down by a federal court, a decision that is now pending review by the US Supreme Court). In July, I wrote about signals that the agency is softening its stance toward AI companies. Indeed, in December, the FTC overturned a Biden-era ruling against an AI company that allowed people to flood the internet with fake product reviews, writing that it clashed with President Trump\u2019s AI Action Plan. Wednesday\u2019s workshop may shed light on how partisan the FTC\u2019s approach to age verification will be. Red states favor laws that require porn websites to verify ages (but critics warn this could be used to block a much wider range of content). Bethany Soye, a Republican state representative who is leading an effort to pass such a bill in her state of South Dakota, is scheduled to speak at the FTC meeting. The ACLU generally opposes laws requiring IDs to visit websites and has instead advocated for an expansion of existing parental controls. While all this gets debated, though, AI has set the world of child safety on fire. We\u2019re dealing with increased generation of child sexual abuse material, concerns (and lawsuits) about suicides and self-harm following chatbot conversations, and troubling evidence of kids\u2019 forming attachments to AI companions. Colliding stances on privacy, politics, free expression, and surveillance will complicate any effort to find a solution. Write to me with your thoughts.\u00a0 hide"
  ]
}