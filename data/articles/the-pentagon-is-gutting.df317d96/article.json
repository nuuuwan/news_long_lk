{
  "url": "https://www.technologyreview.com/2025/06/10/1118229/pentagon-gutting-ai-test/",
  "title": "The Pentagon is gutting the team that tests AI and weapons systems",
  "ut": 1749511800.0,
  "body_paragraphs": [
    "The Trump administration\u2019s chainsaw approach to federal spending lives on, even as Elon Musk turns on the president. On May 28, Secretary of Defense Pete Hegseth announced he\u2019d be gutting a key office at the Department of Defense responsible for testing and evaluating the safety of weapons and AI systems. As part of a string of moves aimed at \u201creducing bloated bureaucracy and wasteful spending in favor of increased lethality,\u201d Hegseth cut the size of the Office of the Director of Operational Test and Evaluation in half. The group was established in the 1980s\u2014following orders from Congress\u2014after criticisms that the Pentagon was fielding weapons and systems that didn\u2019t perform as safely or effectively as advertised. Hegseth is reducing the agency\u2019s staff to about 45, down from 94, and firing and replacing its director. He gave the office just seven days to implement the changes.  It is a significant overhaul of a department that in 40 years has never before been placed so squarely on the chopping block. Here\u2019s how today\u2019s defense tech companies, which have fostered close connections to the Trump administration, stand to gain, and why safety testing might suffer as a result.\u00a0 The Operational Test and Evaluation office is \u201cthe last gate before a technology gets to the field,\u201d says Missy Cummings, a former fighter pilot for the US Navy who is now a professor of engineering and computer science at George Mason University. Though the military can do small experiments with new systems without running it by the office, it has to test anything that gets fielded at scale.",
    "\u201cIn a bipartisan way\u2014up until now\u2014everybody has seen it\u2019s working to help reduce waste, fraud, and abuse,\u201d she says. That\u2019s because it provides an independent check on companies\u2019 and contractors\u2019 claims about how well their technology works. It also aims to expose the systems to more rigorous safety testing. The gutting comes at a particularly pivotal time for AI and military adoption: The Pentagon is experimenting with putting AI into everything, mainstream companies like OpenAI are now more comfortable working with the military, and defense giants like Anduril are winning big contracts to launch AI systems (last Thursday, Anduril announced a whopping $2.5 billion funding round, doubling its valuation to over $30 billion).",
    "Hegseth claims his cuts will \u201cmake testing and fielding weapons more efficient,\u201d saving $300 million. But Cummings is concerned that they are paving a way to faster adoption while increasing the chances that new systems won\u2019t be as safe or effective as promised. \u201cThe firings in DOTE send a clear message that all perceived obstacles for companies favored by Trump are going to be removed,\u201d she says. Anduril and Anthropic, which have launched AI applications for military use, did not respond to my questions about whether they pushed for or approve of the cuts. A representative for OpenAI said that the company was not involved in lobbying for the restructuring.\u00a0 \u201cThe cuts make me nervous,\u201d says Mark Cancian, a senior advisor at the Center for Strategic and International Studies who previously worked at the Pentagon in collaboration with the testing office. \u201cIt\u2019s not that we\u2019ll go from effective to ineffective, but you might not catch some of the problems that would surface in combat without this testing step.\u201d It\u2019s hard to say precisely how the cuts will affect the office\u2019s ability to test systems, and Cancian admits that those responsible for getting new technologies out onto the battlefield sometimes complain that it can really slow down adoption. But still, he says, the office frequently uncovers errors that weren\u2019t previously caught. It\u2019s an especially important step, Cancian says, whenever the military is adopting a new type of technology like generative AI. Systems that might perform well in a lab setting almost always encounter new challenges in more realistic scenarios, and the Operational Test and Evaluation group is where that rubber meets the road. So what to make of all this? It\u2019s true that the military was experimenting with artificial intelligence long before the current AI boom, particularly with computer vision for drone feeds, and defense tech companies have been winning big contracts for this push across multiple presidential administrations. But this era is different. The Pentagon is announcing ambitious pilots specifically for large language models, a relatively nascent technology that by its very nature produces hallucinations and errors, and it appears eager to put much-hyped AI into everything. The key independent group dedicated to evaluating the accuracy of these new and complex systems now only has half the staff to do it. I\u2019m not sure that\u2019s a win for anyone. This story originally appeared in\u00a0The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,\u00a0sign up here. hide"
  ]
}