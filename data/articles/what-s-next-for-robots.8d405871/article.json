{
  "url": "https://www.technologyreview.com/2025/01/23/1110496/whats-next-for-robots/",
  "title": "What\u2019s next for robots",
  "ut": 1737621596.0,
  "body_paragraphs": [
    "MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them\u00a0here. Jan Liphardt teaches bioengineering at Stanford, but to many strangers in Los Altos, California, he is a peculiar man they see walking a four-legged robotic dog down the street.\u00a0  Liphardt has been experimenting with building and modifying robots for years, and when he brings his \u201cdog\u201d out in public, he generally gets one of three reactions. Young children want to have one, their parents are creeped out, and baby boomers try to ignore it. \"They\u2019ll quickly walk by,\u201d he says, \u201clike, \u2018What kind of dumb new stuff is going on here?\u2019\u201d\u00a0 In the many conversations I\u2019ve had about robots, I\u2019ve also found that most people tend to fall into these three camps, though I don\u2019t see such a neat age division. Some are upbeat and vocally hopeful that a future is just around the corner in which machines can expertly handle much of what is currently done by humans, from cooking to surgery. Others are scared: of job losses, injuries, and whatever problems may come up as we try to live side by side.",
    "The final camp, which I think is the largest, is just unimpressed. We\u2019ve been sold lots of promises that robots will transform society ever since the first robotic arm was installed on an assembly line at a General Motors plant in New Jersey in 1961. Few of those promises have panned out so far.\u00a0 But this year, there\u2019s reason to think that even those staunchly in the \u201cbored\u201d camp will be intrigued by what\u2019s happening in the robot races. Here\u2019s a glimpse at what to keep an eye on.",
    "Humanoids are put to the test The race to build humanoid robots is motivated by the idea that the world is set up for the human form, and that automating that form could mean a seismic shift for robotics. It is led by some particularly outspoken and optimistic entrepreneurs, including Brett Adcock, the founder of Figure AI, a company making such robots that\u2019s valued at more than $2.6 billion (it\u2019s begun testing its robots with BMW). Adcock recently told Time, \u201cEventually, physical labor will be optional.\u201d Elon Musk, whose company Tesla is building a version called Optimus, has said humanoid robots will create \u201ca future where there is no poverty.\u201d A robotics company called Eliza Wakes Up is taking preorders for a $420,000 humanoid called, yes, Eliza. In June 2024, Agility Robotics sent a fleet of its Digit humanoid robots to GXO Logistics, which moves products for companies ranging from Nike to Nestl\u00e9. The humanoids can handle most tasks that involve picking things up and moving them somewhere else, like unloading pallets or putting boxes on a conveyor.\u00a0 There have been hiccups: Highly polished concrete floors can cause robots to slip at first, and buildings need good Wi-Fi coverage for the robots to keep functioning. But charging is a bigger issue. Agility\u2019s current version of Digit, with a 39-pound battery, can run for two to four hours before it needs to charge for one hour, so swapping out the robots for fresh ones is a common task on each shift. If there are a small number of charging docks installed, the robots can theoretically charge by shuffling among the docks themselves overnight when some facilities aren\u2019t running, but moving around on their own can set off a building\u2019s security system. \u201cIt\u2019s a problem,\u201d says CTO Melonee Wise. Wise is cautious about whether humanoids will be widely adopted in workplaces. \u201cI\u2019ve always been a pessimist,\u201d she says. That\u2019s because getting robots to work well in a lab is one thing, but integrating them into a bustling warehouse full of people and forklifts moving goods on tight deadlines is another task entirely.  If 2024 was the year of unsettling humanoid product launch videos, this year we will see those humanoids put to the test, and we\u2019ll find out whether they\u2019ll be as productive for paying customers as promised. Now that Agility\u2019s robots have been deployed in fast-paced customer facilities, it\u2019s clear that small problems can really add up.\u00a0 Then there are issues with how robots and humans share spaces. In the GXO facility the two work in completely separate areas, Wise says, but there are cases where, for example, a human worker might accidentally leave something obstructing a charging station. That means Agility\u2019s robots can\u2019t return to the dock to charge, so they need to alert a human employee to move the obstruction out of the way, slowing operations down.\u00a0\u00a0 It\u2019s often said that robots don\u2019t call out sick or need health care. But this year, as fleets of humanoids arrive on the job, we\u2019ll begin to find out the limitations they do have. Learning from imagination The way we teach robots how to do things is changing rapidly. It used to be necessary to break their tasks down into steps with specifically coded instructions, but now, thanks to AI, those instructions can be gleaned from observation. Just as ChatGPT was taught to write through exposure to trillions of sentences rather than by explicitly learning the rules of grammar, robots are learning through videos and demonstrations.",
    "That poses a big question: Where do you get all these videos and demonstrations for robots to learn from? Nvidia, the world\u2019s most valuable company, has long aimed to meet that need with simulated worlds, drawing on its roots in the video-game industry. It creates worlds in which roboticists can expose digital replicas of their robots to new environments to learn. A self-driving car can drive millions of virtual miles, or a factory robot can learn how to navigate in different lighting conditions. In December, the company went a step further, releasing what it\u2019s calling a \u201cworld foundation model.\u201d Called Cosmos, the model has learned from 20 million hours of video\u2014the equivalent of watching YouTube nonstop since Rome was at war with Carthage\u2014that can be used to generate synthetic training data. Related StoryOpenAI has upped its lobbying efforts nearly sevenfoldThe firm's spending makes clear how much it wants to shape the new rules around government AI policy.",
    "Here\u2019s an example of how this model could help in practice. Imagine you run a robotics company that wants to build a humanoid that cleans up hospitals. You can start building this robot\u2019s \u201cbrain\u201d with a model from Nvidia, which will give it a basic understanding of physics and how the world works, but then you need to help it figure out the specifics of how hospitals work. You could go out and take videos and images of the insides of hospitals, or pay people to wear sensors and cameras while they go about their work there.  \u201cBut those are expensive to create and time consuming, so you can only do a limited number of them,\u201d says Rev Lebaredian, vice president of simulation technologies at Nvidia. Cosmos can instead take a handful of those examples and create a three-dimensional simulation of a hospital. It will then start making changes\u2014different floor colors, different sizes of hospital beds\u2014and create slightly different environments. \u201cYou\u2019ll multiply that data that you captured in the real world millions of times,\u201d Lebaredian says. In the process, the model will be fine-tuned to work well in that specific hospital setting.\u00a0 It\u2019s sort of like learning both from your experiences in the real world and from your own imagination (stipulating that your imagination is still bound by the rules of physics).\u00a0 Teaching robots through AI and simulations isn\u2019t new, but it\u2019s going to become much cheaper and more powerful in the years to come.\u00a0 A smarter brain gets a smarter body Plenty of progress in robotics has to do with improving the way a robot senses and plans what to do\u2014its \u201cbrain,\u201d in other words. Those advancements can often happen faster than those that improve a robot\u2019s \u201cbody,\u201d which determine how well a robot can move through the physical world, especially in environments that are more chaotic and unpredictable than controlled assembly lines.",
    "The military has always been keen on changing that and expanding the boundaries of what\u2019s physically possible. The US Navy has been testing machines from a company called Gecko Robotics that can navigate up vertical walls (using magnets) to do things like infrastructure inspections, checking for cracks, flaws, and bad welding on aircraft carriers.\u00a0 There are also investments being made for the battlefield. While nimble and affordable drones have reshaped rural battlefields in Ukraine, new efforts are underway to bring those drone capabilities indoors. The defense manufacturer Xtend received an $8.8 million contract from the Pentagon in December 2024 for its drones, which can navigate in confined indoor spaces and urban environments. These so-called \u201cloitering munitions\u201d are one-way attack drones carrying explosives that detonate on impact.",
    "\u201cThese systems are designed to overcome challenges like confined spaces, unpredictable layouts, and GPS-denied zones,\u201d says Rubi Liani, cofounder and CTO at Xtend. Deliveries to the Pentagon should begin in the first few months of this year.\u00a0 Another initiative\u2014sparked in part by the Replicator project, the Pentagon\u2019s plan to spend more than $1 billion on small unmanned vehicles\u2014aims to develop more autonomously controlled submarines and surface vehicles. This is particularly of interest as the Department of Defense focuses increasingly on the possibility of a future conflict in the Pacific between China and Taiwan. In such a conflict, the drones that have dominated the war in Ukraine would serve little use because battles would be waged almost entirely at sea, where small aerial drones would be limited by their range. Instead, undersea drones would play a larger role. All these changes, taken together, point toward a future where robots are more flexible in how they learn, where they work, and how they move.\u00a0 Jan Liphardt from Stanford thinks the next frontier of this transformation will hinge on the ability to instruct robots through speech. Large language models\u2019 ability to understand and generate text has already made them a sort of translator between Liphardt and his robot. \u201cWe can take one of our quadrupeds and we can tell it, \u2018Hey, you\u2019re a dog,\u2019 and the thing wants to sniff you and tries to bark,\u201d he says. \u201cThen we do one word change\u2014\u2018You\u2019re a cat.\u2019 Then the thing meows and, you know, runs away from dogs. And we haven\u2019t changed a single line of code.\u201d Correction: A previous version of this story incorrectly stated that the robotics company Eliza Wakes Up has ties to a16z.  hide"
  ]
}