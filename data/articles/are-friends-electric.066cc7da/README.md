# Are friends electric?

[https://www.technologyreview.com/2025/02/25/1111767/book-reviews-ai-robots-automation-eve-herold-sarah-a-bell-antonio-casilli/](https://www.technologyreview.com/2025/02/25/1111767/book-reviews-ai-robots-automation-eve-herold-sarah-a-bell-antonio-casilli/)

*05:15 AM, Tuesday, February 25, 2025*

To the best of my knowledge, I am not a robot. And yet, like other humans who spend too much time on the internet, I’m routinely asked to prove this fact by clicking on crosswalks and motorcycles in photos, deciphering distorted numbers and letters, and checking little white boxes that affirm my non-robot status. These so-called captchas, or “completely automated public Turing tests to tell computers and humans apart,” are supposed to help prevent spam and data scraping, although it now appears that bots are better at solving them than humans. Go figure.  Thankfully, the difference between humans and machines in the real world is much easier to discern, at least for now. One of the more robust differentiators involves our unique skill sets. While machines tend to excel at things adults find difficult—playing world-champion-level chess, say, or multiplying really big numbers—they find it difficult (or impossible) to accomplish the stuff a five-year-old can do with ease, such as catching a ball or walking around a room without bumping into things.  Related StoryWill we ever trust robots?If most robots still need remote human operators to be safe and effective, why should we welcome them into our homes?

This discrepancy between the relative ease of teaching a machine abstract thinking and the difficulty of teaching it basic sensory, social, and motor skills is what’s known as Moravec’s paradox. Named after an observation the roboticist Hans Moravec made back in the late 1980s, the paradox states that what’s hard for humans (math, logic, scientific reasoning) is easy for machines, and what’s hard for machines (tying shoelaces, reading emotions, having a conversation) is easy for humans.  In her latest book, Robots and the People Who Love Them: Holding On to Our Humanity in an Age of Social Robots, science writer Eve Herold argues that thanks to new approaches in machine learning and continued advances in AI, we’re finally starting to unravel this paradox. As a result, a new era of personal and social robots is about to unfold, she says—one that will force us to reimagine the nature of everything from friendship and love to work, health care, and home life.

Robots and the People Who Love Them: Holding On to Our Humanity in an Age of Social RobotsEve HeroldST. MARTIN’S PRESS, 2024   To give readers a sense of what this brave new world of social robots will look like, Herold points us toward Pepper, a doe-eyed humanoid robot that’s made by the Japanese company SoftBank. “Robots like Pepper will soon make themselves indispensable because of their unique, highly personalized relationships with us,” Herold writes, before describing with press-release-like zeal how this chest-high companion can effortlessly read our expressions and emotional states and respond appropriately in its own childlike voice.  If Pepper sounds vaguely familiar, it may be because it was relentlessly hyped as the world’s first “emotional robot” in the years following its 2014 introduction. That abruptly stopped in 2021, however, when SoftBank pulled the plug on Pepper production because of lack of demand and—probably not unrelatedly—the $2,000 android’s general incompetence. Books can obviously take a long time to write, and a lot can change while you’re writing them. But it’s hard to reconcile this particular oversight with the fact that Pepper was canned some three years before the book’s publication.

Positioning a defunct product that nobody seems to have liked or bought as part of some vanguard for a new social-­robot revolution doesn’t inspire confidence. Herold might respond by pointing out that her book’s focus is less on the robots themselves than on what we humans will bring to the new social relationships we forge with them. Fair enough.  But while she dutifully unpacks our penchant for anthropomorphizing and walks readers through some rudimentary research on deep learning and the uncanny valley, Herold’s conclusions about human nature and psychology often seem either oversimplified or divorced from the evidence she provides. For someone who says that “the only way to write about the future is with a high degree of humility,” there are also an unusually large number of deeply questionable assertions (“So far, the trust we’ve placed in algorithms has been, on balance, well placed …”) and sweeping predictions (“There’s no doubt some version of a companion robot will be coming soon to homes throughout the industrialized world”).    Early on in the book, Herold reminds readers that “science writing that attempts to envision the future often says much more about the time it was written than it says about the future world.” In this respect, Robots and the People Who Love Them is indeed quite revealing. Among other things, the book reflects the way we tend to reduce discussions of technological impacts into binary terms (“It’ll be amazing”/”It’ll be terrible”); the shrugging acquiescence with which we seem to regard undesirable outcomes; the readiness of science and technology writers to succumb to industry hype; and the disturbing extent to which the logic and values of machines (speed, efficiency) have already been adopted by humans. It’s probably not one of Herold’s intended takeaways, but if the book demonstrates anything, it’s not that robots are becoming more like us; it’s that we’re becoming more like them.   Vox ex Machina: A Cultural History of Talking MachinesSarah A. BellMIT PRESS, 2024   For a more rigorous look at one of the pillars of human social expression—and, specifically, how we’ve tried to transfer it to machines—Sarah A. Bell’s Vox ex Machina: A Cultural History of Talking Machines offers a compelling and insightful history of voice synthesis during the 20th century. Bell, a writer and professor at Michigan Technological University, is interested in how we try to digitally reproduce different expressions of human embodiment, be it speech, emotions, or visual identities. As she points out early on in the book, understanding this process often means understanding the ways in which engineers (almost universally male ones) have decided to measure and quantify aspects of our bodies.  The story begins at the epicenter for many of the century’s most important technological breakthroughs: Bell Labs. By the 1930s, researchers there were already thinking about human speech as a type of signal or, as the head of the acoustics research department put it years later, “specialized acoustic code.” One of those engineers, Homer Dudley, likened the tongue to a telegraph tapper, seeing it as merely an instrument inside our mouths that “modulated the ‘carrier wave’ emanating from the glottis.” In the same way that Morse code broke down writing into parts for later reassembly, Dudley believed, speech sounds—and everything else that makes up the richness of human vocal expression—could similarly be compressed, or reduced to pulses. According to Bell, researchers like Dudley laid the groundwork for pretty much all the voice synthesis work that has come since, “embedding their assumptions about the mechanical nature of the human voice in all the technologies that would follow.” One of the first and most famous examples of Dudley’s work was the Voder, or Voice Demonstrator. Debuting at the 1939 World’s Fair in New York, it was basically a small voice organ that was operated by “Voderettes,” women who went through a year of training to master all the speech sounds the machine could make by manipulating 10 keys, a wrist plate, and a pedal.   Debuting at the 1939 World’s Fair in New York, the Voder was a small voice organ operated by “Voderettes,” women trained to master the machine’s speech soundsCOLLECTIONS OF THE NEW YORK PUBLIC LIBRARY   The talking-machine demonstrations, although highly choreographed, were a hit with visitors and the press—so much so that people seemed willing to attribute far more understanding and autonomy to the Voder than was warranted. Even though the Voderette was in full view during the entire demonstration, the press usually mentioned the woman responsible for making the sounds only in passing, if at all. Instead, the Voder was anthropomorphized and granted a high degree of agency. “He hasn’t any mouth, lungs, or larynx—but he talks a blue streak,” wrote Popular Science.  Related StoryHow cuddly robots could change dementia careResearchers are using AI and technological advancements to create companion robots

From the Voder and Elektro the Moto-Man to Speak & Spell and Perfect Paul to Alexa and Siri, Vox ex Machina showcases both the products of voice synthesis and the underlying technologies that made them possible. It’s a fascinating tour, particularly when Bell focuses on the ways in which the public’s reaction to these “talking machines” presaged its reaction to the “thinking” ones that would emerge decades later. While the practice of describing humans with machine metaphors and machines with human metaphors dates back centuries, the ability of machines to simulate human speech (however poorly) “gave machinic personification a new inflection,” writes Bell.

In other words, the more machines could “speak” and “think,” the more we started to think of ourselves as machines. Indeed, one can’t help but see striking parallels to what’s happening with today’s artificial intelligence—specifically, our willingness to reduce or minimize what makes us human to better conform to whatever “intelligent” attribute a product may be demonstrating. Sam Altman’s response to the fact that LLMs are just really good word calculators? “i am a stochastic parrot, and so r u.”  “Forget about losing jobs to automation. Remarkably, the reality is that humans steal the jobs of robots.”  The Voder may have been one of the first crude attempts at speech synthesis, but the disconnect between the way it worked (with a lot of human training and labor) and the way the public and press perceived it (as a more or less autonomous machine with its own voice) foreshadowed a problem we still face today. In Waiting for Robots: The Hired Hands of Automation, Antonio A. Casilli argues that despite claims to the contrary, human input remains a crucial component of all modern automation and artificial-intelligence tools, regardless of their sophistication. The difference is that instead of this role being obvious—as was the case with the Voderettes—it’s now hidden, and usually on purpose.  Waiting for Robots: The Hired Hands of AutomationAntonio A. CasilliUNIVERSITY OF CHICAGO PRESS, 2024   Casilli is a sociology professor at the Polytechnic Institute of Paris who studies the unseen and unacknowledged “digital labor” that undergirds many of today’s social media platforms, microtask sites, and on-demand services. Rather than viewing automation and AI as destroyers of human jobs, he makes a convincing case that they merely result in the further atomization of work, fracturing it into smaller, more meaningless, more demeaning tasks for many of us. “Forget about losing jobs to automation,” he writes. “Remarkably, the reality is that humans steal the jobs of robots.” Whether it’s Amazon’s Mechanical Turk, a service for recruiting hundreds of thousands of micro-taskers to perform video-filtering and image-tagging tasks that machines can’t do, or the perpetual human “supervision” and “reinforcement” required for automated learning and AI training, Casilli gives readers plenty of examples of how human labor (much of it coming from Asian, Latin American, and African countries) props up—or, in some cases, pretends to actually be—intelligent systems and products. Related StoryCongress used to evaluate emerging technologies. Let’s do it again.A look back at the Office of Technology Assessment, the Congressional think tank that detected lies and tested tech.

Ultimately, Casilli is less concerned that robots will replace white-collar workers, and more worried that thousands of lower-paid or unpaid digital workers will. As he points out, we are already unwittingly being recruited by companies to collectively perform millions of hours of free work every year. Take the aforementioned captchas: Google, which owns and deploys one of the most popular versions of the service (ReCAPTCHA and No CAPTCHA), has been using this digital labor for more than a decade. The results help detect house numbers to improve Google Street View, digitize texts for Google Books, and train its computer vision algorithms to detect locations and reconstruct scenes, enhancing Google Images and improving the performance of Waymo’s self-driving cars. “The irony here is that a service that is supposed to distinguish humans from robots is actually making humans work to produce more robots,” Casilli writes. While all the hype and hyperbole surrounding today’s AI tools can feel unprecedented, Casilli reminds readers that such rhetoric isn’t really new at all. Robots, automation, and various intelligent systems have been just on the verge of taking over all aspects of our work lives and cultural output for decades now. In the end, artificial intelligence is a technological process that isn’t actually artificial, he says. Peer behind the curtains of smooth and seamless efficiency, and it’s humans all the way down. Bryan Gardiner is a writer based in Oakland, California. hide

