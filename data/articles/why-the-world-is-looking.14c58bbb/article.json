{
  "url": "https://www.technologyreview.com/2025/03/25/1113696/why-the-world-is-looking-to-ditch-us-ai-models/",
  "title": "Why the world is looking to ditch US AI models",
  "ut": 1742859000.0,
  "body_paragraphs": [
    "A few weeks ago, when I was at the digital rights conference RightsCon in Taiwan, I watched in real time as civil society organizations from around the world, including the US, grappled with the loss of one of the biggest funders of global digital rights work: the United States government. As I wrote in my dispatch, the Trump administration's shocking, rapid gutting of the US government (and its push into what some prominent political scientists call \u201ccompetitive authoritarianism\u201d) also affects the operations and policies of American tech companies\u2014many of which, of course, have users far beyond US borders. People at RightsCon said they were already seeing changes in these companies\u2019 willingness to engage with and invest in communities that have smaller user bases\u2014especially non-English-speaking ones.\u00a0  As a result, some policymakers and business leaders\u2014in Europe, in particular\u2014are reconsidering their reliance on US-based tech and asking whether they can quickly spin up better, homegrown alternatives. This is particularly true for AI. One of the clearest examples of this is in social media. Yasmin Curzi, a Brazilian law professor who researches domestic tech policy, put it to me this way: \u201cSince Trump\u2019s second administration, we cannot count on [American social media platforms] to do even the bare minimum anymore.\u201d",
    "Social media content moderation systems\u2014which already use automation and are also experimenting with deploying large language models to flag problematic posts\u2014are failing to detect gender-based violence in places as varied as India, South Africa, and Brazil. If platforms begin to rely even more on LLMs for content moderation, this problem will likely get worse, says Marlena Wisniak, a human rights lawyer who focuses on AI governance at the European Center for Not-for-Profit Law. \u201cThe LLMs are moderated poorly, and the poorly moderated LLMs are then also used to moderate other content,\u201d she tells me. \u201cIt\u2019s so circular, and the errors just keep repeating and amplifying.\u201d\u00a0 Part of the problem is that the systems are trained primarily on data from the English-speaking world (and American English at that), and as a result, they perform less well with local languages and context.",
    "Even multilingual language models, which are meant to process multiple languages at once, still perform poorly with non-Western languages. For instance, one evaluation of ChatGPT\u2019s response to health-care queries found that results were far worse in Chinese and Hindi, which are less well represented in North American data sets, than in English and Spanish.\u00a0\u00a0\u00a0 For many at RightsCon, this validates their calls for more community-driven approaches to AI\u2014both in and out of the social media context. These could include small language models, chatbots, and data sets designed for particular uses and specific to particular languages and cultural contexts. These systems could be trained to recognize slang usages and slurs, interpret words or phrases written in a mix of languages and even alphabets, and identify \u201creclaimed language\u201d (onetime slurs that the targeted group has decided to embrace). All of these tend to be missed or miscategorized by language models and automated systems trained primarily on Anglo-American English. The founder of the startup Shhor AI, for example, hosted a panel at RightsCon and talked about its new content moderation API focused on Indian vernacular languages. Many similar solutions have been in development for years\u2014and we\u2019ve covered a number of them, including a Mozilla-facilitated volunteer-led effort to collect training data in languages other than English, and promising startups like Lelapa AI, which is building AI for African languages. Earlier this year, we even included small language models on our 2025 list of top 10 breakthrough technologies.\u00a0 Still, this moment feels a little different. The second Trump administration, which shapes the actions and policies of American tech companies, is obviously a major factor. But there are others at play.\u00a0 Related StoryAt RightsCon in Taipei, activists reckon with a US retreat from promoting digital rights\u00a0The United States government has gone from taking the leading role in supporting an open and safe internet to demonstrating how to dismantle it.",
    "First, recent research and development on language models has reached the point where data set size is no longer a predictor of performance, meaning that more people can create them. In fact, \u201csmaller language models might be worthy competitors of multilingual language models in specific, low-resource languages,\u201d says Aliya Bhatia, a visiting fellow at the Center for Democracy & Technology who researches automated content moderation.\u00a0 Then there\u2019s the global landscape. AI competition was a major theme of the recent Paris AI Summit, which took place the week before RightsCon. Since then, there\u2019s been a steady stream of announcements about \u201csovereign AI\u201d initiatives that aim to give a country (or organization) full control over all aspects of AI development.\u00a0 AI sovereignty is just one part of the desire for broader \u201ctech sovereignty\u201d that\u2019s also been gaining steam, growing out of more sweeping concerns about the privacy and security of data transferred to the United States. The European Union appointed its first commissioner for tech sovereignty, security, and democracy last November and has been working on plans for a \u201cEuro Stack,\u201d or \u201cdigital public infrastructure.\u201d The definition of this is still somewhat fluid, but it could include the energy, water, chips, cloud services, software, data, and AI needed to support modern society and future innovation. All these are largely provided by US tech companies today. Europe\u2019s efforts are partly modeled after \u201cIndia Stack,\u201d that country\u2019s digital infrastructure that includes the biometric identity system Aadhaar. Just last week, Dutch lawmakers passed several motions to untangle the country from US tech providers.\u00a0 This all fits in with what Andy Yen, CEO of the Switzerland-based digital privacy company Proton, told me at RightsCon. Trump, he said, is \u201ccausing Europe to move faster \u2026 to come to the realization that Europe needs to regain its tech sovereignty.\u201d This is partly because of the leverage that the president has over tech CEOs, Yen said, and also simply \u201cbecause tech is where the future economic growth of any country is.\u201d",
    "But just because governments get involved doesn\u2019t mean that issues around inclusion in language models will go away. \u201cI think there needs to be guardrails about what the role of the government here is. Where it gets tricky is if the government decides \u2018These are the languages we want to advance\u2019 or \u2018These are the types of views we want represented in a data set,\u2019\u201d Bhatia says. \u201cFundamentally, the training data a model trains on is akin to the worldview it develops.\u201d\u00a0 It\u2019s still too early to know what this will all look like, and how much of it will prove to be hype. But no matter what happens, this is a space we\u2019ll be watching. This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,\u00a0sign up here. hide"
  ]
}