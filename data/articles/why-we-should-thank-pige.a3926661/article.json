{
  "url": "https://www.technologyreview.com/2025/08/18/1121370/ai-pigeons-reinforcement-learning/",
  "title": "Why we should thank pigeons for our AI breakthroughs",
  "ut": 1755477000.0,
  "body_paragraphs": [
    "In 1943, while the world\u2019s brightest physicists split atoms for the Manhattan Project, the American psychologist B.F. Skinner led his own secret government project to win World War II.\u00a0 Skinner did not aim to build a new class of larger, more destructive weapons. Rather, he wanted to make conventional bombs more precise. The idea struck him as he gazed out the window of his train on the way to an academic conference. \u201cI saw a flock of birds lifting and wheeling in formation as they flew alongside the train,\u201d he wrote. \u201cSuddenly I saw them as \u2018devices\u2019 with excellent vision and maneuverability. Could they not guide a missile?\u201d  Skinner started his missile research with crows, but the brainy black birds proved intractable. So he went to a local shop that sold pigeons to Chinese restaurants, and \u201cProject Pigeon\u201d was born. Though ordinary pigeons, Columba livia, were no one\u2019s idea of clever animals, they proved remarkably cooperative subjects in the lab. Skinner rewarded the birds with food for pecking at the right target on aerial photographs\u2014and eventually planned to strap the birds into a device in the nose of a warhead, which they would steer by pecking at the target on a live image projected through a lens onto a screen.\u00a0 The military never deployed Skinner\u2019s kamikaze pigeons, but his experiments convinced him that the pigeon was \u201can extremely reliable instrument\u201d for studying the underlying processes of learning. \u201cWe have used pigeons, not because the pigeon is an intelligent bird, but because it is a practical one and can be made into a machine,\u201d he said in 1944. Related StoryAI is changing how we study bird migrationAfter decades of frustration, machine-learning tools are unlocking a treasure trove of acoustic data for ecologists.",
    "People looking for precursors to artificial intelligence often point to science fiction by authors like Isaac Asimov or thought experiments like the Turing test. But an equally important, if surprising and less appreciated, forerunner is Skinner\u2019s research with pigeons in the middle of the 20th century. Skinner believed that association\u2014learning, through trial and error, to link an action with a punishment or reward\u2014was the building block of every behavior, not just in pigeons but in all living organisms, including human beings. His \u201cbehaviorist\u201d theories fell out of favor with psychologists and animal researchers in the 1960s but were taken up by computer scientists who eventually provided the foundation for many of the artificial-intelligence tools from leading firms like Google and OpenAI. \u00a0 These companies\u2019 programs are increasingly incorporating a kind of machine learning whose core concept\u2014reinforcement\u2014is taken directly from Skinner\u2019s school of psychology and whose main architects, the computer scientists Richard Sutton and Andrew Barto, won the 2024 Turing Award, an honor widely considered to be the Nobel Prize of computer science. Reinforcement learning has helped enable computers to drive cars, solve complex math problems, and defeat grandmasters in games like chess and Go\u2014but it has not done so by emulating the complex workings of the human mind. Rather, it has supercharged the simple associative processes of the pigeon brain.",
    "It\u2019s a \u201cbitter lesson\u201d of 70 years of AI research, Sutton has written: that human intelligence has not worked as a model for machine learning\u2014instead, the lowly principles of associative learning are what power the algorithms that can now simulate or outperform humans on a variety of tasks. If artificial intelligence really is close to throwing off the yoke of its creators, as many people fear, then our computer overlords may be less like ourselves than like \u201crats with wings\u201d\u2014and planet-size brains. And even if it\u2019s not, the pigeon brain can at least help demystify a technology that many worry (or rejoice) is \u201cbecoming human.\u201d\u00a0 In turn, the recent accomplishments of AI are now prompting some animal researchers to rethink the evolution of natural intelligence. Johan Lind, a biologist at Stockholm University, has written about the \u201cassociative learning paradox,\u201d wherein the process is largely dismissed by biologists as too simplistic to produce complex behaviors in animals but celebrated for producing humanlike behaviors in computers. The research suggests not only a greater role for associative learning in the lives of intelligent animals like chimpanzees and crows, but also far greater complexity in the lives of animals we\u2019ve long dismissed as simple-minded, like the ordinary Columba livia.",
    "When Sutton began working in AI, he felt as if he had a \u201csecret weapon,\u201d he told me: He had studied psychology as an undergrad. \u201cI was mining the psychological literature for animals,\u201d he says.  Skinner started his missile research with crows but switched to pigeons when the brainy black birds proved intractable.B.F. SKINNER FOUNDATION   Ivan Pavlov began to uncover the mechanics of associative learning at the end of the 19th century in his famous experiments on \u201cclassical conditioning,\u201d which showed that dogs would salivate at a neutral stimulus\u2014like a bell or flashing light\u2014if it was paired predictably with the presentation of food. In the middle of the 20th century, Skinner took Pavlov\u2019s principles of conditioning and extended them from an animal\u2019s involuntary reflexes to its overall behavior.\u00a0  Skinner wrote that \u201cbehavior is shaped and maintained by its consequences\u201d\u2014that a random action with desirable results, like pressing a lever that releases a food pellet, will be \u201creinforced\u201d so that the animal is likely to repeat it. Skinner reinforced his lab animals\u2019 behavior step by step, teaching rats to manipulate marbles and pigeons to play simple tunes on four-key pianos. The animals learned chains of behavior, through trial and error, in order to maximize long-term rewards. Skinner argued that this type of associative learning, which he called \u201coperant conditioning\u201d (and which other psychologists had called \u201cinstrumental learning\u201d), was the building block of all behavior. He believed that psychology should study only behaviors that could be observed and measured without ever making reference to an \u201cinner agent\u201d in the mind.  When Richard Sutton began working in AI, he felt as if he had a \u201csecret weapon\u201d: He studied psychology as an undergrad. \u201cI was mining the psychological literature for animals,\u201d he says.  Skinner thought that even human language developed through operant conditioning, with children learning the meanings of words through reinforcement. But his 1957 book on the subject, Verbal Behavior, provoked a brutal review from Noam Chomsky, and psychology\u2019s focus started to swing from observable behavior to innate \u201ccognitive\u201d abilities of the human mind, like logic and symbolic thinking. Biologists soon rebelled against behaviorism also, attacking psychologists\u2019 quest to explain the diversity of animal behavior through an elementary and universal mechanism. They argued that each species evolved specific behaviors suited to its habitat and lifestyle, and that most behaviors were inherited, not learned.\u00a0 By the \u201970s, when Sutton started reading about Skinner\u2019s and similar experiments, many psychologists and researchers interested in intelligence had moved on from pea-brained pigeons, which learn mostly by association, to large-brained animals with more sophisticated behaviors that suggested potential cognitive abilities. \u201cThis was clearly old stuff that was not exciting to people anymore,\u201d he told me. Still, Sutton found these old experiments instructive for machine learning: \u201cI was coming to AI with an animal-learning-theorist mindset and seeing the big lack of anything like instrumental learning in engineering.\u201d\u00a0  Many engineers in the second half of the 20th century tried to model AI on human intelligence, writing convoluted programs that attempted to mimic human thinking and implement rules that govern human response and behavior. This approach\u2014commonly called \u201csymbolic AI\u201d\u2014was severely limited; the programs stumbled over tasks that were easy for people, like recognizing objects and words. It just wasn\u2019t possible to write into code the myriad classification rules human beings use to, say, separate apples from oranges or cats from dogs\u2014and without pattern recognition, breakthroughs in more complex tasks like problem solving, game playing, and language translation seemed unlikely too. These computer scientists, the AI skeptic Hubert Dreyfus wrote in 1972, accomplished nothing more than \u201ca small engineering triumph, an ad hoc solution of a specific problem, without general applicability.\u201d",
    "Advertisement Pigeon research, however, suggested another route. A 1964 study showed that pigeons could learn to discriminate between photographs with people and photographs without people. Researchers simply presented the birds with a series of images and rewarded them with a food pellet for pecking an image showing a person. They pecked randomly at first but quickly learned to identify the right images, including photos where people were partially obscured. The results suggested that you didn\u2019t need rules to sort objects; it was possible to learn concepts and use categories through associative learning alone.\u00a0  In another Skinner experiment, a pigeon receives food after correctly matching a colored light to a corresponding colored panel.GETTY IMAGES   When Sutton began working with Barto on AI in the late \u201970s, they wanted to create a \u201ccomplete, interactive goal-seeking agent\u201d that could explore and influence its environment like a pigeon or rat. \u201cWe always felt the problems we were studying were closer to what animals had to face in evolution to actually survive,\u201d Barto told me. The agent needed two main functions: search, to try out and choose from many actions in a situation, and memory, to associate an action with the situation where it resulted in a reward. Sutton and Barto called their approach \u201creinforcement learning\u201d; as Sutton said, \u201cIt\u2019s basically instrumental learning.\u201d In 1998, they published the definitive exploration of the concept in a book, Reinforcement Learning: An Introduction.\u00a0 Over the following two decades, as computing power grew exponentially, it became possible to train AI on increasingly complex tasks\u2014that is, essentially, to run the AI \u201cpigeon\u201d through millions more trials.\u00a0 Programs trained with a mix of human input and reinforcement learning defeated human experts at chess and Atari. Then, in 2017, engineers at Google DeepMind built the AI program AlphaGo Zero entirely through reinforcement learning, giving it a numerical reward of +1 for every game of Go that it won and \u22121 for every game that it lost. Programmed to seek the maximum reward, it began without any knowledge of Go but improved over 40 days until it attained what its creators called \u201csuperhuman performance.\u201d Not only could it defeat the world\u2019s best human players at Go, a game considered even more complicated than chess, but it actually pioneered new strategies that professional players now use.",
    "Related StoryHow machine learning is helping us probe the secret names of animalsYou can add marmoset monkeys to the list of species that use \u201cnames.\u201d But whether animals have anything more to say remains unknown.",
    "\u201cHumankind has accumulated Go knowledge from millions of games played over thousands of years,\u201d the program\u2019s builders wrote in Nature in 2017. \u201cIn the space of a few days, starting tabula rasa, AlphaGo Zero was able to rediscover much of this Go knowledge, as well as novel strategies that provide new insights into the oldest of games.\u201d The team\u2019s lead researcher was David Silver, who studied reinforcement learning under Sutton at the University of Alberta. Today, more and more tech companies have turned to reinforcement learning in products such as consumer-facing chatbots and agents. The first generation of generative AI, including large language models like OpenAI\u2019s GPT-2 and GPT-3, tapped into a simpler form of associative learning called \u201csupervised learning,\u201d which trained the model on data sets that had been labeled by people. Programmers often used reinforcement to fine-tune their results by asking people to rate a program\u2019s performance and then giving these ratings back to the program as goals to pursue. (Researchers call this \u201creinforcement learning from feedback.\u201d)\u00a0 Then, last fall, OpenAI revealed its o-series of large language models, which it classifies as \u201creasoning\u201d models. The pioneering AI firm boasted that they are \u201ctrained with reinforcement learning to perform reasoning\u201d and claimed they are capable of \u201ca long internal chain of thought.\u201d The Chinese startup DeepSeek also used reinforcement learning to train its attention-grabbing \u201creasoning\u201d LLM, R1. \u201cRather than explicitly teaching the model on how to solve a problem, we simply provide it with the right incentives, and it autonomously develops advanced problem-\u00adsolving strategies,\u201d they explained. These descriptions might impress users, but at least psychologically speaking, they are confused. A computer trained on reinforcement learning needs only search and memory, not reasoning or any other cognitive mechanism, in order to form associations and maximize rewards. Some computer scientists have criticized the tendency to anthropomorphize these models\u2019 \u201cthinking,\u201d and a team of Apple engineers recently published a paper noting their failure at certain complex tasks and \u201craising crucial questions about their true reasoning capabilities.\u201d",
    "Sutton, too, dismissed the claims of reasoning as \u201cmarketing\u201d in an email, adding that \u201cno serious scholar of mind would use \u2018reasoning\u2019 to describe what is going on in LLMs.\u201d Still, he has argued, with Silver and other coauthors, that the pigeons\u2019 method\u2014learning, through trial and error, which actions will yield rewards\u2014is \u201cenough to drive behavior that exhibits most if not all abilities that are studied in natural and artificial intelligence,\u201d including human language \u201cin its full richness.\u201d\u00a0 In a paper published in April, Sutton and Silver stated that \u201ctoday\u2019s technology, with appropriately chosen algorithms, already provides a sufficiently powerful foundation to \u2026 rapidly progress AI towards truly superhuman agents.\u201d The key, they argue, is building AI agents that depend less than LLMs on human dialogue and prejudgments to inform their behavior.\u00a0  \u201cPowerful agents should have their own stream of experience that progresses, like humans, over a long time-scale,\u201d they wrote. \u201cUltimately, experiential data will eclipse the scale and quality of human generated data. This paradigm shift, accompanied by algorithmic advancements in RL, will unlock in many domains new capabilities that surpass those possessed by any human.\u201d  If computers can do all that with just a pigeonlike brain, some animal researchers are now wondering if actual pigeons deserve more credit than they\u2019re commonly given.\u00a0  \u201cWhen considered in light of the accomplishments of AI, the extension of associative learning to purportedly more complicated forms of cognitive performance offers fresh prospects for understanding how biological systems may have evolved,\u201d Ed Wasserman, a psychologist at the University of Iowa, wrote in a recent study in the journal Current Biology.\u00a0  Wasserman trained pigeons to succeed at a complex categorization task, which several undergraduate students failed. The students tried to find a rule that would help them sort various discs; the pigeons simply developed a sense for the group to which any given disc belonged.  In one experiment, Wasserman trained pigeons to succeed at a complex categorization task, which several undergraduate students failed. The students tried, in vain, to find a rule that would help them sort various discs with parallel black lines of various widths and tilts; the pigeons simply developed a sense, through practice and association, for the group to which any given disc belonged.",
    "Like Sutton, Wasserman became interested in behaviorist psychology when Skinner\u2019s theories were out of fashion. He didn\u2019t switch to computer science, however: He stuck with pigeons. \u201cThe pigeon lives or dies by these really rudimentary learning rules,\u201d Wasserman told me recently, \u201cbut they are powerful enough to have succeeded colossally in object recognition.\u201d In his most famous experiments, Wasserman trained pigeons to detect cancerous tissue and symptoms of heart disease in medical scans as accurately as experienced doctors with framed diplomas behind their desks. Given his results, Wasserman found it odd that so many psychologists and ethologists regarded associative learning as a crude, mechanical mechanism, incapable of producing the intelligence of clever animals like apes, elephants, dolphins, parrots, and crows.\u00a0 Other researchers also started to reconsider the role of associative learning in animal behavior after AI started besting human professionals in complex games. \u201cWith the progress of artificial intelligence, which in essence is built upon associative processes, it is increasingly ironic that associative learning is considered too simple and insufficient for generating biological intelligence,\u201d Lind, the biologist from Stockholm University, wrote in 2023. He often cites Sutton and Barto\u2019s computer science in his biological research, and he believes it\u2019s human beings\u2019 symbolic language and cumulative cultures that really put them in a cognitive category of their own.",
    "Ethologists generally propose cognitive mechanisms, like theory of mind (that is, the ability to attribute mental states to others), to explain remarkable animal behaviors like social learning and tool use. But Lind has built models showing that these flexible behaviors could have developed through associative learning, suggesting that there may be no need to invoke cognitive mechanisms at all. If animals learn to associate a behavior with a reward, then the behavior itself will come to approximate the value of the reward. A new behavior can then become associated with the first behavior, allowing the animal to learn chains of actions that ultimately lead to the reward. In Lind\u2019s view, studies demonstrating self-control and planning in chimpanzees and ravens are probably describing behaviors acquired through experience rather than innate mechanisms of the mind. \u00a0 Related StoryA Google Gemini model now has a \u201cdial\u201d to adjust how much it reasonsReasoning is AI\u2019s new frontier, but Google\u2019s move hints at a growing and expensive problem: Models overthink for no good reason.",
    "Lind has been frustrated with what he calls the \u201clow standard that is accepted in animal cognition studies.\u201d As he wrote in an email, \u201cMany researchers in this field do not seem to worry about excluding alternative hypotheses and they seem happy to neglect a lot of current and historical knowledge.\u201d There are some signs, though, that his arguments are catching on. A group of psychologists not affiliated with Lind referenced his \u201cassociative learning paradox\u201d last year in a criticism of a Current Biology study, which purported to show that crows used \u201ctrue statistical inference\u201d and not \u201clow-level associative learning strategies\u201d in an experiment. The psychologists found that they could explain the crows\u2019 performance with a simple reinforcement-\u00adlearning model\u2014\u201cexactly the kind of low-level associative learning process that [the original authors] ruled out.\u201d\u00a0 Skinner might have felt vindicated by such arguments. He lamented psychology\u2019s cognitive turn until his death in 1990, maintaining that it was scientifically irresponsible to probe the minds of living beings. After \u201cProject Pigeon,\u201d he became increasingly obsessed with \u201cbehaviorist\u201d solutions to societal problems. He went from training pigeons for war to inventions like the \u201cAir Crib,\u201d which aimed to \u201csimplify\u201d baby care by keeping the infant behind glass in a climate-\u00adcontrolled chamber and eliminating the need for clothing and bedding. Skinner rejected free will, arguing that human behavior is determined by environmental variables, and wrote a novel, Walden II, about a utopian community founded on his ideas.  People who care about animals might feel uneasy about a revival in behaviorist theory. The \u201ccognitive revolution\u201d broke with centuries of Western thinking, which had emphasized human supremacy over animals and treated other creatures like stimulus-response machines. But arguing that animals learn by association is not the same as arguing that they are simple-minded. Scientists like Lind and Wasserman do not deny that internal forces like instinct and emotion also influence animal behavior. Sutton, too, believes that animals develop models of the world through their experiences and use them to plan actions. Their point is not that intelligent animals are empty-headed but that associative learning is a much more powerful\u2014indeed, \u201ccognitive\u201d\u2014mechanism than many of their peers believe. The psychologists who recently criticized the study on crows and statistical inference did not conclude that the birds were stupid. Rather, they argued \u201cthat a reinforcement learning model can produce complex, flexible behaviour.\u201d This is largely in line with the work of another psychologist, Robert Rescorla, whose work in the \u201970s and \u201980s influenced both Wasserman and Sutton. Rescorla encouraged people to think of association not as a \u201clow-level mechanical process\u201d but as \u201cthe learning that results from exposure to relations among events in the environment\u201d and \u201ca primary means by which the organism represents the structure of its world.\u201d\u00a0 This is true even of a laboratory pigeon pecking at screens and buttons in a small experimental box, where scientists carefully control and measure stimuli and rewards. But the pigeon\u2019s learning extends outside the box. Wasserman\u2019s students transport the birds between the aviary and the laboratory in buckets\u2014and experienced pigeons jump immediately into the buckets whenever the students open the doors. Much as Rescorla suggested, they are learning the structure of their world inside the laboratory and the relation of its parts, like the bucket and the box, even though they do not always know the specific task they will face inside.\u00a0  Comparative psychologists and animal researchers have long grappled with a question that suddenly seems urgent because of AI: How do we attribute sentience to other living beings?  The same associative mechanisms through which the pigeon learns the structure of its world can open a window to the kind of inner life that Skinner and many earlier psychologists said did not exist. Pharmaceutical researchers have long used pigeons in drug-discrimination tasks, where they\u2019re given, say, an amphetamine or a sedative and rewarded with a food pellet for correctly identifying which drug they took. The birds\u2019 success suggests they both experience and discriminate between internal states. \u201cIs that not tantamount to introspection?\u201d Wasserman asked. It is hard to imagine AI matching a pigeon on this specific task\u2014a reminder that, though AI and animals share associative mechanisms, there is more to life than behavior and learning. A pigeon deserves ethical consideration as a living creature not because of how it learns but because of what it feels. A pigeon can experience pain and suffer, while an AI chatbot cannot\u2014even if some large language models, trained on corpora that include descriptions of human suffering and sci-fi stories of sentient computers, can trick people into believing otherwise.",
    "Psychologist Ed Wasserman trained pigeons to detect cancerous tissue and symptoms of heart disease in medical scans as accurately as experienced physicians.UNIVERSITY OF IOWA/WASSERMAN LAB   \u201cThe intensive public and private investments into AI research in recent years have resulted in the very technologies that are forcing us to confront the question of AI sentience today,\u201d two philosophers of science wrote in Aeon in 2023. \u201cTo answer these current questions, we need a similar degree of investment into research on animal cognition and behavior.\u201d Indeed, comparative psychologists and animal researchers have long grappled with questions that suddenly seem urgent because of AI: How do we attribute sentience to other living beings? How can we distinguish true sentience from a very convincing performance of sentience? Such an undertaking would yield knowledge not only about technology and animals but also about ourselves. Most psychologists probably wouldn\u2019t go as far as Sutton in arguing that reward is enough to explain most if not all human behavior, but no one would dispute that people often learn by association too. In fact, most of Wasserman\u2019s undergraduate students eventually succeeded at his recent experiment with the striped discs, but only after they gave up searching for rules. They resorted, like the pigeons, to association and couldn\u2019t easily explain afterwards what they\u2019d learned. It was just that with enough practice, they started to get a feel for the categories.\u00a0 It is another irony about associative learning: What has long been considered the most complex form of intelligence\u2014a cognitive ability like rule-based learning\u2014may make us human, but we also call on it for the easiest of tasks, like sorting objects by color or size. Meanwhile, some of the most refined demonstrations of human learning\u2014like, say, a sommelier learning to taste the difference between grapes\u2014are learned not through rules, but only through experience.\u00a0 Learning through experience relies on ancient associative mechanisms that we share with pigeons and countless other creatures, from honeybees to fish. The laboratory pigeon is not only in our computers but in our brains\u2014and the engine behind some of humankind\u2019s most impressive feats.\u00a0 Ben Crair is a science and travel writer based in Berlin."
  ]
}