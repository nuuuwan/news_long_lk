{
  "url": "https://www.technologyreview.com/2024/09/12/1103926/googles-new-tool-lets-large-language-models-fact-check-their-responses/",
  "title": "Google\u2019s new tool lets large language models fact-check their responses",
  "ut": 1726111800.0,
  "body_paragraphs": [
    "As long as chatbots have been around, they have made things up. Such \u201challucinations\u201d are an inherent part of how AI models work. However, they\u2019re a big problem for companies betting big on AI, like Google, because they make the responses it generates unreliable.\u00a0 Google is releasing a tool today to address the issue. Called DataGemma, it uses two methods to help large language models fact-check their responses against reliable data and cite their sources more transparently to users.\u00a0  The first of the two methods is called Retrieval-Interleaved Generation (RIG), which acts as a sort of fact-checker. If a user prompts the model with a question\u2014like \u201cHas the use of renewable energy sources increased in the world?\u201d\u2014the model will come up with a \u201cfirst draft\u201d answer. Then RIG identifies what portions of the draft answer could be checked against Google\u2019s Data Commons, a massive repository of data and statistics from reliable sources like the United Nations or the Centers for Disease Control and Prevention. Next, it runs those checks and replaces any incorrect original guesses with correct facts. It also cites its sources to the user. The second method, which is commonly used in other large language models, is called Retrieval-Augmented Generation (RAG). Consider a prompt like \u201cWhat progress has Pakistan made against global health goals?\u201d In response, the model examines which data in the Data Commons could help it answer the question, such as information about access to safe drinking water, hepatitis B immunizations, and life expectancies. With those figures in hand, the model then builds its answer on top of the data and cites its sources.",
    "\u201cOur goal here was to use Data Commons to enhance the reasoning of LLMs by grounding them in real-world statistical data that you could source back to where you got it from,\u201d says Prem Ramaswami, head of Data Commons at Google. Doing so, he says, will \u201ccreate more trustable, reliable AI.\u201d Related StoryWhat is AI?Everyone thinks they know but no one can agree. And that\u2019s a problem.",
    "It is only available to researchers for now, but Ramaswami says access could widen further after more testing. If it works as hoped, it could be a real boon for Google\u2019s plan to embed AI deeper into its search engine.",
    "However, it comes with a host of caveats. First, the usefulness of the methods is limited by whether the relevant data is in the Data Commons, which is more of a data repository than an encyclopedia. It can tell you the GDP of Iran, but it\u2019s unable to confirm the date of the First Battle of Fallujah or when Taylor Swift released her most recent single. In fact, Google\u2019s researchers found that with about 75% of the test questions, the RIG method was unable to obtain any usable data from the Data Commons. And even if helpful data is indeed housed in the Data Commons, the model doesn\u2019t always formulate the right questions to find it.\u00a0 Second, there is the question of accuracy. When testing the RAG method, researchers found that the model gave incorrect answers 6% to 20% of the time. Meanwhile, the RIG method pulled the correct stat from Data Commons only about 58% of the time (though that\u2019s a big improvement over the 5% to 17% accuracy rate of Google\u2019s large language models when they\u2019re not pinging Data Commons).\u00a0 Ramaswami says DataGemma\u2019s accuracy will improve as it gets trained on more and more data. The initial version has been trained on only about 700 questions, and fine-tuning the model required his team to manually check each individual fact it generated. To further improve the model, the team plans to increase that data set from hundreds of questions to millions. hide"
  ]
}