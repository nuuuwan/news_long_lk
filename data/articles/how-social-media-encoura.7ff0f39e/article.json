{
  "url": "https://www.technologyreview.com/2025/12/23/1130393/how-social-media-encourages-the-worst-of-ai-boosterism/",
  "title": "How social media encourages the worst of AI boosterism",
  "ut": 1766446200.0,
  "body_paragraphs": [
    "Demis Hassabis, CEO of Google DeepMind, summed it up in three words: \u201cThis is embarrassing.\u201d\u00a0\u00a0 Hassabis was replying on X to an overexcited post by S\u00e9bastien Bubeck, a research scientist at the rival firm OpenAI, announcing that two mathematicians had used OpenAI\u2019s latest large language model, GPT-5, to find solutions to 10 unsolved problems in mathematics. \u201cScience acceleration via AI has officially begun,\u201d Bubeck crowed.  Put your math hats on for a minute, and let\u2019s take a look at what this beef from mid-October was about. It\u2019s a perfect example of what\u2019s wrong with AI right now. Bubeck was excited that GPT-5 seemed to have somehow solved a number of puzzles known as Erd\u0151s problems.",
    "Paul Erd\u0151s, one of the most prolific mathematicians of the 20th century, left behind hundreds of puzzles when he died. To help keep track of which ones have been solved, Thomas Bloom, a mathematician at the University of Manchester, UK, set up erdosproblems.com, which lists more than 1,100 problems and notes that around 430 of them come with solutions.\u00a0 When Bubeck celebrated GPT-5\u2019s breakthrough, Bloom was quick to call him out. \u201cThis is a dramatic misrepresentation,\u201d he wrote on X. Bloom explained that a problem isn\u2019t necessarily unsolved if this website does not list a solution. That simply means Bloom wasn\u2019t aware of one. There are millions of mathematics papers out there, and nobody has read all of them. But GPT-5 probably has.",
    "It turned out that instead of coming up with new solutions to 10 unsolved problems, GPT-5 had scoured the internet for 10 existing solutions that Bloom hadn\u2019t seen before. Oops! There are two takeaways here. One is that breathless claims about big breakthroughs shouldn\u2019t be made via social media: Less knee jerk and more gut check. The second is that GPT-5\u2019s ability to find references to previous work that Bloom wasn\u2019t aware of is also amazing. The hype overshadowed something that should have been pretty cool in itself. Mathematicians are very interested in using LLMs to trawl through vast numbers of existing results, Fran\u00e7ois Charton, a research scientist who studies the application of LLMs to mathematics at the AI startup Axiom Math, told me when I talked to him about this Erd\u0151s gotcha.  But literature search is dull compared with genuine discovery, especially to AI\u2019s fervent boosters on social media. Bubeck\u2019s blunder isn\u2019t the only example. In August, a pair of mathematicians showed that no LLM at the time was able to solve a math puzzle known as Yu Tsumura\u2019s 554th Problem. Two months later, social media erupted with evidence that GPT-5 now could. \u201cLee Sedol moment is coming for many,\u201d one observer commented, referring to the Go master who lost to DeepMind\u2019s AI AlphaGo in 2016. But Charton pointed out that solving Yu Tsumura\u2019s 554th Problem isn\u2019t a big deal to mathematicians. \u201cIt\u2019s a question you would give an undergrad,\u201d he said. \u201cThere is this tendency to overdo everything.\u201d Meanwhile, more sober assessments of what LLMs may or may not be good at are coming in. At the same time that mathematicians were fighting on the internet about GPT-5, two new studies came out that looked in depth at the use of LLMs in medicine and law (two fields that model makers have claimed their tech excels at).",
    "Related StoryA brief history of Sam Altman\u2019s hypeRead next Researchers found that LLMs could make certain medical diagnoses, but they were flawed at recommending treatments. When it comes to law, researchers found that LLMs often give inconsistent and incorrect advice. \u201cEvidence thus far spectacularly fails to meet the burden of proof,\u201d the authors concluded. But that\u2019s not the kind of message that goes down well on X. \u201cYou\u2019ve got that excitement because everybody is communicating like crazy\u2014nobody wants to be left behind,\u201d Charton said. X is where a lot of AI news drops first, it\u2019s where new results are trumpeted, and it\u2019s where key players like Sam Altman, Yann LeCun, and Gary Marcus slug it out in public. It\u2019s hard to keep up\u2014and harder to look away. Bubeck\u2019s post was only embarrassing because his mistake was caught. Not all errors are. Unless something changes researchers, investors, and non-specific boosters will keep teeing each other up. \u201cSome of them are scientists, many are not, but they are all nerds,\u201d Charton told me. \u201cHuge claims work very well on these networks.\u201d ***** There\u2019s a coda! I wrote everything you\u2019ve just read above for the Algorithm column in the January/February 2026 issue of MIT Technology Review magazine (out very soon). Two days after that went to press, Axiom told me its own math model, AxiomProver, had solved two open Erd\u0151s problems (#124 and #481, for the math fans in the room). That\u2019s impressive stuff for a small startup founded just a few months ago. Yup\u2014AI moves fast! But that\u2019s not all. Five days later the company announced that AxiomProver had solved nine out of 12 problems in this year\u2019s Putnam competition, a college-level math challenge that some people consider harder than the better-known International Math Olympiad (which LLMs from both Google DeepMind and OpenAI aced a few months back).\u00a0 The Putnam result was lauded on X by big names in the field, including Jeff Dean, chief scientist at Google DeepMind, and Thomas Wolf, cofounder at the AI firm Hugging Face. Once again familiar debates played out in the replies. A few researchers pointed out that while the International Math Olympiad demands more creative problem-solving, the Putnam competition tests math knowledge\u2014which makes it notoriously hard for undergrads, but easier, in theory, for LLMs that have ingested the internet. How should we judge Axiom\u2019s achievements? Not on social media, at least. And the eye-catching competition wins are just a starting point. Determining just how good LLMs are at math will require a deeper dive into exactly what these models are doing when they solve hard (read: hard for humans) math problems. This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,\u00a0sign up here. hide"
  ]
}