{
  "url": "https://www.technologyreview.com/2026/01/06/1130707/why-ai-predictions-are-so-hard/",
  "title": "Why AI predictions are so hard",
  "ut": 1767655800.0,
  "body_paragraphs": [
    "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,\u00a0sign up here. Sometimes AI feels like a niche topic to write about, but then the holidays happen, and I hear relatives of all ages talking about cases of chatbot-induced psychosis, blaming rising electricity prices on data centers, and asking whether kids should have unfettered access to AI. It\u2019s everywhere, in other words. And people are alarmed.  Inevitably, these conversations take a turn: AI is having all these ripple effects now, but if the technology gets better, what happens next? That\u2019s usually when they look at me, expecting a forecast of either doom or hope.\u00a0 I probably disappoint, if only because predictions for AI are getting harder and harder to make.",
    "Despite that, MIT Technology Review has, I must say, a pretty excellent track record of making sense of where AI is headed. We\u2019ve just published a sharp list of predictions for what\u2019s next in 2026 (where you can read my thoughts on the legal battles surrounding AI), and the predictions on last year\u2019s list all came to fruition. But every holiday season, it gets harder and harder to work out the impact AI will have. That\u2019s mostly because of three big unanswered questions. For one, we don\u2019t know if large language models will continue getting incrementally smarter in the near future. Since this particular technology is what underpins nearly all the excitement and anxiety in AI right now, powering everything from AI companions to customer service agents, its slowdown would be a pretty huge deal. Such a big deal, in fact, that we devoted a whole slate of stories in December to what a new post-AI-hype era might look like.",
    "Number two, AI is pretty abysmally unpopular among the general public. Here\u2019s just one example: Nearly a year ago, OpenAI\u2019s Sam Altman stood next to President Trump to excitedly announce a $500 billion project to build data centers across the US in order to train larger and larger AI models. The pair either did not guess or did not care that many Americans would staunchly oppose having such data centers built in their communities. A year later, Big Tech is waging an uphill battle to win over public opinion and keep on building. Can it win?\u00a0 The response from lawmakers to all this frustration is terribly confused. Trump has pleased Big Tech CEOs by moving to make AI regulation a federal rather than a state issue, and tech companies are now hoping to codify this into law. But the crowd that wants to protect kids from chatbots ranges from progressive lawmakers in California to the increasingly Trump-aligned Federal Trade Commission, each with distinct motives and approaches. Will they be able to put aside their differences and rein AI firms in?\u00a0 If the gloomy holiday dinner table conversation gets this far, someone will say: Hey, isn\u2019t AI being used for objectively good things? Making people healthier, unearthing scientific discoveries, better understanding climate change? Well, sort of. Machine learning, an older form of AI, has long been used in all sorts of scientific research. One branch, called deep learning, forms part of AlphaFold, a Nobel Prize\u2013winning tool for protein prediction that has transformed biology. Image recognition models are getting better at identifying cancerous cells.\u00a0 But the track record for chatbots built atop newer large language models is more modest. Technologies like ChatGPT are quite good at analyzing large swathes of research to summarize what\u2019s already been discovered. But some high-profile reports that these sorts of AI models had made a genuine discovery, like solving a previously unsolved mathematics problem, were bogus. They can assist doctors with diagnoses, but they can also encourage people to diagnose their own health problems without consulting doctors, sometimes with disastrous results.\u00a0 This time next year, we\u2019ll probably have better answers to my family\u2019s questions, and we\u2019ll have a bunch of entirely new questions too. In the meantime, be sure to read our full piece forecasting what will happen this year, featuring predictions from the whole AI team.  hide"
  ]
}