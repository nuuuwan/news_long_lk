{
  "url": "https://www.technologyreview.com/2025/01/17/1110086/openai-has-created-an-ai-model-for-longevity-science/",
  "title": "OpenAI has created an AI model for longevity science",
  "ut": 1737088552.0,
  "body_paragraphs": [
    "When you think of AI\u2019s contributions to science, you probably think of AlphaFold, the Google DeepMind protein-folding program that earned its creator a Nobel Prize last year. Now OpenAI says it\u2019s getting into the science game too\u2014with a model for engineering proteins.  The company says it has developed a language model that dreams up proteins capable of turning regular cells into stem cells\u2014and that it has handily beat humans at the task. The work represents OpenAI\u2019s first model focused on biological data and its first public claim that its models can deliver unexpected scientific results. As such, it is a step toward determining whether or not AI can make true discoveries, which some argue is a major test on the pathway to \u201cartificial general intelligence.\u201d",
    "Last week, OpenAI CEO Sam Altman said he was \u201cconfident\u201d his company knows how to build an AGI, adding that \u201csuperintelligent tools could massively accelerate scientific discovery and innovation well beyond what we are capable of doing on our own.\u201d\u00a0 The protein engineering project started a year ago when Retro Biosciences, a longevity research company based in San Francisco, approached OpenAI about working together.",
    "That link-up did not happen by chance. Sam Altman, the CEO of OpenAI, personally funded Retro with $180 million, as MIT Technology Review first reported in 2023. Related StorySam Altman invested $180 million into a company trying to delay deathCan anti-aging breakthroughs add 10 healthy years to the human life span? The CEO of OpenAI is paying to find out.",
    "Retro has the goal of extending the normal human lifespan by 10 years. For that, it studies what are called Yamanaka factors. Those are a set of proteins that, when added to a human skin cell, will cause it to morph into a young-seeming stem cell, a type that can produce any other tissue in the body.\u00a0 It\u2019s a phenomenon that researchers at Retro, and at richly funded companies like Altos Labs, see as the possible starting point for rejuvenating animals, building human organs, or providing supplies of replacement cells. But such cell \u201creprogramming\u201d is not very efficient. It takes several weeks, and less than 1% of cells treated in a lab dish will complete the rejuvenation journey.  OpenAI\u2019s new model, called GPT-4b micro, was trained to suggest ways to re-engineer the protein factors to increase their function. According to OpenAI, researchers used the model\u2019s suggestions to change two of the Yamanaka factors to be more than 50 times as effective\u2014at least according to some preliminary measures.\u00a0 \u201cJust across the board, the proteins seem better than what the scientists were able to produce by themselves,\u201d says John Hallman, an OpenAI researcher. Hallman and OpenAI\u2019s Aaron Jaech, as well as Rico Meinl from Retro, were the model\u2019s lead developers. Outside scientists won\u2019t be able to tell if the results are real until they\u2019re published, something the companies say they are planning. Nor is the model available for wider use\u2014it\u2019s still a bespoke demonstration, not an official product launch.",
    "\u201cThis project is meant to show that we\u2019re serious about contributing to science,\u201d says Jaech. \u201cBut whether those capabilities will come out to the world as a separate model or whether they\u2019ll be rolled into our mainline reasoning models\u2014that\u2019s still to be determined.\u201d The model does not work the same way as Google\u2019s AlphaFold, which predicts what shape proteins will take. Since the Yamanaka factors are unusually floppy and unstructured proteins, OpenAI said, they called for a different approach, which its large language models were suited to. The model was trained on examples of protein sequences from many species, as well as information on which proteins tend to interact with one another. While that\u2019s a lot of data, it\u2019s just a fraction of what OpenAI\u2019s flagship chatbots were trained on, making GPT-4b an example of a \u201csmall language model\u201d that works with a focused data set. Once Retro scientists were given the model, they tried to steer it to suggest possible redesigns of the Yamanaka proteins. The prompting tactic used is similar to the \u201cfew-shot\u201d method, in which a user queries a chatbot by providing a series of examples with answers, followed by an example for the bot to respond to. Although genetic engineers have ways to direct evolution of molecules in the lab, they can usually test only so many possibilities. And even a protein of typical length can be changed in nearly infinite ways (since they\u2019re built from hundreds of amino acids, and each acid comes in 20 possible varieties). OpenAI\u2019s model, however, often spits out suggestions in which a third of the amino acids in the proteins were changed.  OPENAI   \u201cWe threw this model into the lab immediately and we got real-world results,\u201d says Retro\u2019s CEO, Joe Betts-Lacroix. He says the model\u2019s ideas were unusually good, leading to improvements over the original Yamanaka factors in a substantial fraction of cases. Vadim Gladyshev, a Harvard University aging researcher who consults with Retro, says better ways of making stem cells are needed. \u201cFor us, it would be extremely useful. [Skin cells] are easy to reprogram, but other cells are not,\u201d he says. \u201cAnd to do it in a new species\u2014it\u2019s often extremely different, and you don\u2019t get anything.\u201d",
    "How exactly the GPT-4b arrives at its guesses is still not clear\u2014as is often the case with AI models. \u201cIt\u2019s like when AlphaGo crushed the best human at Go, but it took a long time to find out why,\u201d says Betts-Lacroix. \u201cWe are still figuring out what it does, and we think the way we apply this is only scratching the surface.\u201d OpenAI says no money changed hands in the collaboration. But because the work could benefit Retro\u2014whose biggest investor is Altman\u2014the announcement may add to questions swirling around the OpenAI CEO\u2019s side projects.",
    "Last year, the Wall Street Journal said Altman\u2019s wide-ranging investments in private tech startups amount to an \u201copaque investment empire\u201d that is \u201ccreating a mounting list of potential conflicts,\u201d since some of these companies also do business with OpenAI. In Retro\u2019s case, simply being associated with Altman, OpenAI, and the race toward AGI could boost its profile and increase its ability to hire staff and raise funds. Betts-Lacroix did not answer questions about whether the early-stage company is currently in fundraising mode.\u00a0 OpenAI says Altman was not directly involved in the work and that it never makes decisions based on Altman\u2019s other investments.\u00a0 hide"
  ]
}