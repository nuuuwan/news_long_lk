{
  "url": "https://www.technologyreview.com/2024/12/18/1108796/this-is-where-the-data-to-build-ai-comes-from/",
  "title": "This is where the data to build AI comes from",
  "ut": 1734481210.0,
  "body_paragraphs": [
    "AI is all about data. Reams and reams of data are needed to train algorithms to do what we want, and what goes into the AI models determines what comes out. But here\u2019s the problem: AI developers and researchers don\u2019t really know much about the sources of the data they are using. AI\u2019s data collection practices are immature compared with the sophistication of AI model development. Massive data sets often lack clear information about what is in them and where it came from.\u00a0 The Data Provenance Initiative, a group of over 50 researchers from both academia and industry, wanted to fix that. They wanted to know, very simply: Where does the data to build AI come from? They audited nearly 4,000 public data sets spanning over 600 languages, 67 countries, and three decades. The data came from 800 unique sources and nearly 700 organizations.\u00a0  Their findings, shared exclusively with MIT Technology Review, show a worrying trend: AI's data practices risk concentrating power overwhelmingly in the hands of a few dominant technology companies.\u00a0 In the early 2010s, data sets came from a variety of sources, says Shayne Longpre, a researcher at MIT who is part of the project.",
    "It came not just from encyclopedias and the web, but also from sources such as parliamentary transcripts, earning calls, and weather reports. Back then, AI data sets were specifically curated and collected from different sources to suit individual tasks, Longpre says. Then transformers, the architecture underpinning language models, were invented in 2017, and the AI sector started seeing performance get better the bigger the models and data sets were. Today, most AI data sets are built by indiscriminately hoovering material from the internet. Since 2018, the web has been the dominant source for data sets used in all media, such as audio, images, and video, and a gap between scraped data and more curated data sets has emerged and widened.",
    "\ufeff\ufeff\ufeff\ufeff\ufeff\ufeff\ufeff\u201cIn foundation model development, nothing seems to matter more for the capabilities than the scale and heterogeneity of the data and the web,\u201d says Longpre. The need for scale has also boosted the use of synthetic data massively. The past few years have also seen the rise of multimodal generative AI models, which can generate videos and images. Like large language models, they need as much data as possible, and the best source for that has become YouTube.\u00a0 For video models, as you can see in this chart, over 70% of data for both speech and image data sets comes from one source.  This could be a boon for Alphabet, Google\u2019s parent company, which owns YouTube. Whereas text is distributed across the web and controlled by many different websites and platforms, video data is extremely concentrated in one platform.  \u201cIt gives a huge concentration of power over a lot of the most important data on the web to one company,\u201d says Longpre.\u00a0 And because Google is also developing its own AI models, its massive advantage also raises questions about how the company will make this data available for competitors, says Sarah Myers West, the co\u2013executive director at the AI Now Institute. \u201cIt\u2019s important to think about data not as though it\u2019s sort of this naturally occurring resource, but it\u2019s something that is created through particular processes,\u201d says Myers West. \u201cIf the data sets on which most of the AI that we\u2019re interacting with reflect the intentions and the design of big, profit-motivated corporations\u2014that\u2019s reshaping the infrastructures of our world in ways that reflect the interests of those big corporations,\u201d she says.",
    "This monoculture also raises questions about how accurately the human experience is portrayed in the data set and what kinds of models we are building, says Sara Hooker, the vice president of research at the technology company Cohere, who is also part of the Data Provenance Initiative. People upload videos to YouTube with a particular audience in mind, and the way people act in those videos is often intended for very specific effect. \u201cDoes [the data] capture all the nuances of humanity and all the ways that we exist?\u201d says Hooker.\u00a0 Hidden restrictions AI companies don\u2019t usually share what data they used to train their models. One reason is that they want to protect their competitive edge. The other is that because of the complicated and opaque way data sets are bundled, packaged, and distributed, they likely don\u2019t even know where all the data came from. They also probably don\u2019t have complete information about any constraints on how that data is supposed to be used or shared. The researchers at the Data Provenance Initiative found that data sets often have restrictive licenses or terms attached to them, which should limit their use for commercial purposes, for example.   \u201cThis lack of consistency across the data lineage makes it very hard for developers to make the right choice about what data to use,\u201d says Hooker. It also makes it almost impossible to be completely certain you haven\u2019t trained your model on copyrighted data, adds Longpre. More recently, companies such as OpenAI and Google have struck exclusive data-sharing deals with publishers, major forums such as Reddit, and social media platforms on the web. But this becomes another way for them to concentrate their power. \u201cThese exclusive contracts can partition the internet into various zones of who can get access to it and who can\u2019t,\u201d says Longpre.",
    "The trend benefits the biggest AI players, who can afford such deals, at the expense of researchers, nonprofits, and smaller companies, who will struggle to get access. The largest companies also have the best resources for crawling data sets. \u201cThis is a new wave of asymmetric access that we haven\u2019t seen to this extent on the open web,\u201d Longpre says.",
    "The West vs. the rest The data that is used to train AI models is also heavily skewed to the Western world. Over 90% of the data sets that the researchers analyzed came from Europe and North America, and fewer than 4% came from Africa.\u00a0 \"These data sets are reflecting one part of our world and our culture, but completely omitting others,\" says Hooker.  The dominance of the English language in training data is partly explained by the fact that the internet is still over 90% in English, and there are still a lot of places on Earth where there\u2019s really poor internet connection or none at all, says Giada Pistilli, principal ethicist at Hugging Face, who was not part of the research team. But another reason is convenience, she adds: Putting together data sets in other languages and taking other cultures into account requires conscious intention and a lot of work.\u00a0 The Western focus of these data sets becomes particularly clear with multimodal models. When an AI model is prompted for the sights and sounds of a wedding, for example, it might only be able to represent Western weddings, because that\u2019s all that it has been trained on, Hooker says.\u00a0 This reinforces biases and could lead to AI models that push a certain US-centric worldview, erasing other languages and cultures. \u201cWe are using these models all over the world, and there\u2019s a massive discrepancy between the world we\u2019re seeing and what\u2019s invisible to these models,\u201d Hooker says.\u00a0 hide"
  ]
}