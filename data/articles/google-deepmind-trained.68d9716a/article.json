{
  "url": "https://www.technologyreview.com/2024/08/09/1096102/google-deepmind-trained-a-robot-to-beat-humans-at-table-tennis/",
  "title": "Google DeepMind trained a robot to beat humans at table tennis",
  "ut": 1723160609.0,
  "body_paragraphs": [
    "Do you fancy your chances of beating a robot at a game of table tennis? Google DeepMind has trained a robot to play the game at the equivalent of amateur-level competitive performance, the company has announced. It claims it\u2019s the first time a robot has been taught to play a sport with humans at a human level. Researchers managed to get a robotic arm wielding a 3D-printed paddle to win 13 of 29 games against human opponents of varying abilities in full games of competitive table tennis. The research was published in an Arxiv paper.\u00a0  The system is far from perfect. Although the table tennis bot was able to beat all beginner-level human opponents it faced and 55% of those playing at amateur level, it lost all the games against advanced players. Still, it\u2019s an impressive advance. \u201cEven a few months back, we projected that realistically the robot may not be able to win against people it had not played before. The system certainly exceeded our expectations,\u201d says\u00a0 Pannag Sanketi, a senior staff software engineer at Google DeepMind who led the project. \u201cThe way the robot outmaneuvered even strong opponents was mind blowing.\u201d",
    "And the research is not just all fun and games. In fact, it represents a step towards creating robots that can perform useful tasks skillfully and safely in real environments like homes and warehouses, which is a long-standing goal of the robotics community. Google DeepMind\u2019s approach to training machines is applicable to many other areas of the field, says Lerrel Pinto, a computer science researcher at New York University who did not work on the project. \u201cI'm a big fan of seeing robot systems actually working with and around real humans, and this is a fantastic example of this,\u201d he says. \u201cIt may not be a strong player, but the raw ingredients are there to keep improving and eventually get there.\u201d",
    "To become a proficient table tennis player, humans require excellent hand-eye coordination, the ability to move rapidly and make quick decisions reacting to their opponent\u2014all of which are significant challenges for robots. Google DeepMind\u2019s researchers used a two-part approach to train the system to mimic these abilities: they used computer simulations to train the system to master its hitting skills; then fine tuned it using real-world data, which allows it to improve over time. Related StoryHow AI taught Cassie the two-legged robot to run and jumpReinforcement learning can help robots tackle new tasks they haven't tried before",
    "The researchers compiled a dataset of table tennis ball states, including data on position, spin, and speed. The system drew from this library in a simulated environment designed to accurately reflect the physics of table tennis matches to learn skills such as returning a serve, hitting a forehand topspin, or backhand shot. As the robot\u2019s limitations meant it could not serve the ball, the real-world games were modified to accommodate this. During its matches against humans, the robot collects data on its performance to help refine its skills. It tracks the ball\u2019s position using data captured by a pair of cameras, and follows its human opponent\u2019s playing style through a motion capture system that uses LEDs on its opponent\u2019s paddle. The ball data is fed back into the simulation for training, creating a continuous feedback loop.This feedback allows the robot to test out new skills to try and beat its opponent\u2014meaning it can adjust its tactics and behavior just like a human would. This means it becomes progressively better both throughout a given match, and over time the more games it plays. The system struggled to hit the ball when it was hit either very fast, beyond its field of vision (more than six feet above the table), or very low, because of a protocol that instructs it to avoid collisions that could damage its paddle. Spinning balls proved a challenge because it lacked the capacity to directly measure spin\u2014a limitation that advanced players were quick to take advantage of. Training a robot for all eventualities in a simulated environment is a real challenge, says Chris Walti, founder of robotics company Mytra and previously head of Tesla\u2019s robotics team, who was not involved in the project.\u201cIt's very, very difficult to actually simulate the real world because there's so many variables, like a gust of wind, or even dust [on the table]\u201d he says. \u201cUnless you have very realistic simulations, a robot\u2019s performance is going to be capped.\u201d\u00a0 Google DeepMind believes these limitations could be addressed in a number of ways, including by developing predictive AI models designed to anticipate the ball\u2019s trajectory, and introducing better collision-detection algorithms. Crucially, the human players enjoyed their matches against the robotic arm. Even the advanced competitors who were able to beat it said they\u2019d found the experience fun and engaging, and said they felt it had potential as a dynamic practice partner to help them hone their skills.\u00a0 \u201cI would definitely love to have it as a training partner, someone to play some matches from time to time,\u201d one of the study participants said. hide"
  ]
}