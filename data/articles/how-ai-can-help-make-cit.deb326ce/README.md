# How AI can help make cities work better for residents

[https://www.technologyreview.com/2025/06/16/1118210/ai-city-government-residents-constituents/](https://www.technologyreview.com/2025/06/16/1118210/ai-city-government-residents-constituents/)

*06:00 AM, Monday, June 16, 2025*

In recent decades, cities have become increasingly adept at amassing all sorts of data. But that data can have limited impact when government officials are unable to communicate, let alone analyze or put to use, all the information they have access to. This dynamic has always bothered Sarah Williams, a professor of urban planning and technology at MIT. “We do a lot of spatial and data analytics. We sit on academic papers and research that could have a huge impact on the way we plan and design our cities,” she says of her profession. “It wasn’t getting communicated.”  Shortly after joining MIT in 2012, Williams created the Civic Data Design Lab to bridge that divide. Over the years, she and her colleagues have pushed the narrative and expository bounds of urban planning data using the latest technologies available—making numbers vivid and accessible through human stories and striking graphics. One project she was involved in, on rates of incarceration in New York City by neighborhood, is now in the permanent collection of the Museum of Modern Art in New York. Williams’s other projects have tracked the spread and impact of air pollution in Beijing using air quality monitors and mapped the daily commutes of Nairobi residents using geographic information systems.   Cities should be transparent in how they’re using AI and what its limitations are. In doing so, they have an opportunity to model more ethical and responsive ways of using this technology.  In recent years, as AI became more accessible, Williams was intrigued by what it could reveal about cities. “I really started thinking, ‘What are the implications for urban planning?’” she says. These tools have the potential to organize and illustrate vast amounts of data instantaneously. But having more information also increases the risks of misinformation and manipulation. “I wanted to help guide cities in thinking about the positives and negatives of these tools,” she says.

In 2024, that inquiry led to a collaboration with the city of Boston, which was exploring how and whether to apply AI in various government functions through its Office of Emerging Technology. Over the course of the year, Williams and her team followed along as Boston experimented with several new applications for AI in government and gathered feedback at community meetings. On the basis of these findings, Williams and the Civic Data Design Lab published the Generative AI Playbook for Civic Engagement in the spring. It’s a publicly available document that helps city governments take advantage of AI’s capabilities and navigate its ­attendant risks. This kind of guidance is especially important as the federal government takes an increasingly laissez-faire approach to AI regulation.

“That gray zone is where nonprofits and academia can create research to help guide states and private institutions,” Williams says.  Related StoryHow the federal government is tracking changes in the supply of street drugsThe National Institute of Standards and Technology’s new harm reduction initiative is helping prevent needless deaths.

The lab’s playbook and academic papers touch on a wide range of emerging applications, from virtual assistants for Boston’s procurement division to optimization of traffic signals to chatbots for the 311 nonemergency services hotline. But Williams’s primary focus is how to use this technology for civic engagement. AI could help make the membrane between the government and the public more porous, allowing each side to understand the other a little better.  Right now, civic engagement is mostly limited to “social media, websites, and community meetings,” she says. “If we can create more tools to help close that gap, that’s really important.” One of Boston’s AI-powered experiments moves in that direction. The city used a large language model to summarize every vote of the Boston City Council for the past 16 years, creating simple and straightforward descriptions of each measure. This easily searchable database “will help you find what you’re looking for a lot more quickly,” says Michael Lawrence Evans, head of the Office of Emerging Technology.  A quick search for “housing” shows the city council’s recent actions to create a new housing accelerator fund and to expand the capacity of migrant shelters. Though not every summary has been double-checked by a human, the tool’s accuracy was confirmed through “a really robust evaluation,” Evans says.   AI tools may also help governments understand the needs and desires of residents. The community is “already inputting a lot of its knowledge” through community meetings, public surveys, 311 tickets, and other channels, Williams says. Boston, for instance, recorded nearly 300,000 311 requests in 2024 (most were complaints related to parking). New York City recorded 35 million 311 contacts in 2023. It can be difficult for government workers to spot trends in all that noise. “Now they have a more structured way to analyze that data that didn’t really exist before,” she says. AI can help paint a clearer picture of how these sorts of resident complaints are distributed geographically. At a community meeting in Boston last year, city staff used generative AI to instantly produce a map of pothole complaints from the previous month.  AI also has the potential to illuminate more abstract data on residents’ desires. One mechanism Williams cites in her research is Polis, an open-source polling platform used by several national governments around the world and a handful of cities and media companies in the US. A recent update allows poll hosts to categorize and summarize responses using AI. It’s something of an experiment in how AI can help facilitate direct democracy—an issue that tool creator Colin Megill has worked on with both OpenAI and Anthropic.  But even as Megill explores these frontiers, he is proceeding cautiously. The goal is to “enhance human agency,” he says, and to avoid “manipulation” at all costs: “You want to give the model very specific and discrete tasks that augment human authors but don’t replace them.”

Misinformation is another concern as local governments figure out how best to work with AI. Though they’re increasingly common, 311 chatbots have a mixed record on this front. New York City’s chatbot made headlines last year for providing inaccurate and, at times, bizarre information. When an Associated Press reporter asked if it was legal for a restaurant to serve cheese that had been nibbled on by a rat, the chatbot responded, “Yes, you can still serve the cheese to customers if it has rat bites.” (The New York chatbot appears to have improved since then. When asked by this reporter, it responded firmly in the negative to the nibbling rat question.) Related StoryInside the race to archive the US government’s websitesAmid takedowns of various government sites and databases, several organizations are working to preserve vital climate, health, and scientific data before it’s gone for good.

These AI mishaps can reduce trust in government—precisely the opposite of the outcome that Williams is pursuing in her work.  “Currently, we don’t have a lot of trust in AI systems,” she says. “That’s why having that human facilitator is really important.” Cities should be transparent in how they’re using AI and what its limitations are, she says. In doing so, they have an opportunity to model more ethical and responsive ways of using this technology.  Next on Williams’s agenda is exploring how cities can develop their own AI systems rather than relying on tech giants, which often have a different set of priorities. This technology could be open-source; not only would communities be able to better understand the data they produce, but they would own it.  “One of the biggest criticisms of AI right now is that the people who are doing the labor are not paid for the work that they do [to train the systems],” she says. “I’m super excited about how communities can own their large language models. Then communities can own the data that’s inside them and allow people to have access to it.”   Benjamin Schneider is a freelance writer covering housing, transportation, and urban policy. hide

