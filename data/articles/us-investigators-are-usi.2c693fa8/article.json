{
  "url": "https://www.technologyreview.com/2025/09/26/1124343/us-investigators-are-using-ai-to-detect-child-abuse-images-made-by-ai/",
  "title": "US investigators are using AI to detect child abuse images made by AI",
  "ut": 1758879214.0,
  "body_paragraphs": [
    "Generative AI has enabled the production of child sexual abuse images to skyrocket. Now the leading investigator of child exploitation in the US is experimenting with using AI to distinguish AI-generated images from material depicting real victims, according to a new government filing. The Department of Homeland Security\u2019s Cyber Crimes Center, which investigates child exploitation across international borders, has awarded a $150,000 contract to San Francisco\u2013based Hive AI for its software, which can identify whether a piece of content was AI-generated.  The filing, posted on September 19, is heavily redacted and Hive cofounder and CEO Kevin Guo told MIT Technology Review that he could not discuss the details of the contract, but confirmed it involves use of the company\u2019s AI detection algorithms for child sexual abuse material (CSAM). The filing quotes data from the National Center for Missing and Exploited Children that reported a 1,325% increase in incidents involving generative AI in 2024. \u201cThe sheer volume of digital content circulating online necessitates the use of automated tools to process and analyze data efficiently,\u201d the filing reads.",
    "The first priority of child exploitation investigators is to find and stop any abuse currently happening, but the flood of AI-generated CSAM has made it difficult for investigators to know whether images depict a real victim currently at risk. A tool that could successfully flag real victims would be a massive help when they try to prioritize cases. Identifying AI-generated images \u201censures that investigative resources are focused on cases involving real victims, maximizing the program\u2019s impact and safeguarding vulnerable individuals,\u201d the filing reads.",
    "Hive AI offers AI tools that create videos and images, as well as a range of content moderation tools that can flag violence, spam, and sexual material and even identify celebrities. In December, MIT Technology Review reported that the company was selling its deepfake-detection technology to the US military.\u00a0 Related StoryThe US Department of Defense is investing in deepfake detectionIt has signed a contract with startup Hive AI worth $2.4 million over two years.",
    "For detecting CSAM, Hive offers a tool created with Thorn, a child safety nonprofit, which companies can integrate into their platforms. This tool uses a \u201chashing\u201d system, which assigns unique IDs to content known by investigators to be CSAM, and blocks that material from being uploaded. This tool, and others like it, have become a standard line of defense for tech companies.\u00a0 But these tools simply identify a piece of content as CSAM; they don\u2019t detect whether it was generated by AI. Hive has created a separate tool that determines whether images in general were AI-generated. Though it is not trained specifically to work on CSAM, according to Guo, it doesn\u2019t need to be. \u201cThere\u2019s some underlying combination of pixels in this image that we can identify\u201d as AI-generated, he says. \u201cIt can be generalizable.\u201d\u00a0 This tool, Guo says, is what the Cyber Crimes Center will be using to evaluate CSAM. He adds that Hive benchmarks its detection tools for each specific use case its customers have in mind. The National Center for Missing and Exploited Children, which participates in efforts to stop the spread of CSAM, did not respond to requests for comment on the effectiveness of such detection models in time for publication.\u00a0 In its filing, the government justifies awarding the contract to Hive without a competitive bidding process. Though parts of this justification are redacted, it primarily references two points also found in a Hive presentation slide deck. One involves a 2024 study from the University of Chicago, which found that Hive\u2019s AI detection tool outranked four other detectors in identifying AI-generated art. The other is its contract with the Pentagon for identifying deepfakes. The trial will last three months.\u00a0 hide"
  ]
}