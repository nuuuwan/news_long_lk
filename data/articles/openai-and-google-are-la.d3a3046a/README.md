# OpenAI and Google are launching supercharged AI assistants. Hereâ€™s how you can try them out.

## Summary ğŸ¤–

Google and OpenAI have developed AI assistants that can engage in real-time conversations, interpret surroundings using live video and translate chats instantaneously. OpenAI used a model called GPT-4o to read bedtime stories and solve maths problems, while Google's tool, named Gemini Live, is expected to provide similar functionalities. GPT-4o's text and vision functions will be rolled out on OpenAI's web interface and its GPT app soon. Developers can currently access these features in the API, with voice functions set to be releasedÂ soon. The toolÂ will be free but with usage limitations. Gemini Live will be introduced via Google's premium AI plan, Gemini Advanced, in the coming months. Another tool from Google, named Project Astra, will not be released until later this year.


## Follow-up Questions ğŸ¤–

1. Can you expand on some practical applications of these AI tools in daily life?
2. How will these advancements in AI affect the job market, particularly industries reliant on translation, coding and content creation?
3. What measures are Google and OpenAI taking to ensure the security of user data with these new AI assistants?
4. How do both Google and OpenAI respectively handle concerns around misinformation or bias in AI?
5. What potential is there for these tools in educational sectors such as teaching and studying?
6. What specific functionalities does OpenAI's GPT-4o have over Google's Gemini Live and vice versa? 
7. Could you provide more details on Googleâ€™s â€œdo-everythingâ€ AI agent, Project Astra?
8. Can you give more information on OpenAIâ€™s paid plans and their benefits?
9. What hurdles might both companies face in implementing these AI models broad-scale to the public?
10. How will these advanced AI models impact the ongoing discussion about AI ethics and the necessity of regulations?

## Full Text

[https://www.technologyreview.com/2024/05/15/1092516/openai-and-google-are-launching-supercharged-ai-assistants-heres-how-you-can-try-them-out/](https://www.technologyreview.com/2024/05/15/1092516/openai-and-google-are-launching-supercharged-ai-assistants-heres-how-you-can-try-them-out/)

*02:18 PM, Wednesday, May 15, 2024*

This week, Google and OpenAI both announced theyâ€™ve built supercharged AI assistants: tools that can converse with you in real time and recover when you interrupt them, analyze your surroundings via live video, and translate conversations on the fly.Â  OpenAI struck first on Monday, when it debuted its new flagship model GPT-4o. The live demonstration showed it reading bedtime stories and helping to solve math problems, all in a voice that sounded eerily like Joaquin Phoenixâ€™s AI girlfriend in the movie Her (a trait not lost on CEO Sam Altman).Â   On Tuesday, Google announced its own new tools, including a conversational assistant called Gemini Live, which can do many of the same things. It also revealed that itâ€™s building a sort of â€œdo-everythingâ€ AI agent, which is currently in development but will not be released until later this year. Soon youâ€™ll be able to explore for yourself to gauge whether youâ€™ll turn to these tools in your daily routine as much as their makers hope, or whether theyâ€™re more like a sci-fi party trick that eventually loses its charm. Hereâ€™s what you should know about how to access these new tools, what you might use them for, and how much it will cost.

OpenAIâ€™s GPT-4o What itâ€™s capable of: The model can talk with you in real time, with a response delay of about 320 milliseconds, which OpenAI says is on par with natural human conversation. You can ask the model to interpret anything you point your smartphone camera at, and it can provide assistance with tasks like coding or translating text. It can also summarize information, and generate images, fonts, and 3D renderings.Â  How to access it: OpenAI says it will start rolling out GPT-4oâ€™s text and vision features in the web interface as well as the GPT app, but has not set a date. The company says it will add the voice functions in the coming weeks, although itâ€™s yet to set an exact date for this either. Developers can access the text and vision features in the API now, but voice mode will launch only to a â€œsmall groupâ€ of developers initially.

How much it costs: Use of GPT-4o will be free, but OpenAI will set caps on how much you can use the model before you need to upgrade to a paid plan. Those who join one of OpenAIâ€™s paid plans, which start at $20 per month, will have five times more capacity on GPT-4o.Â  Googleâ€™s Gemini LiveÂ  What is Gemini Live? This is the Google product most comparable to GPT-4oâ€”a version of the companyâ€™s AI model that you can speak with in real time. Google says that youâ€™ll also be able to use the tool to communicate via live video â€œlater this year.â€ The company promises it will be a useful conversational assistant for things like preparing for a job interview or rehearsing a speech. How to access it: Gemini Live launches in â€œthe coming monthsâ€ via Googleâ€™s premium AI plan, Gemini Advanced.Â  How much it costs: Gemini Advanced offers a two-month free trial period and costs $20 per month thereafter.Â  But wait, whatâ€™s Project Astra? Astra is a project to build a do-everything AI agent, which was demoed at Googleâ€™s I/O conference but will not be released until later this year. People will be able to use Astra through their smartphones and possibly desktop computers, but the company is exploring other options too, such as embedding it into smart glasses or other devices, Oriol Vinyals, vice president of research at Google DeepMind, told MIT Technology Review. Which is better? Itâ€™s hard to tell without having hands on the full versions of these models ourselves. Google showed off Project Astra through a polished video, whereas OpenAI opted to debut GPT-4o via a seemingly more authentic live demonstration, but in both cases, the models were asked to do things the designers likely already practiced. The real test will come when theyâ€™re debuted to millions of users with unique demands.Â Â  That said, if you compare OpenAIâ€™s published videos with Googleâ€™s, the two leading tools look very similar, at least in their ease of use. To generalize, GPT-4o seems to be slightly ahead on audio, demonstrating realistic voices, conversational flow, and even singing, whereas Project Astra shows off more advanced visual capabilities, like being able to â€œrememberâ€ where you left your glasses. OpenAIâ€™s decision to roll out the new features more quickly might mean its product will get more use at first than Googleâ€™s, which wonâ€™t be fully available until later this year. Itâ€™s too soon to tell which model "hallucinates" false information less often or creates more useful responses.

Are they safe? Both OpenAI and Google say their models are well tested: OpenAI says GPT-4o was evaluated by more than 70 experts in fields like misinformation and social psychology, and Google has said that Gemini "has the most comprehensive safety evaluations of any Google AI model to date, including for bias and toxicity.â€Â  But these companies are building a future where AI models search, vet, and evaluate the worldâ€™s information for us to serve up a concise answer to our questions. Even more so than with simpler chatbots, itâ€™s wise to remain skeptical about what they tell you. Additional reporting by Melissa HeikkilÃ¤. hide

