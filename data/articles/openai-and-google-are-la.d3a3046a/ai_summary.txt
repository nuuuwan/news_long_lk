Google and OpenAI have developed AI assistants that can engage in real-time conversations, interpret surroundings using live video and translate chats instantaneously. OpenAI used a model called GPT-4o to read bedtime stories and solve maths problems, while Google's tool, named Gemini Live, is expected to provide similar functionalities. GPT-4o's text and vision functions will be rolled out on OpenAI's web interface and its GPT app soon. Developers can currently access these features in the API, with voice functions set to be released soon. The tool will be free but with usage limitations. Gemini Live will be introduced via Google's premium AI plan, Gemini Advanced, in the coming months. Another tool from Google, named Project Astra, will not be released until later this year.
