{
  "url": "https://www.technologyreview.com/2025/06/03/1117685/inside-the-tedious-effort-to-tally-ais-energy-appetite/",
  "title": "Inside the tedious effort to tally AI\u2019s energy appetite",
  "ut": 1748907000.0,
  "body_paragraphs": [
    "After working on it for months, my colleague Casey Crownhart and I finally saw our story on AI\u2019s energy and emissions burden go live last week.\u00a0 The initial goal sounded simple: Calculate how much energy is used each time we interact with a chatbot, and then tally that up to understand why everyone from leaders of AI companies to officials at the White House wants to harness unprecedented levels of electricity to power AI and reshape our energy grids in the process.\u00a0  It was, of course, not so simple. After speaking with dozens of researchers, we realized that the common understanding of AI\u2019s energy appetite is full of holes. I encourage you to read the full story, which has some incredible graphics to help you understand everything from the energy used in a single query right up to what AI will require just three years from now (enough electricity to power 22% of US households, it turns out). But here are three takeaways I have after the project.\u00a0 AI is in its infancy We focused on measuring the energy requirements that go into using a chatbot, generating an image, and creating a video with AI. But these three uses are relatively small-scale compared with where AI is headed next.",
    "Lots of AI companies are building reasoning models, which \u201cthink\u201d for longer and use more energy. They\u2019re building hardware devices, perhaps like the one Jony Ive has been working on (which OpenAI just acquired for $6.5 billion), that have AI constantly humming along in the background of our conversations. They\u2019re designing agents and digital clones of us to act on our behalf. All these trends point to a more energy-intensive future (which, again, helps explain why OpenAI and others are spending such inconceivable amounts of money on energy).\u00a0 But the fact that AI is in its infancy raises another point. The models, chips, and cooling methods behind this AI revolution could all grow more efficient over time, as my colleague Will Douglas Heaven explains. This future isn\u2019t predetermined.",
    "Related StoryThe data center boom in the desertThe AI race is transforming northwestern Nevada into one of the world's largest data-center markets\u2014and sparking fears of water strains in the nation\u2019s driest state.",
    "AI video is on another level When we tested the energy demands of various models, we found the energy required to produce even a low-quality, five-second video to be pretty shocking: It was 42,000 times more than the amount needed for a chatbot answer a question about a recipe, and enough to power a microwave for over an hour. If there\u2019s one type of AI whose energy appetite should worry you, it\u2019s this one.\u00a0 Soon after we published, Google debuted the latest iteration of its Veo model. People quickly created compilations of the most impressive clips (this one being the most shocking to me). Something we point out in the story is that Google (as well as OpenAI, which has its own video generator, Sora) denied our request for specific numbers on the energy their AI models use. Nonetheless, our reporting suggests it\u2019s very likely that high-definition video models like Veo and Sora are much larger, and much more energy-demanding, than the models we tested.\u00a0 I think the key to whether the use of AI video will produce indefensible clouds of emissions in the near future will be how it\u2019s used, and how it\u2019s priced. The example I linked shows a bunch of TikTok-style content, and I predict that if creating AI video is cheap enough, social video sites will be inundated with this type of content.\u00a0 There are more important questions than your own individual footprint We expected that a lot of readers would understandably think about this story in terms of their own individual footprint, wondering whether their AI usage is contributing to the climate crisis. Don\u2019t panic: It\u2019s likely that asking a chatbot for help with a travel plan does not meaningfully increase your carbon footprint. Video generation might. But after reporting on this for months, I think there are more important questions. Consider, for example, the water being drained from aquifers in Nevada, the country\u2019s driest state, to power data centers that are drawn to the area by tax incentives and easy permitting processes, as detailed in an incredible story by James Temple. Or look at how Meta\u2019s largest data center project, in Louisiana, is relying on natural gas despite industry promises to use clean energy, per a story by David Rotman. Or the fact that nuclear energy is not the silver bullet that AI companies often make it out to be.\u00a0 There are global forces shaping how much energy AI companies are able to access and what types of sources will provide it. There is also very little transparency from leading AI companies on their current and future energy demands, even while they\u2019re asking for public support for these plans. Pondering your individual footprint can be a good thing to do, provided you remember that it\u2019s not so much your footprint as these other factors that are keeping climate researchers and energy experts we spoke to up at night. This story originally appeared in\u00a0The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,\u00a0sign up here. hide"
  ]
}