{
  "url": "https://www.technologyreview.com/2025/05/13/1116321/police-tech-can-sidestep-facial-recognition-bans-now/",
  "title": "Police tech can sidestep facial recognition bans now",
  "ut": 1747092600.0,
  "body_paragraphs": [
    "Six months ago I attended the largest gathering of chiefs of police in the US to see how they\u2019re using AI. I found some big developments, like officers getting AI to write their police reports. Today, I published a new story that shows just how far AI for police has developed since then.\u00a0 It\u2019s about a new method police departments and federal agencies have found to track people: an AI tool that uses attributes like body size, gender, hair color and style, clothing, and accessories instead of faces. It offers a way around laws curbing the use of facial recognition, which are on the rise.\u00a0  Advocates from the ACLU, after learning of the tool through MIT Technology Review, said it was the first instance they\u2019d seen of such a tracking system used at scale in the US, and they say it has a high potential for abuse by federal agencies. They say the prospect that AI will enable more powerful surveillance is especially alarming at a time when the Trump administration is pushing for more monitoring of protesters, immigrants, and students.\u00a0 I hope you read the full story for the details, and to watch a demo video of how the system works. But first, let\u2019s talk for a moment about what this tells us about the development of police tech and what rules, if any, these departments are subject to in the age of AI.",
    "As I pointed out in my story six months ago, police departments in the US have extraordinary independence. There are more than 18,000 departments in the country, and they generally have lots of discretion over what technology they spend their budgets on. In recent years, that technology has increasingly become AI-centric.\u00a0 Related StoryHow a new type of AI is helping police skirt facial recognition bansAdoption of the tech has civil liberties advocates alarmed, especially as the government vows to expand surveillance of protesters and students.",
    "Companies like Flock and Axon sell suites of sensors\u2014cameras, license plate readers, gunshot detectors, drones\u2014and then offer AI tools to make sense of that ocean of data (at last year\u2019s conference I saw schmoozing between countless AI-for-police startups and the chiefs they sell to on the expo floor). Departments say these technologies save time, ease officer shortages, and help cut down on response times.",
    "Those sound like fine goals, but this pace of adoption raises an obvious question: Who makes the rules here? When does the use of AI cross over from efficiency into surveillance, and what type of transparency is owed to the public? In some cases, AI-powered police tech is already driving a wedge between departments and the communities they serve. When the police in Chula Vista, California, were the first in the country to get special waivers from the Federal Aviation Administration to fly their drones farther than normal, they said the drones would be deployed to solve crimes and get people help sooner in emergencies. They\u2019ve had some successes.\u00a0 But the department has also been sued by a local media outlet alleging it has reneged on its promise to make drone footage public, and residents have said the drones buzzing overhead feel like an invasion of privacy. An investigation found that these drones were deployed more often in poor neighborhoods, and for minor issues like loud music.\u00a0 Jay Stanley, a senior policy analyst at the ACLU, says there\u2019s no overarching federal law that governs how local police departments adopt technologies like the tracking software I wrote about. Departments usually have the leeway to try it first, and see how their communities react after the fact. (Veritone, which makes the tool I wrote about, said they couldn\u2019t name or connect me with departments using it so the details of how it\u2019s being deployed by police are not yet clear).\u00a0 Sometimes communities take a firm stand; local laws against police use of facial recognition have been passed around the country. But departments\u2014or the police tech companies they buy from\u2014can find workarounds. Stanley says the new tracking software I wrote about poses lots of the same issues as facial recognition while escaping scrutiny because it doesn\u2019t technically use biometric data. \u201cThe community should be very skeptical of this kind of tech and, at a minimum, ask a lot of questions,\u201d he says. He laid out a road map of what police departments should do before they adopt AI technologies: have hearings with the public, get community permission, and make promises about how the systems will and will not be used. He added that the companies making this tech should also allow it to be tested by independent parties.\u00a0 \u201cThis is all coming down the pike,\u201d he says\u2014and so quickly that policymakers and the public have little time to keep up. He adds, \u201cAre these powers we want the police\u2014the authorities that serve us\u2014to have, and if so, under what conditions?\u201d This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,\u00a0sign up here. hide"
  ]
}