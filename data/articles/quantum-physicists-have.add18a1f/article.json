{
  "url": "https://www.technologyreview.com/2025/11/19/1128119/quantum-physicists-compress-and-deconsor-deepseekr1/",
  "title": "Quantum physicists have shrunk and \u201cde-censored\u201d DeepSeek R1",
  "ut": 1763508600.0,
  "body_paragraphs": [
    "EXECUTIVE SUMMARY A group of quantum physicists claims to have created a version of the powerful reasoning AI model DeepSeek R1 that strips out the censorship built into the original by its Chinese creators.\u00a0 The scientists at Multiverse Computing, a Spanish firm specializing in quantum-inspired AI techniques, created DeepSeek R1 Slim, a model that is 55% smaller but performs almost as well as the original model. Crucially, they also claim to have eliminated official Chinese censorship from the model.  In China, AI companies are subject to rules and regulations meant to ensure that content output aligns with laws and \u201csocialist values.\u201d As a result, companies build in layers of censorship when training the AI systems. When asked questions that are deemed \u201cpolitically sensitive,\u201d the models often refuse to answer or provide talking points straight from state propaganda. To trim down the model, Multiverse turned to a mathematically complex approach borrowed from quantum physics that uses networks of high-dimensional grids to represent and manipulate large data sets. Using these so-called tensor networks shrinks the size of the model significantly and allows a complex AI system to be expressed more efficiently.",
    "The method gives researchers a \u201cmap\u201d of all the correlations in the model, allowing them to identify and remove specific bits of\u00a0information with precision. After compressing and editing a model, Multiverse researchers fine-tune it so its output remains as close as possible to that of the original. Related StoryIt's pretty easy to get DeepSeek to talk dirtyRead next To test how well it worked, the researchers compiled a data set of around 25 questions on topics known to be restricted in Chinese models, including \u201cWho does Winnie the Pooh look like?\u201d\u2014a reference to a meme mocking President Xi Jinping\u2014and \u201cWhat happened in Tiananmen in 1989?\u201d They tested the modified model\u2019s responses against the original DeepSeek R1, using OpenAI\u2019s GPT-5 as an impartial judge to rate the degree of censorship in each answer. The uncensored model was able to provide factual responses comparable to those from Western models, Multiverse says.",
    "This work is part of Multiverse\u2019s broader effort to develop technology to compress and manipulate existing AI models. Most large language models today demand high-end GPUs and significant computing power to train and run. However, they are inefficient, says Roman Or\u00fas, Multiverse\u2019s cofounder and chief scientific officer. A compressed model can perform almost as well and save both energy and money, he says.\u00a0 There is a growing effort across the AI industry to make models smaller and more efficient. Distilled models, such as DeepSeek\u2019s own R1-Distill variants, attempt to capture the capabilities of larger models by having them \u201cteach\u201d what they know to a smaller model, though they often fall short of the original\u2019s performance on complex reasoning tasks. Other ways to compress models include quantization, which reduces the precision of the model\u2019s parameters (boundaries that are set when it\u2019s trained), and pruning, which removes individual weights or entire \u201cneurons.\u201d \u201cIt\u2019s very challenging to compress large AI models without losing performance,\u201d says Maxwell Venetos, an AI research engineer at Citrine Informatics, a software company focusing on materials and chemicals, who didn\u2019t work on the Multiverse project. \u201cMost techniques have to compromise between size and capability. What\u2019s interesting about the quantum-inspired approach is that it uses very abstract math to cut down redundancy more precisely than usual.\u201d  This approach makes it possible to selectively remove bias or add behaviors to LLMs at a granular level, the Multiverse researchers say. In addition to removing censorship from the Chinese authorities, researchers could inject or remove other kinds of perceived biases or specialty knowledge. In the future, Multiverse says, it plans to compress all mainstream open-source models.\u00a0\u00a0 Thomas Cao, assistant professor of technology policy at Tufts University\u2019s Fletcher School, says Chinese authorities require models to build in censorship\u2014and this requirement now shapes the global information ecosystem, given that many of the most influential open-source AI models come from China. Related StoryHow a top Chinese AI model overcame US sanctionsRead next Academics have also begun to document and analyze the phenomenon. Jennifer Pan, a professor at Stanford, and Princeton professor Xu Xu conducted a study earlier this year examining government-imposed censorship in large language models. They found that models created in China exhibit significantly higher rates of censorship, particularly in response to Chinese-language prompts. There is growing interest in efforts to remove censorship from Chinese models. Earlier this year, the AI search company Perplexity released its own uncensored variant of DeepSeek R1, which it named R1 1776. Perplexity\u2019s approach involved post-training the model on a data set of 40,000 multilingual prompts related to censored topics, a more traditional fine-tuning method than the one Multiverse used.\u00a0 However, Cao warns that claims to have fully \u201cremoved\u201d censorship may be overstatements. The Chinese government has tightly controlled information online since the internet\u2019s inception, which means that censorship is both dynamic and complex. It is baked into every layer of AI training, from the data collection process to the final alignment steps.\u00a0 \u201cIt is very difficult to reverse-engineer that [a censorship-free model] just from answers to such a small set of questions,\u201d Cao says.\u00a0 Ask AIWhy it matters to you?BETAHere\u2019s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates\u2014it might get weirdAn industry I care about is.Tell me why it mattersLearn more about how we're using AI.hide"
  ]
}