{
  "url": "https://www.technologyreview.com/2026/01/23/1131559/americas-coming-war-over-ai-regulation/",
  "title": "America\u2019s coming war over AI regulation",
  "ut": 1769124600.0,
  "body_paragraphs": [
    "MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here. In the final weeks of 2025, the battle over regulating artificial intelligence in the US reached a boiling point. On December 11, after Congress failed twice to pass a law banning state AI laws, President Donald Trump signed a sweeping executive order seeking to handcuff states from regulating the booming industry. Instead, he vowed to work with Congress to establish a \u201cminimally burdensome\u201d national AI policy, one that would position the US to win the global AI race. The move marked a qualified victory for tech titans, who have been marshaling multimillion-dollar war chests to oppose AI regulations, arguing that a patchwork of state laws would stifle innovation.  In 2026, the battleground will shift to the courts. While some states might back down from passing AI laws, others will charge ahead, buoyed by mounting public pressure to protect children from chatbots and rein in power-hungry data centers. Meanwhile, dueling super PACs bankrolled by tech moguls and AI-safety advocates will pour tens of millions into congressional and state elections to seat lawmakers who champion their competing visions for AI regulation.\u00a0 Trump\u2019s executive order directs the Department of Justice to establish a task force that sues states whose AI laws clash with his vision for light-touch regulation. It also directs the Department of Commerce to starve states of federal broadband funding if their AI laws are \u201conerous.\u201d In practice, the order may target a handful of laws in Democratic states, says James Grimmelmann, a law professor at Cornell Law School. \u201cThe executive order will be used to challenge a smaller number of provisions, mostly relating to transparency and bias in AI, which tend to be more liberal issues,\u201d Grimmelmann says.",
    "Ask AIWhy it matters to you?BETAHere\u2019s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates\u2014it might get weirdA location I care about is.Tell me why it mattersLearn more about how we're using AI. For now, many states aren\u2019t flinching. On December 19, New York\u2019s governor, Kathy Hochul, signed the Responsible AI Safety and Education (RAISE) Act, a landmark law requiring AI companies to publish the protocols used to ensure the safe development of their AI models and report critical safety incidents. On January 1, California debuted the nation\u2019s first frontier AI safety law, SB 53\u2014which the RAISE Act was modeled on\u2014aimed at preventing catastrophic harms such as biological weapons or cyberattacks. While both laws were watered down from earlier iterations to survive bruising industry lobbying, they struck a rare, if fragile, compromise between tech giants and AI safety advocates. If Trump targets these hard-won laws, Democratic states like California and New York will likely take the fight to court. Republican states like Florida with vocal champions for AI regulation might follow suit. Trump could face an uphill battle. \u201cThe Trump administration is stretching itself thin with some of its attempts to effectively preempt [legislation] via executive action,\u201d says Margot Kaminski, a law professor at the University of Colorado Law School. \u201cIt\u2019s on thin ice.\u201d",
    "But Republican states that are anxious to stay off Trump\u2019s radar or can\u2019t afford to lose federal broadband funding for their sprawling rural communities might retreat from passing or enforcing AI laws. Win or lose in court, the chaos and uncertainty could chill state lawmaking. Paradoxically, the Democratic states that Trump wants to rein in\u2014armed with big budgets and emboldened by the optics of battling the administration\u2014may be the least likely to budge. In lieu of state laws, Trump promises to create a federal AI policy with Congress. But the gridlocked and polarized body won\u2019t be delivering a bill this year. In July, the Senate killed a moratorium on state AI laws that had been inserted into a tax bill, and in November, the House scrapped an encore attempt in a defense bill. In fact, Trump\u2019s bid to strong-arm Congress with an executive order may sour any appetite for a bipartisan deal.\u00a0 The executive order \u201chas made it harder to pass responsible AI policy by hardening a lot of positions, making it a much more partisan issue,\u201d says Brad Carson, a former Democratic congressman from Oklahoma who is building a network of super PACs backing candidates who support AI regulation. \u201cIt hardened Democrats and created incredible fault lines among Republicans,\u201d he says.\u00a0 While AI accelerationists in Trump\u2019s orbit\u2014AI and crypto czar David Sacks among them\u2014champion deregulation, populist MAGA firebrands like Steve Bannon warn of rogue superintelligence and mass unemployment. In response to Trump\u2019s executive order, Republican state attorneys general signed a bipartisan letter urging the FCC not to supersede state AI laws. With Americans increasingly anxious about how AI could harm mental health, jobs, and the environment, public demand for regulation is growing. If Congress stays paralyzed, states will be the only ones acting to keep the AI industry in check. In 2025, state legislators introduced more than 1,000 AI bills, and nearly 40 states enacted over 100 laws, according to the National Conference of State Legislatures. Efforts to protect children from chatbots may inspire rare consensus. On January 7, Google and Character Technologies, a startup behind the companion chatbot Character.AI, settled several lawsuits with families of teenagers who killed themselves after interacting with the bot. Just a day later, the Kentucky attorney general sued Character Technologies, alleging that the chatbots drove children to suicide and other forms of self-harm. OpenAI and Meta face a barrage of similar suits. Expect more to pile up this year. Without AI laws on the books, it remains to be seen how product liability laws and free speech doctrines apply to these novel dangers. \u201cIt\u2019s an open question what the courts will do,\u201d says Grimmelmann.\u00a0 While litigation brews, states will move to pass child safety laws, which are exempt from Trump\u2019s proposed ban on state AI laws. On January 9, OpenAI inked a deal with a former foe, the child-safety advocacy group Common Sense Media, to back a ballot initiative in California called the Parents & Kids Safe AI Act, setting guardrails around how chatbots interact with children. The measure proposes requiring AI companies to verify users\u2019 age, offer parental controls, and undergo independent child-safety audits. If passed, it could be a blueprint for states across the country seeking to crack down on chatbots.\u00a0 Fueled by widespread backlash against data centers, states will also try to regulate the resources needed to run AI. That means bills requiring data centers to report on their power and water use and foot their own electricity bills. If AI starts to displace jobs at scale, labor groups might float AI bans in specific professions. A few states concerned about the catastrophic risks posed by AI may pass safety bills mirroring SB 53 and the RAISE Act.\u00a0 Meanwhile, tech titans will continue to use their deep pockets to crush AI regulations. Leading the Future, a super PAC backed by OpenAI president Greg Brockman and the venture capital firm Andreessen Horowitz, will try to elect candidates who endorse unfettered AI development to Congress and state legislatures. They\u2019ll follow the crypto industry\u2019s playbook for electing allies and writing the rules. To counter this, super PACs funded by Public First, an organization run by Carson and former Republican congressman Chris Stewart of Utah, will back candidates advocating for AI regulation. We might even see a handful of candidates running on anti-AI populist platforms. In 2026, the slow, messy process of American democracy will grind on. And the rules written in state capitals could decide how the most disruptive technology of our generation develops far beyond America\u2019s borders, for years to come. hide"
  ]
}