# Artificial intelligence3 daysOpenAI and Google are launching supercharged AI assistants. Here‚Äôs how you can try them out.

## Summary ü§ñ

Google and OpenAI have announced supercharged AI assistants that can conduct real time conversations with humans. OpenAI's new model, GPT-4o can interpret anything users point their smartphone camera at and provide assistance with tasks like coding and translating text. It will be available for free, but with usage caps. Google's assistant, named Gemini Live, is comparable to GPT-4o and communicates via live video. It will be launched in the coming months and cost $20 per month post a free two-month trial. Both products will also include voice functions and are touted to be safe, after being rigorously tested by the respective companies.


## Follow-up Questions ü§ñ

1. How does the "response delay" in the OpenAI's GPT-4o compare to other similar AI models in terms of efficiency?
2. What are some specific tasks that the AI models are being designed to handle for the users?
3. Can you go into more detail about Google's Project Astra, and what it is expected to achieve?
4. Could you elaborate on the testing and safety evaluations conducted on these AI models?
5. How could these AI models potentially impact the daily routine of the average person?
6. What are the potential concerns or risks surrounding the use of AI in this capacity?
7. How will the roll-out method impact the positioning of both OpenAI and Google's products in the market?
8. Could you elaborate on the voice mode features that will initially be available only to a "small group" of developers?
9. What are some examples of the "unique demands" users might present when the models are launched?
10. Can you explain some specific measures that are being taken to prevent these AI bots from "hallucinating" false information?
11. What is the significance of the models‚Äô ability to ‚Äúremember‚Äù the location of objects, as demonstrated by Project Astra?
12. Could you elaborate on the planned future applications of these AI models such as embedding into smart glasses mentioned by Google DeepMind?


## Full Text

[https://www.technologyreview.com/2024/05/15/1092516/openai-and-google-are-launching-supercharged-ai-assistants-heres-how-you-can-try-them-out/](https://www.technologyreview.com/2024/05/15/1092516/openai-and-google-are-launching-supercharged-ai-assistants-heres-how-you-can-try-them-out/)

*02:18 PM, Wednesday, May 15, 2024*

 This week, Google and OpenAI both announced they‚Äôve built supercharged AI assistants: tools that can converse with you in real time and recover when you interrupt them, analyze your surroundings via live video, and translate conversations on the fly.¬† OpenAI struck first on Monday, when it debuted its new flagship model GPT-4o. The live demonstration showed it reading bedtime stories and helping to solve math problems, all in a voice that sounded eerily like Joaquin Phoenix‚Äôs AI girlfriend in the movie Her (a trait not lost on CEO Sam Altman).¬†  On Tuesday, Google announced its own new tools, including a conversational assistant called Gemini Live, which can do many of the same things. It also revealed that it‚Äôs building a sort of ‚Äúdo-everything‚Äù AI agent, which is currently in development but will not be released until later this year. Soon you‚Äôll be able to explore for yourself to gauge whether you‚Äôll turn to these tools in your daily routine as much as their makers hope, or whether they‚Äôre more like a sci-fi party trick that eventually loses its charm. Here‚Äôs what you should know about how to access these new tools, what you might use them for, and how much it will cost.¬† 

OpenAI‚Äôs GPT-4o What it‚Äôs capable of: The model can talk with you in real time, with a response delay of about 320 milliseconds, which OpenAI says is on par with natural human conversation. You can ask the model to interpret anything you point your smartphone camera at, and it can provide assistance with tasks like coding or translating text. It can also summarize information, and generate images, fonts, and 3D renderings.¬† How to access it: OpenAI says it will start rolling out GPT-4o‚Äôs text and vision features in the web interface as well as the GPT app, but has not set a date. The company says it will add the voice functions in the coming weeks, although it‚Äôs yet to set an exact date for this either. Developers can access the text and vision features in the API now, but voice mode will launch only to a ‚Äúsmall group‚Äù of developers initially. 

How much it costs: Use of GPT-4o will be free, but OpenAI will set caps on how much you can use the model before you need to upgrade to a paid plan. Those who join one of OpenAI‚Äôs paid plans, which start at $20 per month, will have five times more capacity on GPT-4o.¬† Google‚Äôs Gemini Live¬† What is Gemini Live? This is the Google product most comparable to GPT-4o‚Äîa version of the company‚Äôs AI model that you can speak with in real time. Google says that you‚Äôll also be able to use the tool to communicate via live video ‚Äúlater this year.‚Äù The company promises it will be a useful conversational assistant for things like preparing for a job interview or rehearsing a speech. How to access it: Gemini Live launches in ‚Äúthe coming months‚Äù via Google‚Äôs premium AI plan, Gemini Advanced.¬† How much it costs: Gemini Advanced offers a two-month free trial period and costs $20 per month thereafter.¬† But wait, what‚Äôs Project Astra? Astra is a project to build a do-everything AI agent, which was demoed at Google‚Äôs I/O conference but will not be released until later this year. People will be able to use Astra through their smartphones and possibly desktop computers, but the company is exploring other options too, such as embedding it into smart glasses or other devices, Oriol Vinyals, vice president of research at Google DeepMind, told MIT Technology Review. Which is better? It‚Äôs hard to tell without having hands on the full versions of these models ourselves. Google showed off Project Astra through a polished video, whereas OpenAI opted to debut GPT-4o via a seemingly more authentic live demonstration, but in both cases, the models were asked to do things the designers likely already practiced. The real test will come when they‚Äôre debuted to millions of users with unique demands.¬†¬† That said, if you compare OpenAI‚Äôs published videos with Google‚Äôs, the two leading tools look very similar, at least in their ease of use. To generalize, GPT-4o seems to be slightly ahead on audio, demonstrating realistic voices, conversational flow, and even singing, whereas Project Astra shows off more advanced visual capabilities, like being able to ‚Äúremember‚Äù where you left your glasses. OpenAI‚Äôs decision to roll out the new features more quickly might mean its product will get more use at first than Google‚Äôs, which won‚Äôt be fully available until later this year. It‚Äôs too soon to tell which model "hallucinates" false information less often or creates more useful responses. 

Are they safe? Both OpenAI and Google say their models are well tested: OpenAI says GPT-4o was evaluated by more than 70 experts in fields like misinformation and social psychology, and Google has said that Gemini "has the most comprehensive safety evaluations of any Google AI model to date, including for bias and toxicity.‚Äù¬† But these companies are building a future where AI models search, vet, and evaluate the world‚Äôs information for us to serve up a concise answer to our questions. Even more so than with simpler chatbots, it‚Äôs wise to remain skeptical about what they tell you. Additional reporting by Melissa Heikkil√§. hide

