{
  "url": "https://www.technologyreview.com/2025/09/02/1122856/can-an-ai-doppelganger-help-me-do-my-job/",
  "title": "Can an AI doppelg\u00e4nger help me do my job?",
  "ut": 1756769400.0,
  "body_paragraphs": [
    "Everywhere I look, I see AI clones. On X and LinkedIn, \u201cthought leaders\u201d and influencers offer their followers a chance to ask questions of their digital replicas. OnlyFans creators are having AI models of themselves chat, for a price, with followers. \u201cVirtual human\u201d salespeople in China are reportedly outselling real humans.\u00a0 Digital clones\u2014AI models that replicate a specific person\u2014package together a few technologies that have been around for a while now: hyperrealistic video models to match your appearance, lifelike voices based on just a couple of minutes of speech recordings, and conversational chatbots increasingly capable of holding our attention. But they\u2019re also offering something the ChatGPTs of the world cannot: an AI that\u2019s not smart in the general sense, but that 'thinks' like you do.\u00a0  Who are they for? Delphi, a startup that recently raised $16 million from funders including Anthropic and actor/director Olivia Wilde\u2019s venture capital firm, Proximity Ventures, helps famous people create replicas that can speak with their fans in both chat and voice calls. It feels like MasterClass\u2014the platform for instructional seminars led by celebrities\u2014vaulted into the AI age. On its website, Delphi writes that modern leaders \u201cpossess potentially life-altering knowledge and wisdom, but their time is limited and access is constrained.\u201d It has a library of official clones created by famous figures that you can speak with. Arnold Schwarzenegger, for example, told me, \u201cI\u2019m here to cut the crap and help you get stronger and happier,\u201d before informing me cheerily that I\u2019ve now been signed up to receive the Arnold\u2019s Pump Club newsletter. Even if his or other celebrities\u2019 clones fall short of Delphi\u2019s lofty vision of spreading \u201cpersonalized wisdom at scale,\u201d they at least seem to serve as a funnel to find fans, build mailing lists, or sell supplements.",
    "But what about for the rest of us? Could well-crafted clones serve as our stand-ins? I certainly feel stretched thin at work sometimes, wishing I could be in two places at once, and I bet you do too. I could see a replica popping into a virtual meeting with a PR representative, not to trick them into thinking it\u2019s the real me, but simply to take a brief call on my behalf. A recording of this call might summarize how it went.\u00a0 To find out, I tried making a clone. Tavus, a Y Combinator alum that raised $18 million last year, will build a video avatar of you (plans start at $59 per month) that can be coached to reflect your personality and can join video calls. These clones have the \u201cemotional intelligence of humans, with the reach of machines,\u201d according to the company. \u201cReporter\u2019s assistant\u201d does not appear on the company\u2019s site as an example use case, but it does mention therapists, physician\u2019s assistants, and other roles that could benefit from an AI clone.",
    "For Tavus\u2019s onboarding process, I turned on my camera, read through a script to help it learn my voice (which also acted as a waiver, with me agreeing to lend my likeness to Tavus), and recorded one minute of me just sitting in silence. Within a few hours, my avatar was ready. Upon meeting this digital me, I found it looked and spoke like I do (though I hated its teeth). But faking my appearance was the easy part. Could it learn enough about me and what topics I cover to serve as a stand-in with minimal risk of embarrassing me? Via a helpful chatbot interface, Tavus walked me through how to craft my clone\u2019s personality, asking what I wanted the replica to do. It then helped me formulate instructions that became its operating manual. I uploaded three dozen of my stories that it could use to reference what I cover. It may have benefited from having more of my content\u2014interviews, reporting notes, and the like\u2014but I would never share that data for a host of reasons, not the least of which being that the other people who appear in it have not consented to their sides of our conversations being used to train an AI replica. So in the realm of AI\u2014where models learn from entire libraries of data\u2014I didn\u2019t give my clone all that much to learn from, but I was still hopeful it had enough to be useful.\u00a0 Alas, conversationally it was a wild card. It acted overly excited about story pitches I would never pursue. It repeated itself, and it kept saying it was checking my schedule to set up a meeting with the real me, which it could not do as I never gave it access to my calendar. It spoke in loops, with no way for the person on the other end to wrap up the conversation.\u00a0  These are common early quirks, Tavus\u2019s cofounder Quinn Favret told me. The clones typically rely on Meta\u2019s Llama model, which \u201coften aims to be more helpful than it truly is,\u201d Favret says, and developers building on top of Tavus\u2019s platform are often the ones who set instructions for how the clones finish conversations or access calendars. For my purposes, it was a bust. To be useful to me, my AI clone would need to show at least some basic instincts for understanding what I cover, and at the very least not creep out whoever\u2019s on the other side of the conversation. My clone fell short. Related StoryWe need to start wrestling with the ethics of AI agentsAI could soon not only mimic our personality, but go out and act on our behalf. There are some things we need to sort out before then.",
    "Such a clone could be helpful in other jobs, though. If you\u2019re an influencer looking for ways to engage with more fans, or a salesperson for whom work is a numbers game and a clone could give you a leg up, it might just work. You run the risk that your replica could go off the rails or embarrass the real you, but the tradeoffs might be reasonable.\u00a0 Favret told me some of Tavus\u2019s bigger customers are companies using clones for health-care intake and job interviews. Replicas are also being used in corporate role-play, for practicing sales pitches or having HR-related conversations with employees, for example.",
    "But companies building clones are promising that they will be much more than cold-callers or telemarketing machines. Delphi says its clones will offer \u201cmeaningful, personal interactions at infinite scale,\u201d and Tavus says its replicas have \u201ca face, a brain, and memories\u201d that enable \u201cmeaningful face-to-face conversations.\u201d Favret also told me a growing number of Tavus\u2019s customers are building clones for mentorship and even decision-making, like AI loan officers who use clones to qualify and filter applicants. Which is sort of the crux of it. Teaching an AI clone discernment, critical thinking, and taste\u2014never mind the quirks of a specific person\u2014is still the stuff of science fiction. That\u2019s all fine when the person chatting with a clone is in on the bit (most of us know that Schwarzenegger\u2019s replica, for example, will not coach me to be a better athlete). But as companies polish clones with \u201chuman\u201d features and exaggerate their capabilities, I worry that people chasing efficiency will start using their replicas at best for roles that are cringeworthy, and at worst for making decisions they should never be entrusted with. In the end, these models are designed for scale, not fidelity. They can flatter us, amplify us, even sell for us\u2014but they can\u2019t quite become us. This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,\u00a0sign up here.  hide"
  ]
}