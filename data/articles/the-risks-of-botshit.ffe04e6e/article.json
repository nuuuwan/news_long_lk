{
  "url": "https://hbr.org/2024/07/the-risks-of-botshit",
  "title": "The Risks of Botshit",
  "ut": 1721198155.0,
  "body_paragraphs": [
    "Illustration by HBR Staff",
    "Botshit \u2014 made-up, inaccurate, and untruthful chatbot content that humans uncritically use for tasks \u2014 can pose major risks to your business in the form of reputational damage, incorrect decisions, legal liability, economic losses, and even human safety. Yet, it\u2019s unlikely that chatbots are going away. How can you manage these risks while taking advantage of the benefits of promising new tools? The authors suggest asking two key questions based on their research: How important is chatbot response veracity for a task? And how difficult is it to verify the veracity of the chatbot response? Based on your responses to these questions, you can better identify the risks associated with a given task \u2014 and successfully mitigate them.",
    "Hot off the heels of OpenAI releasing their GenAI chatbot ChatGPT to the public in November 2022, Google released their own chatbot called Bard (now Gemini). During Bard\u2019s first public demonstration, it generated a major factual error in response to a question about the discoveries made by the James Webb Space Telescope. This wrong answer by the chatbot led to a 9% drop in the stock price of Alphabet, Google\u2019s parent company \u2014\u00a0 at the time, $100 billion in market value.",
    "Read more on AI and machine learning",
    "Technology and analytics and Quality management"
  ]
}