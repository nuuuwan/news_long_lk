# OpenAI just released GPT-4.5 and says it is its biggest and best chat model yet

[https://www.technologyreview.com/2025/02/27/1112619/openai-just-released-gpt-4-5-and-says-it-is-its-biggest-and-best-chat-model-yet/](https://www.technologyreview.com/2025/02/27/1112619/openai-just-released-gpt-4-5-and-says-it-is-its-biggest-and-best-chat-model-yet/)

*03:27 PM, Thursday, February 27, 2025*

OpenAI has just released GPT-4.5, a new version of its flagship large language model. The company claims it is its biggest and best model for all-round chat yet. “It’s really a step forward for us,” says Mia Glaese, a research scientist at OpenAI. Since the releases of its so-called reasoning models o1 and o3, OpenAI has been pushing two product lines. GPT-4.5 is part of the non-reasoning lineup—what Glaese’s colleague Nick Ryder, also a research scientist, calls “an installment in the classic GPT series.”  People with a $200-a-month ChatGPT Pro account can try out GPT-4.5 today. OpenAI says it will begin rolling out to other users next week. With each release of its GPT models, OpenAI has shown that bigger means better. But there has been a lot of talk about how that approach is hitting a wall—including remarks from OpenAI’s former chief scientist Ilya Sutskever. The company’s claims about GPT-4.5 feel like a thumb in the eye to the naysayers.

All large language models pick up patterns across the billions of documents they are trained on. Smaller models learned syntax and basic facts. Bigger models can find more specific patterns like emotional cues, such as when a speaker’s words signal hostility, says Ryder: “All of these subtle patterns that come through a human conversation—those are the bits that these larger and larger models will pick up on.” “It has the ability to engage in warm, intuitive, natural, flowing conversations,” says Glaese. “And we think that it has a stronger understanding of what users mean, especially when their expectations are more implicit, leading to nuanced and thoughtful responses.”

Making it hum “We kind of know what the engine looks like at this point, and now it’s really about making it hum,” says Ryder. “This is primarily an exercise in scaling up the compute, scaling up the data, finding more efficient training methods, and then pushing the frontier.” OpenAI won’t say exactly how big its new model is. But it claims the jump in scale from GPT-4o to GPT-4.5 is the same as the jump from GPT-3.5 to GPT-4o. Experts have estimated that GPT-4 could have as many as 1.8 trillion parameters, the values that get tweaked when a model is trained.  GPT-4.5 was trained with techniques similar to those used for its predecessor GPT-4o, including human-led fine-tuning and reinforcement learning with human feedback. “The key to creating intelligent systems is a recipe we’ve been following for many years, which is to find scalable paradigms where we can pour more and more resources in to get more intelligent systems out,” says Ryder.  Unlike reasoning models such as o1 and o3, which work through answers step by step, most large language models like GPT-4.5 spit out the first response they come up with. But GPT-4.5 is more general-purpose. Tested on SimpleQA, a kind of general-knowledge quiz developed by OpenAI last year that includes questions on topics from science and technology to TV shows and video games, GPT-4.5 scores 62.5% compared with 38.6% for GPT-4o and 15% for o3-mini. What’s more, OpenAI claims that GPT-4.5 responds with far fewer made-up answers (known as hallucinations). On the same test, GPT-4.5 made up answers 37.1% of the time, compared with 59.8% for GPT-4o and 80.3% for o3-mini. But SimpleQA is just one benchmark. On other tests, including MMLU, a more common benchmark for comparing large language models, GPT-4.5 beat OpenAI's previous models by a smaller margin. And on standard science and math benchmarks, GPT-4.5 scores worse than o3-mini. Turning on the charm GPT-4.5’s special charm seems to be its conversational skills. Human testers employed by OpenAI say they preferred GPT-4.5 to GPT-4o for everyday queries, professional queries, and creative tasks, including coming up with poems. (Ryder says it is also great at old-school internet ACSII art.)

For example, tell it that you're going through a rough patch and GPT-4.5 might offer a few words of sympathy before saying: "Want to talk about what happened, or do you just need a distraction? I'm here either way." GPT-4o is less good at reading social cues and might try to fix the problem whether you asked it to or not, hitting you with a bullet point list of ways to cheer yourself up.  And yet after years at the top, OpenAI faces a tough crowd. “The focus on emotional intelligence and creativity is cool for niche use cases like writing coaches and brainstorming buddies,” says Waseem Alshikh, cofounder and CTO of Writer, a startup that develops large language models for enterprise customers. “But GPT-4.5 feels like a shiny new coat of paint on the same old car,” he says. “Throwing more compute and data at a model can make it sound smoother, but it’s not a game-changer.” “The juice isn’t worth the squeeze when you consider the energy costs and the fact that most users won’t notice the difference in daily use,” he says. “I’d rather see them pivot to efficiency or niche problem-solving than keep supersizing the same recipe.” Sam Altman has said that GPT-4.5 will be the last release in OpenAI’s classic lineup and that GPT-5 will be a hybrid that combines a general-purpose large language model with a reasoning model. “GPT-4.5 is OpenAI phoning it in while they cook up something bigger behind closed doors," says Alshikh. “Until then, this feels like a pit stop.” Of course, OpenAI insists that its supersized approach still has legs. “Personally, I’m very optimistic about finding ways through those bottlenecks and continuing to scale,” says Ryder. “I think there’s something extremely profound and exciting about pattern-matching across all of human knowledge.” hide

