{
  "url": "https://www.technologyreview.com/2024/06/19/1094027/kling-kuaishou-video-ai-china/",
  "title": "I tested out a buzzy new text-to-video AI model from China",
  "ut": 1718753400.0,
  "body_paragraphs": [
    "This story first appeared in China Report, MIT Technology Review\u2019s newsletter about technology in China. Sign up to receive it in your inbox every Tuesday. You may not be familiar with Kuaishou, but this Chinese company just hit a major milestone: It\u2019s released the first text-to-video generative AI model that\u2019s freely available for the public to test.  The short-video platform, which has over 600 million active users, announced the new tool on June 6. It\u2019s called Kling. Like OpenAI\u2019s Sora model, Kling is able to generate videos \u201cup to two minutes long with a frame rate of 30fps and video resolution up to 1080p,\u201d the company says on its website. But unlike Sora, which still remains inaccessible to the public four months after OpenAI trialed it, Kling soon started letting people try the model themselves.",
    "I was one of them. I got access to it after downloading Kuaishou\u2019s video-editing tool, signing up with a Chinese number, getting on a waitlist, and filling out an additional form through Kuaishou\u2019s user feedback groups. The model can\u2019t process prompts written entirely in English, but you can get around that by either translating the phrase you want to use into Chinese or including one or two Chinese words. So, first things first. Here are a few results I generated with Kling to show you what it\u2019s like. Remember Sora\u2019s impressive demo video of Tokyo\u2019s street scenes or the cat darting through a garden? Here are Kling\u2019s takes:",
    "Prompt: Beautiful, snowy Tokyo city is bustling. The camera moves through the bustling city street, following several people enjoying the beautiful snowy weather and shopping at nearby stalls. Gorgeous sakura petals are flying through the wind along with snowflakes.ZEYI YANG/MIT TECHNOLOGY REVIEW | KLING  Prompt: A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse. She wears sunglasses and red lipstick. She walks confidently and casually. The street is damp and reflective, creating a mirror effect of the colorful lights. Many pedestrians walk about.ZEYI YANG/MIT TECHNOLOGY REVIEW | KLING  Prompt: A white and orange tabby cat is seen happily darting through a dense garden, as if chasing something. Its eyes are wide and happy as it jogs forward, scanning the branches, flowers, and leaves as it walks. The path is narrow as it makes its way between all the plants. The scene is captured from a ground-level angle, following the cat closely, giving a low and intimate perspective. The image is cinematic with warm tones and a grainy texture. The scattered daylight between the leaves and plants above creates a warm contrast, accentuating the cat's orange fur. The shot is clear and sharp, with a shallow depth of field.ZEYI YANG/MIT TECHNOLOGY REVIEW | KLING  Remember the image of Dall-E\u2019s horse-riding astronaut? I asked Kling to generate a video version too.\u00a0 Prompt: An astronaut riding a horse in space.ZEYI YANG/MIT TECHNOLOGY REVIEW | KLING  There are a few things worth applauding here. None of these videos deviates from the prompt much, and the physics seem right\u2014the panning of the camera, the ruffling leaves, and the way the horse and astronaut turn, showing Earth behind them. The generation process took around three minutes for each of them. Not the fastest, but totally acceptable.\u00a0 But there are obvious shortcomings, too. The videos, while 720p in format, seem blurry and grainy; sometimes Kling ignores a major request in the prompt; and most important, all videos generated now are capped at five seconds long, which makes them far less dynamic or complex. However, it\u2019s not really fair to compare these results with things like Sora\u2019s demos, which are hand-picked by OpenAI to release to the public and probably represent better-than-average results. These Kling videos are from the first attempts I had with each prompt, and I rarely included prompt-engineering keywords like \u201c8k, photorealism\u201d to fine-tune the results.\u00a0  If you want to see more Kling-generated videos, check out this handy collection put together by an open-source AI community in China, which includes both impressive results and all kinds of failures. Kling\u2019s general capabilities are good enough, says Guizang, an AI artist in Beijing who has been testing out the model since its release and has compiled a series of direct comparisons between Sora and Kling. Kling\u2019s disadvantage lies in the aesthetics of the results, he says, like the composition or the color grading. \u201cBut that\u2019s not a big issue. That can be fixed quickly,\u201d Guizang, who wished to be identified only by his online alias, tells MIT Technology Review.\u00a0 \u201cThe core capability of a model is in how it simulates physics and real natural environments,\u201d and he says Kling does well in that regard. Kling works in a similar way to Sora: it combines the diffusion models traditionally used in video-generation AIs with a transformer architecture, which helps it understand larger video data files and generate results more efficiently.",
    "But Kling may have a key advantage over Sora: Kuaishou, the most prominent rival to Douyin in China, has a massive video platform with hundreds of millions of users who have collectively uploaded an incredibly big trove of video data that could be used to train it. Kuaishou told MIT Technology Review in a statement that \u201cKling uses publicly available data from the global internet for model training, in accordance with industry standards.\u201d However, the company didn\u2019t elaborate on the specifics of the training data(neither did OpenAI about Sora, which has led to concerns about intellectual-property protections). After testing the model, I feel the biggest limitation to Kling\u2019s usefulness is that it only generates five-second-long videos. \u201cThe longer a video is, the more likely it will hallucinate or generate inconsistent results,\u201d says Shen Yang, a professor studying AI and media at Tsinghua University in Beijing. That limitation means the technology will leave a larger impact on the short-video industry than it does on the movie industry, he says.\u00a0 Related StoryChina\u2019s next cultural export could be TikTok-style short soap operasThese apps are betting on low-budget productions, two-minute episodes, scripts adapted from Chinese web novels, and an aggressive marketing strategy.",
    "Short, vertical videos (those designed for viewing on phones) usually grab the attention of viewers in a few seconds. Shen says Chinese TikTok-like platforms often assess whether a video is successful by how many people would watch through the first three or five seconds before they scroll away\u2014so an AI-generated high-quality video clip that\u2019s just five seconds long could be a game-changer for short-video creators.\u00a0  Guizang agrees that AI could disrupt the content-creating scene for short-form videos. It will benefit creators in the short term as a productivity tool; but in the long run, he worries that platforms like Kuaishou and Douyin could take over the production of videos and directly generate content customized for users, reducing the platforms\u2019 reliance on star creators. It might still take quite some time for the technology to advance to that level, but the field of text-to-video tools is getting much more buzzy now. One week after Kling\u2019s release, a California-based startup called Luma AI also released a similar model for public usage. Runway, a celebrity startup in video generation, has teased a significant update that will make its model much more powerful. ByteDance, Kuaishou\u2019s biggest rival, is also reportedly working on the release of its generative video tool soon. \u201cBy the end of this year, we will have a lot of options available to us,\u201d Guizang says. I asked Kling to generate what society looks like when \u201canyone can quickly generate a video clip based on their own needs.\u201d And here\u2019s what it gave me. Impressive hands, but you didn\u2019t answer the question\u2014sorry. Prompt: With the release of Kuaishou\u2019s Kling model, the barrier to entry for creating short videos has been lowered, resulting in significant impacts on the short-video industry. Anyone can quickly generate a video clip based on their own needs. Please show what the society will look like at that time.ZEYI YANG/MIT TECHNOLOGY REVIEW | KLING  Do you have a prompt you want to see generated with Kling? Send it to zeyi@technologyreview.com and I\u2019ll send you back the result. The prompt has to be less than 200 characters long, and preferably written in Chinese.",
    "Now read the rest of China Report Catch up with China 1. A new investigation revealed that the US military secretly ran a campaign to post anti-vaccine propaganda on social media in 2020 and 2021, aiming to sow distrust in the Chinese-made covid vaccines in Southeast Asian countries. (Reuters $) 2. A Chinese court sentenced Huang Xueqin, the journalist who helped launch the #MeToo movement in China, to five years in prison for \u201cinciting subversion of state power.\u201d (Washington Post $)",
    "3. A Shein executive said the company\u2019s corporate values basically make it an American company, but the company is now trying to hide that remark to avoid upsetting Beijing. (Financial Times $) 4. China is getting close to building the world\u2019s largest particle collider, potentially starting in 2027. (Nature) 5. To retaliate for the European Union\u2019s raising tariffs on electric vehicles, the Chinese government has opened an investigation into allegedly unfair subsidies for Europe\u2019s pork exports. (New York Times $)  On a related note about food: China\u2019s exploding demand for durian fruit in recent years has created a $6 billion business in Southeast Asia, leading some farmers to cut down jungles and coffee plants to make way for durian plantations. (New York Times $)  Lost in translation In 2012, Jiumei, a Chinese woman in her 20s, began selling a service where she sends \u201cgood night\u201d text messages to people online at the price of 1 RMB per text (that\u2019s about $0.14).\u00a0 Twelve years, three mobile phones, four different numbers, and over 50,000 messages later, she\u2019s still doing it, according to the Chinese online publication Personage. Some of her clients are buying the service for themselves, hoping to talk to someone regularly at their most lonely or desperate times. Others are buying it to send anonymous messages\u2014to a friend going through a hard time, or an ex-lover who has cut off communications.\u00a0 The business isn\u2019t very profitable. Jiumei earns around 3,000 RMB ($410) annually from it on top of her day job, and even less in recent years. But she\u2019s persisted because the act of sending these messages has become a nightly ritual\u2014not just for her customers but also for Jiumei herself, offering her solace in her own times of loneliness and hardship. One more thing Globally, Kuaishou has been much less successful than its nemesis ByteDance, except in one country: Brazil. Kwai, the overseas version of Kuaishou, has been so popular in Brazil that even the Marubo people, a tribal group in the remote Amazonian rainforests and one of the last communities to be connected online, have begun using the app, according to the New York Times. hide"
  ]
}