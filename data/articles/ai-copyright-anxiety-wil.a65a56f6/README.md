# AI copyright anxiety will hold back creativity

[https://www.technologyreview.com/2025/06/17/1118898/ai-copyright-anxiety-will-hold-back-creativity/](https://www.technologyreview.com/2025/06/17/1118898/ai-copyright-anxiety-will-hold-back-creativity/)

*06:00 AM, Tuesday, June 17, 2025*

Last fall, while attending a board meeting in Amsterdam, I had a few free hours and made an impromptu visit to the Van Gogh Museum. I often steal time for visits like this—a perk of global business travel for which I am grateful. Wandering the galleries, I found myself before The Courtesan (after Eisen), painted in 1887. Van Gogh had based it on a Japanese woodblock print by Keisai Eisen, which he encountered in the magazine Paris Illustré. He explicitly copied and reinterpreted Eisen’s composition, adding his own vivid border of frogs, cranes, and bamboo. As I stood there, I imagined the painting as the product of a generative AI model prompted with the query How would van Gogh reinterpret a Japanese woodblock in the style of Keisai Eisen? And I wondered: If van Gogh had used such an AI tool to stimulate his imagination, would Eisen—or his heirs—have had a strong legal claim?  If van Gogh were working today, that might be the case. Two years ago, the US Supreme Court found that Andy Warhol had infringed upon the photographer Lynn Goldsmith’s copyright by using her photo of the musician Prince for a series of silkscreens. The court said the works were not sufficiently transformative to constitute fair use—a provision in the law that allows for others to make limited use of copyrighted material.  A few months later, at the Museum of Fine Arts in Boston, I visited a Salvador Dalí exhibition. I had always thought of Dalí as a true original genius who conjured surreal visions out of thin air. But the show included several Dutch engravings, including Pieter Bruegel the Elder’s Seven Deadly Sins (1558), that clearly influenced Dalí’s 8 Mortal Sins Suite (1966). The stylistic differences are significant, but the lineage is undeniable. Dalí himself cited Bruegel as a surrealist forerunner, someone who tapped into the same dream logic and bizarre forms that Dalí celebrated. Suddenly, I was seeing Dalí not just as an original but also as a reinterpreter. Should Bruegel have been flattered that Dalí built on his work—or should he have sued him for making it so “grotesque”? Related StoryHow AI can help supercharge creativityForget one-click creativity. These artists and musicians are finding new ways to make art using AI, by injecting friction, challenge, and serendipity into the process.

During a later visit to a Picasso exhibit in Milan, I came across a famous informational diagram by the art historian Alfred Barr, mapping how modernist movements like Cubism evolved from earlier artistic traditions. Picasso is often held up as one of modern art’s most original and influential figures, but Barr’s chart made plain the many artists he drew from—Goya, El Greco, Cézanne, African sculptors. This made me wonder: If a generative AI model had been fed all those inputs, might it have produced Cubism? Could it have generated the next great artistic “breakthrough”?

These experiences—spread across three cities and centered on three iconic artists—coalesced into a broader reflection I’d already begun. I had recently spoken with Daniel Ek, the founder of Spotify, about how restrictive copyright laws are in music. Song arrangements and lyrics enjoy longer protection than many pharmaceutical patents. Ek sits at the leading edge of this debate, and he observed that generative AI already produces an astonishing range of music. Some of it is good. Much of it is terrible. But nearly all of it borrows from the patterns and structures of existing work. Musicians already routinely sue one another for borrowing from previous works. How will the law adapt to a form of artistry that’s driven by prompts and precedent, built entirely on a corpus of existing material?

And the questions don’t stop there. Who, exactly, owns the outputs of a generative model? The user who crafted the prompt? The developer who built the model? The artists whose works were ingested to train it? Will the social forces that shape artistic standing—critics, curators, tastemakers—still hold sway? Or will a new, AI-era hierarchy emerge? If every artist has always borrowed from others, is AI’s generative recombination really so different? And in such a litigious culture, how long can copyright law hold its current form? The US Copyright Office has begun to tackle the thorny issues of ownership and says that generative outputs can be copyrighted if they are sufficiently human-authored. But it is playing catch-up in a rapidly evolving field.  Different industries are responding in different ways. The Academy of Motion Picture Arts and Sciences recently announced that filmmakers’ use of generative AI would not disqualify them from Oscar contention—and that they wouldn’t be required to disclose when they’d used the technology. Several acclaimed films, including Oscar winner The Brutalist, incorporated AI into their production processes. The music world, meanwhile, continues to wrestle with its definitions of originality. Consider the recent lawsuit against Ed Sheeran. In 2016, he was sued by the heirs of Ed Townsend, co-writer of Marvin Gaye’s “Let’s Get It On,” who claimed that Sheeran’s “Thinking Out Loud” copied the earlier song’s melody, harmony, and rhythm. When the case finally went to trial in 2023, Sheeran brought a guitar to the stand. He played the disputed four-chord progression—I–iii–IV–V—and wove together a mash-up of songs built on the same foundation. The point was clear: These are the elemental units of songwriting. After a brief deliberation, the jury found Sheeran not liable. Reflecting after the trial, Sheeran said: “These chords are common building blocks … No one owns them or the way they’re played, in the same way no one owns the colour blue.”  Exactly. Whether it’s expressed with a guitar, a paintbrush, or a generative algorithm, creativity has always been built on what came before. I don’t consider this essay to be great art. But I should be transparent: I relied extensively on ChatGPT while drafting it. I began with a rough outline, notes typed on my phone in museum galleries, and transcripts from conversations with colleagues. I uploaded older writing samples to give the model a sense of my voice. Then I used the tool to shape a draft, which I revised repeatedly—by hand and with help from an editor—over several weeks. There may still be phrases or sentences in here that came directly from the model. But I’ve iterated so much that I no longer know which ones. Nor, I suspect, could any reader—or any AI detector. (In fact, Grammarly found that 0% of this text appeared to be AI-generated.) Many people today remain uneasy about using these tools. They worry it’s cheating, or feel embarrassed to admit that they’ve sought such help. I’ve moved past that. I assume all my students at Harvard Business School are using AI. I assume most academic research begins with literature scanned and synthesized by these models. And I assume that many of the essays I now read in leading publications were shaped, at least in part, by generative tools.

Why? Because we are professionals. And professionals adopt efficiency tools early. Generative AI joins a long lineage that includes the word processor, the search engine, and editing tools like Grammarly. The question is no longer Who’s using AI? but Why wouldn’t you? I recognize the counterargument, notably put forward by Nicholas Thompson, CEO of the Atlantic: that content produced with AI assistance should not be eligible for copyright protection, because it blurs the boundaries of authorship. I understand the instinct. AI recombines vast corpora of preexisting work, and the results can feel derivative or machine-like. But when I reflect on the history of creativity—van Gogh reworking Eisen, Dalí channeling Bruegel, Sheeran defending common musical DNA—I’m reminded that recombination has always been central to creation. The economist Joseph Schumpeter famously wrote that innovation is less about invention than “the novel reassembly of existing ideas.” If we tried to trace and assign ownership to every prior influence, we’d grind creativity to a halt. From the outset, I knew the tools had transformative potential. What I underestimated was how quickly they would become ubiquitous across industries and in my own daily work. Our copyright system has never required total originality. It demands meaningful human input. That standard should apply in the age of AI as well. When people thoughtfully engage with these models—choosing prompts, curating inputs, shaping the results—they are creating. The medium has changed, but the impulse remains the same: to build something new from the materials we inherit.  Nitin Nohria is the George F. Baker Jr. Professor at Harvard Business School and its former dean. He is also the chair of Thrive Capital, an early investor in several prominent AI firms, including OpenAI. MIT Technology Review’s editorial guidelines state that generative AI should not be used to draft articles unless the article is meant to illustrate the capabilities of such tools and its use is clearly disclosed.  hide

