{
  "url": "https://www.technologyreview.com/2025/12/15/1128352/rise-of-ai-coding-developers-2026/",
  "title": "AI coding is now everywhere. But not everyone is convinced.",
  "ut": 1765755000.0,
  "body_paragraphs": [
    "Depending who you ask, AI-powered coding is either giving software developers an unprecedented productivity boost or churning out masses of poorly designed code that saps their attention and sets software projects up for serious long term-maintenance problems. The problem is right now, it\u2019s not easy to know which is true.  As tech giants pour billions into large language models (LLMs), coding has been touted as the technology\u2019s killer app. Both Microsoft CEO Satya Nadella and Google CEO Sundar Pichai have claimed that around a quarter of their companies\u2019 code is now AI-generated. And in March, Anthropic\u2019s CEO, Dario Amodei, predicted that within six months 90% of all code would be written by AI. It\u2019s an appealing and obvious use case. Code is a form of language, we need lots of it, and it\u2019s expensive to produce manually. It\u2019s also easy to tell if it works\u2014run a program and it\u2019s immediately evident whether it\u2019s functional.  This story is part of MIT Technology Review\u2019s Hype Correction package, a series that resets expectations about what AI is, what it makes possible, and where we go next.   Executives enamored with the potential to break through human bottlenecks are pushing engineers to lean into an AI-powered future. But after speaking to more than 30 developers, technology executives, analysts, and researchers, MIT Technology Review found that the picture is not as straightforward as it might seem.\u00a0\u00a0 For some developers on the front lines, initial enthusiasm is waning as they bump up against the technology\u2019s limitations. And as a growing body of research suggests that the claimed productivity gains may be illusory, some are questioning whether the emperor is wearing any clothes.",
    "The pace of progress is complicating the picture, though. A steady drumbeat of new model releases mean these tools\u2019 capabilities and quirks are constantly evolving. And their utility often depends on the tasks they are applied to and the organizational structures built around them. All of this leaves developers navigating confusing gaps between expectation and reality.\u00a0 Is it the best of times or the worst of times (to channel Dickens) for AI coding? Maybe both.",
    "A fast-moving field It\u2019s hard to avoid AI coding tools these days. There are a dizzying array of products available, both from model developers like Anthropic, OpenAI, and Google and from companies like Cursor and Windsurf, which wrap these models in polished code-editing software. And according to Stack Overflow\u2019s 2025 Developer Survey, they\u2019re being adopted rapidly, with 65% of developers now using them at least weekly. AI coding tools first emerged around 2016 but were supercharged with the arrival of LLMs. Early versions functioned as little more than autocomplete for programmers, suggesting what to type next. Today they can analyze entire code bases, edit across files, fix bugs, and even generate documentation explaining how the code works. All this is guided through natural-language prompts via a chat interface.  \u201cAgents\u201d\u2014autonomous LLM-powered coding tools that can take a high-level plan and build entire programs independently\u2014represent the latest frontier in AI coding. This leap was enabled by the latest reasoning models, which can tackle complex problems step by step and, crucially, access external tools to complete tasks. \u201cThis is how the model is able to code, as opposed to just talk about coding,\u201d says Boris Cherny, head of Claude Code, Anthropic\u2019s coding agent. Ask AIWhy it matters to you?BETAHere\u2019s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates\u2014it might get weirdAn industry I care about is.Tell me why it mattersLearn more about how we're using AI. These agents have made impressive progress on software engineering benchmarks\u2014standardized tests that measure model performance. When OpenAI introduced the SWE-bench Verified benchmark in August 2024, offering a way to evaluate agents\u2019 success at fixing real bugs in open-source repositories, the top model solved just 33% of issues. A year later, leading models consistently score above 70%.\u00a0 In February, Andrej Karpathy, a founding member of OpenAI and former director of AI at Tesla, coined the term \u201cvibe coding\u201d\u2014meaning an approach where people describe software in natural language and let AI write, refine, and debug the code. Social media abounds with developers who have bought into this vision, claiming massive productivity boosts. But while some developers and companies report such productivity gains, the hard evidence is more mixed. Early studies from GitHub, Google, and Microsoft\u2014all vendors of AI tools\u2014found developers completing tasks 20% to 55% faster. But a September report from the consultancy Bain & Company described real-world savings as \u201cunremarkable.\u201d",
    "Advertisement Data from the developer analytics firm GitClear shows that most engineers are producing roughly 10% more durable code\u2014code that isn\u2019t deleted or rewritten within weeks\u2014since 2022, likely thanks to AI. But that gain has come with sharp declines in several measures of code quality. Stack Overflow\u2019s survey also found trust and positive sentiment toward AI tools falling significantly for the first time. And most provocatively, a July study by the nonprofit research organization Model Evaluation & Threat Research (METR) showed that while experienced developers believed AI made them 20% faster, objective tests showed they were actually 19% slower. Growing disillusionment For Mike Judge, principal developer at the software consultancy Substantial, the METR study struck a nerve. He was an enthusiastic early adopter of AI tools, but over time he grew frustrated with their limitations and the modest boost they brought to his productivity. \u201cI was complaining to people because I was like, \u2018It\u2019s helping me but I can\u2019t figure out how to make it really help me a lot,\u2019\u201d he says. \u201cI kept feeling like the AI was really dumb, but maybe I could trick it into being smart if I found the right magic incantation.\u201d Related StoryWhat is vibe coding, exactly?Read next When asked by a friend, Judge had estimated the tools were providing a roughly 25% speedup. So when he saw similar estimates attributed to developers in the METR study he decided to test his own. For six weeks, he guessed how long a task would take, flipped a coin to decide whether to use AI or code manually, and timed himself. To his surprise, AI slowed him down by an median of 21%\u2014mirroring the METR results. This got Judge crunching the numbers. If these tools were really speeding developers up, he reasoned, you should see a massive boom in new apps, website registrations, video games, and projects on GitHub. He spent hours and several hundred dollars analyzing all the publicly available data and found flat lines everywhere.",
    "\u201cShouldn\u2019t this be going up and to the right?\u201d says Judge. \u201cWhere\u2019s the hockey stick on any of these graphs? I thought everybody was so extraordinarily productive.\u201d The obvious conclusion, he says, is that AI tools provide little productivity boost for most developers.\u00a0 Developers interviewed by MIT Technology Review generally agree on where AI tools excel: producing \u201cboilerplate code\u201d (reusable chunks of code repeated in multiple places with little modification), writing tests, fixing bugs, and explaining unfamiliar code to new developers. Several noted that AI helps overcome the \u201cblank page problem\u201d by offering an imperfect first stab to get a developer\u2019s creative juices flowing. It can also let nontechnical colleagues quickly prototype software features, easing the load on already overworked engineers. These tasks can be tedious, and developers are typically\u00a0 glad to hand them off. But they represent only a small part of an experienced engineer\u2019s workload. For the more complex problems where engineers really earn their bread, many developers told MIT Technology Review, the tools face significant hurdles. Perhaps the biggest problem is that LLMs can hold only a limited amount of information in their \u201ccontext window\u201d\u2014essentially their working memory. This means they struggle to parse large code bases and are prone to forgetting what they\u2019re doing on longer tasks. \u201cIt gets really nearsighted\u2014it\u2019ll only look at the thing that\u2019s right in front of it,\u201d says Judge. \u201cAnd if you tell it to do a dozen things, it\u2019ll do 11 of them and just forget that last one.\u201d",
    "DEREK BRAHNEY   LLMs\u2019 myopia can lead to headaches for human coders. While an LLM-generated response to a problem may work in isolation, software is made up of hundreds of interconnected modules. If these aren\u2019t built with consideration for other parts of the software, it can quickly lead to a tangled, inconsistent code base that\u2019s hard for humans to parse and, more important, to maintain. Developers have traditionally addressed this by following conventions\u2014loosely defined coding guidelines that differ widely between projects and teams. \u201cAI has this overwhelming tendency to not understand what the existing conventions are within a repository,\u201d says Bill Harding, the CEO of GitClear. \u201cAnd so it is very likely to come up with its own slightly different version of how to solve a problem.\u201d Advertisement The models also just get things wrong. Like all LLMs, coding models are prone to \u201challucinating\u201d\u2014it\u2019s an issue built into how they work. But because the code they output looks so polished, errors can be difficult to detect, says James Liu, director of software engineering at the advertising technology company Mediaocean. Put all these flaws together, and using these tools can feel a lot like pulling a lever on a one-armed bandit. \u201cSome projects you get a 20x improvement in terms of speed or efficiency,\u201d says Liu. \u201cOn other things, it just falls flat on its face, and you spend all this time trying to coax it into granting you the wish that you wanted and it\u2019s just not going to.\u201d Judge suspects this is why engineers often overestimate productivity gains. \u201cYou remember the jackpots. You don\u2019t remember sitting there plugging tokens into the slot machine for two hours,\u201d he says.  And it can be particularly pernicious if the developer is unfamiliar with the task. Judge remembers getting AI to help set up a Microsoft cloud service called an Azure Functions, which he\u2019d never used before. He thought it would take about two hours, but nine hours later he threw in the towel. \u201cIt kept leading me down these rabbit holes and I didn\u2019t know enough about the topic to be able to tell it \u2018Hey, this is nonsensical,\u2019\u201d he says. The debt begins to mount up Developers\u00a0constantly make trade-offs between speed of development and the maintainability of their code\u2014creating what\u2019s known as \u201ctechnical debt,\u201d says Geoffrey G. Parker, professor of engineering innovation at Dartmouth College. Each shortcut adds complexity and makes the code base harder to manage, accruing \u201cinterest\u201d that must eventually be repaid by restructuring the code. As this debt piles up, adding new features and maintaining the software becomes slower and more difficult.",
    "Accumulating technical debt is inevitable in most projects, but AI tools make it much easier for time-pressured engineers to cut corners, says GitClear\u2019s Harding. And GitClear\u2019s data suggests this is happening at scale. Since 2020, the company has seen a significant rise in the amount of copy-pasted code\u2014an indicator that developers are reusing more code snippets, most likely based on AI suggestions\u2014and an even bigger decline in the amount of code moved from one place to another, which happens when developers clean up their code base. Related StoryThe second wave of AI coding is hereRead next And as models improve, the code they produce is becoming increasingly verbose and complex, says Tariq Shaukat, CEO of Sonar, which makes tools for checking code quality. This is driving down the number of obvious bugs and security vulnerabilities, he says, but at the cost of increasing the number of \u201ccode smells\u201d\u2014harder-to-pinpoint flaws that lead to maintenance problems and technical debt.",
    "Recent research by Sonar found that these make up more than 90% of the issues found in code generated by leading AI models. \u201cIssues that are easy to spot are disappearing, and what\u2019s left are much more complex issues that take a while to find,\u201d says Shaukat. \u201cThat\u2019s what worries us about this space at the moment. You\u2019re almost being lulled into a false sense of security.\u201d If AI tools make it increasingly difficult to maintain code, that could have significant security implications, says Jessica Ji, a security researcher at Georgetown University. \u201cThe harder it is to update things and fix things, the more likely a code base or any given chunk of code is to become insecure over time,\u201d says Ji. There are also more specific security concerns, she says. Researchers have discovered a worrying class of hallucinations where models reference nonexistent software packages in their code. Attackers can exploit this by creating packages with those names that harbor vulnerabilities, which the model or developer may then unwittingly incorporate into software.\u00a0 LLMs are also vulnerable to \u201cdata-poisoning attacks,\u201d where hackers seed the publicly available data sets models train on with data that alters the model\u2019s behavior in undesirable ways, such as generating insecure code when triggered by specific phrases. In October, research by Anthropic found that as few as 250 malicious documents can introduce this kind of back door into an LLM regardless of its size.  The converted Despite these issues, though, there\u2019s probably no turning back. \u201cOdds are that writing every line of code on a keyboard by hand\u2014those days are quickly slipping behind us,\u201d says Kyle Daigle, chief operating officer at the Microsoft-owned code-hosting platform GitHub, which produces a popular AI-powered tool called Copilot (not to be confused with the Microsoft product of the same name). The Stack Overflow report found that despite growing distrust in the technology, usage has increased rapidly and consistently over the past three years. Erin Yepis, a senior analyst at Stack Overflow, says this suggests that engineers are taking advantage of the tools with a clear-eyed view of the risks. The report also found that frequent users tend to be more enthusiastic and more than half of developers are not using the latest coding agents, perhaps explaining why many remain underwhelmed by the technology. Those latest tools can be a revelation. Trevor Dilley, CTO at the software development agency Twenty20 Ideas, says he had found some value in AI editors\u2019 autocomplete functions, but when he tried anything more complex it would \u201cfail catastrophically.\u201d Then in March, while on vacation with his family, he set the newly released Claude Code to work on one of his hobby projects. It completed a four-hour task in two minutes, and the code was better than what he would have written. \u201cI was like, Whoa,\u201d he says. \u201cThat, for me, was the moment, really. There\u2019s no going back from here.\u201d Dilley has since cofounded a startup called DevSwarm, which is creating software that can marshal multiple agents to work in parallel on a piece of software.",
    "The challenge, says Armin Ronacher, a prominent open-source developer, is that the learning curve for these tools is shallow but long. Until March he\u2019d remained unimpressed by AI tools, but after leaving his job at the software company Sentry in April to launch a startup, he started experimenting with agents. \u201cI basically spent a lot of months doing nothing but this,\u201d he says. \u201cNow, 90% of the code that I write is AI-generated.\u201d Getting to that point involved extensive trial and error, to figure out which problems tend to trip the tools up and which they can handle efficiently. Today\u2019s models can tackle most coding tasks with the right guardrails, says Ronacher, but these can be very task and project specific. To get the most out of these tools, developers must surrender control over individual lines of code and focus on the overall software architecture, says Nico Westerdale, chief technology officer at the veterinary staffing company IndeVets. He recently built a data science platform 100,000 lines of code long almost exclusively by prompting models rather than writing the code himself. Westerdale\u2019s process starts with an extended conversation with the modelagent to develop a detailed plan for what to build and how. He then guides it through each step. It rarely gets things right on the first try and needs constant wrangling, but if you force it to stick to well-defined design patterns, the models can produce high-quality, easily maintainable code, says Westerdale. He reviews every line, and the code is as good as anything he\u2019s ever produced, he says: \u201cI\u2019ve just found it absolutely revolutionary,. It\u2019s also frustrating, difficult, a different way of thinking, and we\u2019re only just getting used to it.\u201d  But while individual developers are learning how to use these tools effectively, getting consistent results across a large engineering team is significantly harder. AI tools amplify both the good and bad aspects of your engineering culture, says Ryan J. Salva, senior director of product management at Google. With strong processes, clear coding patterns, and well-defined best practices, these tools can shine.\u00a0  DEREK BRAHNEY   But if your development process is disorganized, they\u2019ll only magnify the problems. It\u2019s also essential to codify that institutional knowledge so the models can draw on it effectively. \u201cA lot of work needs to be done to help build up context and get the tribal knowledge out of our heads,\u201d he says. Advertisement The cryptocurrency exchange Coinbase has been vocal about its adoption of AI tools. CEO Brian Armstrong made headlines in August when he revealed that the company had fired staff unwilling to adopt AI tools. But Coinbase\u2019s head of platform, Rob Witoff, tells MIT Technology Review that while they\u2019ve seen massive productivity gains in some areas, the impact has been patchy. For simpler tasks like restructuring the code base and writing tests, AI-powered workflows have achieved speedups of up to 90%. But gains are more modest for other tasks, and the disruption caused by overhauling existing processes often counteracts the increased coding speed, says Witoff. One factor is that AI tools let junior developers produce far more code,. As in almost all engineering teams, this code has to be reviewed by others, normally more senior developers, to catch bugs and ensure it meets quality standards. But the sheer volume of code now being churned out i whichs quickly saturatinges the ability of midlevel staff to review changes. \u201cThis is the cycle we\u2019re going through almost every month, where we automate a new thing lower down in the stack, which brings more pressure higher up in the stack,\u201d he says. \u201cThen we\u2019re looking at applying automation to that higher-up piece.\u201d Developers also spend only 20% to 40% of their time coding, says Jue Wang, a partner at Bain, so even a significant speedup there often translates to more modest overall gains. Developers spend the rest of their time analyzing software problems and dealing with customer feedback, product strategy, and administrative tasks. To get significant efficiency boosts, companies may need to apply generative AI to all these other processes too, says Jue, and that is still in the works. Rapid evolution Programming with agents is a dramatic departure from previous working practices, though, so it\u2019s not surprising companies are facing some teething issues. These are also very new products that are changing by the day. \u201cEvery couple months the model improves, and there\u2019s a big step change in the model\u2019s coding capabilities and you have to get recalibrated,\u201d says Anthropic\u2019s Cherny. For example, in June Anthropic introduced a built-in planning mode to Claude; it has since been replicated by other providers. In October, the company also enabled Claude to ask users questions when it needs more context or faces multiple possible solutions, which Cherny says helps it avoid the tendency to simply assume which path is the best way forward. Related StoryI tried OpenAI\u2019s new Atlas browser but I still don\u2019t know what it\u2019s forRead next Most significant, Anthropic has added features that make Claude better at managing its own context. When it nears the limits of its working memory, it summarizes key details and uses them to start a new context window, effectively giving it an \u201cinfinite\u201d one, says Cherny. Claude can also invoke sub-agents to work on smaller tasks, so it no longer has to hold all aspects of the project in its own head. The company claims that its latest model, Claude 4.5 Sonnet, can now code autonomously for more than 30 hours without major performance degradation.  Novel approaches to software development could also sidestep coding agents\u2019 other flaws. MIT professor Max Tegmark has introduced something he calls \u201cvericoding,\u201d which could allow agents to produce entirely bug-free code from a natural-language description. It builds on an approach known as \u201cformal verification,\u201d where developers create a mathematical model of their software that can prove incontrovertibly that it functions correctly. This approach is used in high-stakes areas like flight-control systems and cryptographic libraries, but it remains costly and time-consuming, limiting its broader use. Rapid improvements in LLMs\u2019 mathematical capabilities have opened up the tantalizing possibility of models that produce not only software but the mathematical proof that it\u2019s bug free, says Tegmark. \u201cYou just give the specification, and the AI comes back with provably correct code,\u201d he says. \u201cYou don\u2019t have to touch the code. You don\u2019t even have to ever look at the code.\u201d When tested on about 2,000 vericoding problems in Dafny\u2014a language designed for formal verification\u2014the best LLMs solved over 60%, according to non-peer-reviewed research by Tegmark\u2019s group. This was achieved with off-the-shelf LLMs, and Tegmark expects that training specifically for vericoding could improve scores rapidly. And counterintuitively, Tthe speed at which AI generates code could actuallylso ease maintainability concerns. Alex Worden, principal engineer at the business software giant Intuit, notes that maintenance is often difficult because engineers reuse components across projects, creating a tangle of dependencies where one change triggers cascading effects across the code base. Reusing code used to save developers time, but in a world where AI can produce hundreds of lines of code in seconds, that imperative has gone, says Worden. Advertisement Instead, he advocates for \u201cdisposable code,\u201d where each component is generated independently by AI without regard for whether it follows design patterns or conventions. They are then connected via APIs\u2014sets of rules that let components request information or services from each other. Each component\u2019s inner workings are not dependent on other parts of the code base, making it possible to rip them out and replace them without wider impact, says Worden.\u00a0 \u201cThe industry is still concerned about humans maintaining AI-generated code,\u201d he says. \u201cI question how long humans will look at or care about code.\u201d A narrowing talent pipeline For the foreseeable future, though, humans will still need to understand and maintain the code that underpins their projects. And one of the most pernicious side effects of AI tools may be a shrinking pool of people capable of doing so.\u00a0 Early evidence suggests that fears around the job-destroying effects of AI may be justified. A recent Stanford University study found that employment among software developers aged 22 to 25 fell nearly 20% between 2022 and 2025, coinciding with the rise of AI-powered coding tools. Experienced developers could face difficulties too. Luciano Nooijen, an engineer at the video-game infrastructure developer Companion Group, used AI tools heavily in his day job, where they were provided for free. But when he began a side project without access to those tools, he found himself struggling with tasks that previously came naturally. \u201cI was feeling so stupid because things that used to be instinct became manual, sometimes even cumbersome,\u201d says Nooijen. Just as athletes still perform basic drills, he thinks the only way to maintain an instinct for coding is to regularly practice the grunt work. That\u2019s why he\u2019s largely abandoned AI tools, though he admits that deeper motivations are also at play.\u00a0 Part of the reason Nooijen and other developers MIT Technology Review spoke to are pushing back against AI tools is a sense that they are hollowing out the parts of their jobs that they love. \u201cI got into software engineering because I like working with computers. I like making machines do things that I want,\u201d Nooijen says. \u201cIt\u2019s just not fun sitting there with my work being done for me.\u201d"
  ]
}