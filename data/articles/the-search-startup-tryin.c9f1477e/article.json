{
  "url": "https://www.technologyreview.com/2024/12/03/1107726/the-startup-trying-to-turn-the-web-into-a-database/",
  "title": "The search startup trying to turn the web into a database",
  "ut": 1733211137.0,
  "body_paragraphs": [
    "A startup called Exa is pitching a new spin on generative search. It uses the tech behind large language models to return lists of results that it claims are more on point than those from its rivals, including Google and OpenAI. The aim is to turn the internet\u2019s chaotic tangle of web pages into a kind of directory, with results that are specific and precise. Exa already provides its search engine as a back-end service to companies that want to build their own applications on top of it. Today it is launching the first consumer version of that search engine, called Websets.\u00a0\u00a0 Related StoryThe ChatGPT-fueled battle for search is bigger than Microsoft or GoogleA frenzy of activity from tech giants and startups alike is reshaping what people want from search\u2014for better or worse.",
    "\u201cThe web is a collection of data, but it\u2019s a mess,\" says Exa cofounder and CEO Will Bryk. \"There's a Joe Rogan video over here, an Atlantic article over there. There's no organization. But the dream is for the web to feel like a database.\u201d Websets is aimed at power users who need to look for things that other search engines aren\u2019t great at finding, such as types of people or companies. Ask it for \u201cstartups making futuristic hardware\u201d and you get a list of specific companies hundreds long rather than hit-or-miss links to web pages that mention those terms. Google can\u2019t do that, says Bryk: \u201cThere\u2019s a lot of valuable use cases for investors or recruiters or really anyone who wants any sort of data set from the web.\u201d",
    "Things have moved fast since MIT Technology Review broke the news in 2021 that Google researchers were exploring the use of large language models in a new kind of search engine. The idea soon attracted fierce critics. But tech companies took little notice. Three years on, giants like Google and Microsoft jostle with a raft of buzzy newcomers like Perplexity and OpenAI, which launched ChatGPT Search in October, for a piece of this hot new trend. Exa isn\u2019t (yet) trying to out-do any of those companies. Instead, it\u2019s proposing something new. Most other search firms wrap large language models around existing search engines, using the models to analyze a user\u2019s query and then summarize the results. But the search engines themselves haven\u2019t changed much. Perplexity still directs its queries to Google Search or Bing, for example. Think of today\u2019s AI search engines as a sandwich with fresh bread but stale filling.",
    "More than keywords Exa provides users with familiar lists of links but uses the tech behind large language models to reinvent how search itself is done. Here\u2019s the basic idea: Google works by crawling the web and building a vast index of keywords that then get matched to users\u2019 queries. Exa crawls the web and encodes the contents of web pages into a format known as embeddings, which can be processed by large language models. Embeddings turn words into numbers in such a way that words with similar meanings become numbers with similar values. In effect, this lets Exa capture the meaning of text on web pages, not just the keywords. A screenshot of Websets showing results for the search: \"companies; startups; US-based; healthcare focus; technical co-founder\" Large language models use embeddings to predict the next words in a sentence. Exa\u2019s search engine predicts the next link. Type \u201cstartups making futuristic hardware\u201d and the model will come up with (real) links that might follow that phrase. Exa\u2019s approach comes at cost, however. Encoding pages rather than indexing keywords is slow and expensive. Exa has encoded some billion web pages, says Bryk. That\u2019s tiny next to Google, which has indexed around a trillion. But Bryk doesn\u2019t see this as a problem: \u201cYou don\u2019t have to embed the whole web to be useful,\u201d he says. (Fun fact: \u201cexa\u201d means a 1 followed by 18 0s and \u201cgoogol\u201d means a 1 followed by 100 0s.)  Websets is very slow at returning results. A search can sometimes take several minutes. But Bryk claims it\u2019s worth it. \u201cA lot of our customers started to ask for, like, thousands of results, or tens of thousands,\u201d he says. \u201cAnd they were okay with going to get a cup of coffee and coming back to a huge list.\u201d Related StoryWhy Google\u2019s AI Overviews gets things wrongGoogle\u2019s new AI search feature is a mess. So why is it telling us to eat rocks and gluey pizza, and can it be fixed?",
    "\u201cI find Exa most useful when I don't know exactly what I\u2019m looking for,\u201d says Andrew Gao, a computer science student at Stanford Univesrsity who has used the search engine. \u201cFor instance, the query \u2018an interesting blog post on LLMs in finance\u2019 works better on Exa than Perplexity.\u201d But they\u2019re good at different things, he says: \u201cI use both for different purposes.\u201d \u201cI think embeddings are a great way to represent entities like real-world people, places, and things,\u201d says Mike Tung, CEO of Diffbot, a company using knowledge graphs to build yet another kind of search engine. But he notes that you lose a lot of information if you try to embed whole sentences or pages of text: \u201cRepresenting War and Peace as a single embedding would lose nearly all of the specific events that happened in that story, leaving just a general sense of its genre and period.\u201d Bryk acknowledges that Exa is a work in progress. He points to other limitations, too. Exa is not as good as rival search engines if you just want to look up a single piece of information, such as the name of Taylor Swift\u2019s boyfriend or who Will Bryk is: \u201cIt\u2019ll give a lot of Polish-sounding people, because my last name is Polish and embeddings are bad at matching exact keywords,\u201d he says. For now Exa gets around this by throwing keywords back into the mix when they\u2019re needed. But Bryk is bullish: \u201cWe\u2019re covering up the gaps in the embedding method until the embedding method gets so good that we don\u2019t need to cover up the gaps.\u201d hide"
  ]
}