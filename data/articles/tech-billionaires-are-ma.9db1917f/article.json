{
  "url": "https://www.technologyreview.com/2025/06/13/1118198/agi-ai-superintelligence-billionaires/",
  "title": "Tech billionaires are making a risky bet with humanity\u2019s future",
  "ut": 1749774600.0,
  "body_paragraphs": [
    "\u201cThe best way to predict the future is to invent it,\u201d the famed computer scientist Alan Kay once said. Uttered more out of exasperation than as inspiration, his remark has nevertheless attained gospel-like status among Silicon Valley entrepreneurs, in particular a handful of tech billionaires who fancy themselves the chief architects of humanity\u2019s future.\u00a0 Sam Altman, Jeff Bezos, Elon Musk, and others may have slightly different goals and ambitions in the near term, but their grand visions for the next decade and beyond are remarkably similar. Framed less as technological objectives and more as existential imperatives, they include aligning AI with the interests of humanity; creating an artificial superintelligence that will solve all the world\u2019s most pressing problems; merging with that superintelligence to achieve immortality (or something close to it); establishing a permanent, self-\u00adsustaining colony on Mars; and, ultimately, spreading out across the cosmos.  While there\u2019s a sprawling patchwork of ideas and philosophies powering these visions, three features play a central role, says Adam Becker, a science writer and astrophysicist: an unshakable certainty that technology can solve any problem, a belief in the necessity of perpetual growth, and a quasi-religious obsession with transcending our physical and biological limits. In his timely new book, More Everything Forever: AI Overlords, Space Empires, and Silicon Valley\u2019s Crusade to Control the Fate of Humanity, Becker calls this triumvirate of beliefs the \u201cideology of technological salvation\u201d and warns that tech titans are using it to steer humanity in a dangerous direction.\u00a0  \u201cIn most of these isms you\u2019ll find the idea of escape and transcendence, as well as the promise of an amazing future, full of unimaginable wonders\u2014so long as we don\u2019t get in the way of technological progress.\u201d  \u201cThe credence that tech billionaires give to these specific science-fictional futures validates their pursuit of more\u2014to portray the growth of their businesses as a moral imperative, to reduce the complex problems of the world to simple questions of technology, [and] to justify nearly any action they might want to take,\u201d he writes. Becker argues that the only way to break free of these visions is to see them for what they are: a convenient excuse to continue destroying the environment, skirt regulations, amass more power and control, and dismiss the very real problems of today to focus on the imagined ones of tomorrow.",
    "A lot of critics, academics, and journalists have tried to define or distill the Silicon Valley ethos over the years. There was the \u201cCalifornian Ideology\u201d in the mid-\u201990s, the \u201cMove fast and break things\u201d era of the early 2000s, and more recently the \u201cLibertarianism for me, feudalism for thee\u201d\u00a0 or \u201ctechno-\u00adauthoritarian\u201d views. How do you see the \u201cideology of technological salvation\u201d fitting in?\u00a0 I\u2019d say it\u2019s very much of a piece with those earlier attempts to describe the Silicon Valley mindset. I mean, you can draw a pretty straight line from Max More\u2019s principles of transhumanism in the \u201990s to the Californian Ideology [a mashup of countercultural, libertarian, and neoliberal values] and through to what I call the ideology of technological salvation. The fact is, many of the ideas that define or animate Silicon Valley thinking have never been much of a \u00admystery\u2014libertarianism, an antipathy toward the government and regulation, the boundless faith in technology, the obsession with optimization.",
    "What can be difficult is to parse where all these ideas come from and how they fit together\u2014or if they fit together at all. I came up with the ideology of technological salvation as a way to name and give shape to a group of interrelated concepts and philosophies that can seem sprawling and ill-defined at first, but that actually sit at the center of a worldview shared by venture capitalists, executives, and other thought leaders in the tech industry.\u00a0 Readers will likely be familiar with the tech billionaires featured in your book and at least some of their ambitions. I\u2019m guessing they\u2019ll be less familiar with the various \u201cisms\u201d that you argue have influenced or guided their thinking. Effective altruism, rationalism, long\u00adtermism, extropianism, effective accelerationism, futurism, singularitarianism, \u00adtranshumanism\u2014there are a lot of them. Is there something that they all share?\u00a0 They\u2019re definitely connected. In a sense, you could say they\u2019re all versions or instantiations of the ideology of technological salvation, but there are also some very deep historical connections between the people in these groups and their aims and beliefs. The Extropians in the late \u201980s believed in self-\u00adtransformation through technology and freedom from limitations of any kind\u2014ideas that Ray Kurzweil eventually helped popularize and legitimize for a larger audience with the Singularity.\u00a0 In most of these isms you\u2019ll find the idea of escape and transcendence, as well as the promise of an amazing future, full of unimaginable wonders\u2014so long as we don\u2019t get in the way of technological progress. I should say that AI researcher Timnit Gebru and philosopher \u00c9mile Torres have also done a lot of great work linking these ideologies to one another and showing how they all have ties to racism, misogyny, and eugenics.  You argue that the Singularity is the purest expression of the ideology of technological salvation. How so? Well, for one thing, it\u2019s just this very simple, straightforward idea\u2014the Singularity is coming and will occur when we merge our brains with the cloud and expand our intelligence a millionfold. This will then deepen our awareness and consciousness and everything will be amazing. In many ways, it\u2019s a fantastical vision of a perfect technological utopia. We\u2019re all going to live as long as we want in an eternal paradise, watched over by machines of loving grace, and everything will just get exponentially better forever. The end. Related StoryFrom COBOL to chaos: Elon Musk, DOGE, and the Evil Housekeeper ProblemAs DOGE throws out the rule book for government tech, it\u2019s time we plan for the worst\u2014and look to each other for courage and support.",
    "The other isms I talk about in the book have a little more \u2026 heft isn\u2019t the right word\u2014they just have more stuff going on. There\u2019s more to them, right? The rationalists and the effective altruists and the longtermists\u2014they think that something like a singularity will happen, or could happen, but that there\u2019s this really big danger between where we are now and that potential event. We have to address the fact that an all-powerful AI might destroy humanity\u2014the so-called alignment problem\u2014before any singularity can happen.\u00a0 Then you\u2019ve got the effective accelerationists, who are more like Kurzweil, but they\u2019ve got more of a tech-bro spin on things. They\u2019ve taken some of the older transhumanist ideas from the Singularity and updated them for startup culture. Marc Andreessen\u2019s \u201cTechno-Optimist Manifesto\u201d [from 2023] is a good example. You could argue that all of these other philosophies that have gained purchase in Silicon Valley are just twists on Kurzweil\u2019s Singularity, each one building on top of the core ideas of transcendence, techno\u00ad-optimism, and exponential growth.",
    "Early on in the book you take aim at that idea of exponential growth\u2014specifically, Kurzweil\u2019s \u201cLaw of Accelerating Returns.\u201d Could you explain what that is and why you think it\u2019s flawed? Kurzweil thinks there\u2019s this immutable \u201cLaw of Accelerating Returns\u201d at work in the affairs of the universe, especially when it comes to technology. It\u2019s the idea that technological progress isn\u2019t linear but exponential. Advancements in one technology fuel even more rapid advancements in the future, which in turn lead to greater complexity and greater technological power, and on and on. This is just a mistake. Kurzweil uses the Law of Accelerating Returns to explain why the Singularity is inevitable, but to be clear, he\u2019s far from the only one who believes in this so-called law.  \u201cI really believe that when you get as rich as some of these guys are, you can just do things that seem like thinking and no one is really going to correct you or tell you things you don\u2019t want to hear.\u201d  My sense is that it\u2019s an idea that comes from staring at Moore\u2019s Law for too long. Moore\u2019s Law is of course the famous prediction that the number of transistors on a chip will double roughly every two years, with a minimal increase in cost. Now, that has in fact happened for the last 50 years or so, but not because of some fundamental law in the universe. It\u2019s because the tech industry made a choice and some very sizable investments to make it happen. Moore\u2019s Law was ultimately this really interesting observation or projection of a historical trend, but even Gordon Moore [who first articulated it] knew that it wouldn\u2019t and couldn\u2019t last forever. In fact, some think it\u2019s already over.\u00a0 These ideologies take inspiration from some pretty unsavory characters. Transhumanism, you say, was first popularized by the eugenicist Julian Huxley in a speech in 1951. Marc Andreessen\u2019s \u201cTechno-Optimist Manifesto\u201d name-checks the noted fascist Filippo Tommaso Marinetti and his futurist manifesto. Did you get the sense while researching the book that the tech titans who champion these ideas understand their dangerous origins?  You\u2019re assuming in the framing of that question that there\u2019s any rigorous thought going on here at all. As I say in the book, Andreessen\u2019s manifesto runs almost entirely on vibes, not logic. I think someone may have told him about the futurist manifesto at some point, and he just sort of liked the general vibe, which is why he paraphrases a part of it. Maybe he learned something about Marinetti and forgot it. Maybe he didn\u2019t care.\u00a0 I really believe that when you get as rich as some of these guys are, you can just do things that seem like thinking and no one is really going to correct you or tell you things you don\u2019t want to hear. For many of these billionaires, the vibes of fascism, authoritarianism, and colonialism are attractive because they\u2019re fundamentally about creating a fantasy of control.\u00a0 Related StorySorry, AI won\u2019t \u201cfix\u201d climate changeOpenAI\u2019s Sam Altman claims AI will deliver an \"Intelligence Age,\" but tech breakthroughs alone can't solve global warming.",
    "You argue that these visions of the future are being used to hasten environmental destruction, increase authoritarianism, and exacerbate inequalities. You also admit that they appeal to lots of people who aren\u2019t billionaires. Why do you think that is?\u00a0 I think a lot of us are also attracted to these ideas for the same reasons the tech billionaires are\u2014they offer this fantasy of knowing what the future holds, of transcending death, and a sense that someone or something out there is in control. It\u2019s hard to overstate how comforting a simple, coherent narrative can be in an increasingly complex and fast-moving world. This is of course what religion offers for many of us, and I don\u2019t think it\u2019s an accident that a sizable number of people in the rationalist and effective altruist communities are actually ex-evangelicals.",
    "More than any one specific technology, it seems like the most consequential thing these billionaires have invented is a sense of inevitability\u2014that their visions for the future are somehow predestined. How does one fight against that? It\u2019s a difficult question. For me, the answer was to write this book. I guess I\u2019d also say this: Silicon Valley enjoyed well over a decade with little to no pushback on anything. That\u2019s definitely a big part of how we ended up in this mess. There was no regulation, very little critical coverage in the press, and a lot of self-mythologizing going on. Things have started to change, especially as the social and environmental damage that tech companies and industry leaders have helped facilitate has become more clear. That understanding is an essential part of deflating the power of these tech billionaires and breaking free of their visions. When we understand that these dreams of the future are actually nightmares for the rest of us, I think you\u2019ll see that senseof inevitability vanish pretty fast.\u00a0 This interview was edited for length and clarity. Bryan Gardiner is a writer based in Oakland, California.\u00a0 hide"
  ]
}