{
  "url": "https://www.technologyreview.com/2024/07/09/1094774/can-ai-help-me-plan-my-honeymoon/",
  "title": "Can AI help me plan my honeymoon?",
  "ut": 1720484544.0,
  "body_paragraphs": [
    "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. I\u2019m getting married later this summer and am feverishly planning a honeymoon together with my fianc\u00e9. It has been at times overwhelming trying to research and decide between what seem like millions of options while juggling busy work schedules and wedding planning.  Thankfully, my colleague Rhiannon Williams has just published a piece about how to use AI to plan your vacation.\u00a0You can read her story here. The timing could not be better! I decided to put her tips to the test and use AI to plan my honeymoon itinerary. I asked ChatGPT to suggest a travel plan over three weeks in Japan and the Philippines, our dream destinations. I told the chatbot that in Tokyo I wanted to see art and design and eat good food, and in the Philippines I wanted to go somewhere laid-back and outdoorsy that is not very touristy. I also asked ChatGPT to be specific in its suggestions for hotels and activities to book.",
    "The results were pretty good, and they aligned with the research I had already done. I was delighted to see the AI propose we visit Siargao Island in the Philippines, which is known for its surfing. We were planning on going there anyway, but I haven\u2019t had a chance to do much research on what there is to do. ChatGPT came up with some divine-looking day trips involving a stingless-jellyfish sanctuary, cave pools, and other adventures.\u00a0 The AI produced a decent first draft of the trip itinerary. I reckon this saved me a lot of time doing research on planned destinations I didn\u2019t know much about, such as Siargao.",
    "But \u2026 when I asked about places I did know more about, such as Tokyo, I wasn\u2019t that impressed. ChatGPT suggested I visit Shibuya Crossing and eat at a sushi restaurant, which, like,\u00a0c\u2019mon, are some of the most obvious things for tourists to do there. However, I am willing to consider that the problem might have been me and my prompting. Because I found that the more specific I made my prompts, the better the results were.\u00a0 But here\u2019s the thing. Language models work by predicting the next likely word in a sentence. These AI systems don\u2019t have an understanding of what it is like to experience these things, or how long they take. For example, ChatGPT suggested spending one whole day taking photos at a scenic spot. That would get boring pretty quickly. The AI systems of today lack the kind of last-mile reasoning and planning skills that would help me with logistics and budgeting. It also suggested accommodations that were way out of our price range.\u00a0 But this whole process might become much smoother as we build the next generation of AI agents.\u00a0 Agents are AI algorithms and models that can complete complex tasks in the real world. The idea is that one day they could execute a vast range of tasks, much like a human assistant. Agents are the new hot thing in AI, and I just published an explainer looking at what they are and how they work.\u00a0You can read it here.\u00a0 In the future, an AI agent could not only suggest things to do and places to stay on my honeymoon; it would also go a step further than ChatGPT and book flights for me. It would remember my preferences and budget for hotels and only propose accommodation that matched my criteria. It might also remember what I liked to do on past trips, and suggest very specific things to do tailored to those tastes. It might even request bookings for restaurants on my behalf. Unfortunately for my honeymoon, today\u2019s AI systems lack the kind of reasoning, planning, and memory needed. It\u2019s still early days for these systems, and there are a lot of unsolved research questions. But who knows\u2014maybe for our 10th anniversary trip?\u00a0  Now read the rest of The Algorithm Deeper Learning A way to let robots learn by listening will make them more useful Most AI-powered robots today use cameras to understand their surroundings and learn new tasks, but it\u2019s becoming easier to train robots with sound too, helping them adapt to tasks and environments where visibility is limited.",
    "Sound on:\u00a0Researchers at Stanford University tested how much more successful a robot can be if it\u2019s capable of \u201clistening.\u201d They chose four tasks: flipping a bagel in a pan, erasing a whiteboard, putting two Velcro strips together, and pouring dice out of a cup. In each task, sounds provided clues that cameras or tactile sensors struggle with, like knowing if the eraser is properly contacting the whiteboard or whether the cup contains dice. When using vision alone in the last test, the robot could tell 27% of the time whether there were dice in the cup, but that rose to 94% when sound was included.\u00a0Read more from James O\u2019Donnell. Bits and Bytes AI lie detectors are better than humans at spotting liesResearchers at the University of W\u00fcrzburg in Germany found that an AI system was significantly better at spotting fabricated statements than humans. Humans usually only get it right around half the time, but the AI could spot if a statement was true or false in 67% of cases. However, lie detection is a controversial and unreliable technology, and it\u2019s debatable\u00a0 whether we should even be using it in the first place. (MIT Technology Review)\u00a0 A hacker stole secrets from OpenAI\u00a0A hacker managed to access OpenAI\u2019s internal messaging systems and steal information about its AI technology. The company believes the hacker was a private individual, but the incident raised fears among OpenAI employees that China could steal the company\u2019s technology too. (The New York Times) AI has vastly increased Google\u2019s emissions over the past five yearsGoogle said its greenhouse-gas emissions totaled 14.3 million metric tons of carbon dioxide equivalent throughout 2023. This is 48% higher than in 2019, the company said. This is mostly due to Google\u2019s enormous push toward AI, which will likely make it harder to hit its goal of eliminating carbon emissions by 2030. This is an utterly depressing example of how our societies prioritize profit over the climate emergency we are in. (Bloomberg)\u00a0 Why a $14 billion startup is hiring PhDs to train AI systems from their living roomsAn interesting read about the shift happening in AI and data work. Scale AI has previously hired low-paid data workers in countries such as India and the Philippines to annotate data that is used to train AI. But the massive boom in language models has prompted Scale to hire highly skilled contractors in the US with the necessary expertise to help train those models. This highlights just how important data work really is to AI. (The Information)\u00a0 A new \u201cethical\u201d AI music generator can\u2019t write a halfway decent songCopyright is one of the\u00a0thorniest problems\u00a0facing AI today. Just last week I wrote about how\u00a0AI companies are being forced to cough up\u00a0for high-quality training data to build powerful AI. This story illustrates why this matters. This story is about an \u201cethical\u201d AI music generator, which only used a limited data set of licensed music. But without high-quality data, it is not able to generate anything even close to decent. (Wired)\u00a0\u00a0 hide"
  ]
}