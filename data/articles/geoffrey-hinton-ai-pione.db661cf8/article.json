{
  "url": "https://www.technologyreview.com/2024/10/08/1105221/geoffrey-hinton-just-won-the-nobel-prize-in-physics-for-his-work-on-machine-learning/",
  "title": "Geoffrey Hinton, AI pioneer and figurehead of doomerism, wins Nobel Prize",
  "ut": 1728354673.0,
  "body_paragraphs": [
    "Geoffrey Hinton, a computer scientist whose pioneering work on deep learning in the 1980s and \u201990s underpins all of the most powerful AI models in the world today, has been awarded the 2024 Nobel Prize in physics by the Royal Swedish Academy of Sciences. Speaking on the phone to the Academy minutes after the announcement, Hinton said he was flabbergasted: \u201cI had no idea this would happen. I\u2019m very surprised.\u201d Hinton shares the award with fellow computer scientist John Hopfield, who invented a type of pattern-matching neural network that could store and reconstruct data. Hinton built on this technology, known as a Hopfield network, to develop backpropagation, an algorithm that lets neural networks learn. Hopfield and Hinton borrowed methods from physics, especially statistical techniques, to develop their approaches. In the words of the Nobel Prize committee, the pair are recognized \u201cfor foundational discoveries and inventions that enable machine learning with artificial neural networks.\u201d",
    "But since May 2023, when MIT Technology Review helped break the news that Hinton was now scared of the technology that he had helped bring about, the 76-year-old scientist has become much better known as a figurehead for doomerism\u2014the idea that there\u2019s a very real risk that near-future AI could precipitate catastrophic events, up to and including human extinction.\u00a0\u00a0 Doomerism wasn\u2019t new, but Hinton\u2014who won the Turing Award, the top prize in computing science, in 2018\u2014brought new credibility to a position that many of his peers once considered kooky.",
    "What led Hinton to speak out? When I met with him in his London home last year, Hinton told me that he was awestruck by what new large language models could do. OpenAI\u2019s latest flagship model, GPT-4, had been released a few weeks before. What Hinton saw convinced him that such technology\u2014based on deep learning\u2014would quickly become smarter than humans. And he was worried about what motivations it would have when it did.\u00a0\u00a0 \u201cI have suddenly switched my views on whether these things are going to be more intelligent than us,\u201d he told me at the time.\u00a0\u201cI think they\u2019re very close to it now and they will be much more intelligent than us in the future. How do we survive that?\u201d Hinton\u2019s views set off a months-long media buzz and made the kind of existential risks that he and others were imagining (from economic collapse to genocidal robots) into mainstream concerns. Hundreds of top scientists and tech leaders signed open letters warning of the disastrous downsides of artificial intelligence. A moratorium on AI development was floated. Politicians assured voters they would do what they could to prevent the worst. Despite the buzz, many consider Hinton\u2019s views to be fantastical. Yann LeCun, chief AI scientist at Meta and Hinton\u2019s fellow recipient of the 2018 Turing Award, has called doomerism \u201cpreposterously ridiculous.\u201d Today\u2019s prize rewards foundational work in a technology that has become part of everyday life. It is also sure to shine an even brighter light on Hinton\u2019s more scaremongering opinions. hide"
  ]
}