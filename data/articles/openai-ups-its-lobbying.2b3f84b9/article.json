{
  "url": "https://www.technologyreview.com/2025/01/21/1110260/openai-ups-its-lobbying-efforts-nearly-seven-fold/",
  "title": "OpenAI ups its lobbying efforts nearly seven-fold",
  "ut": 1737466866.0,
  "body_paragraphs": [
    "OpenAI spent $1.76 million on lobbying in 2024 and $510,000 in the last three months of the year alone, according to a new disclosure filed on Tuesday\u2014a significant jump from 2023 when the company disclosed just $260,000 spent on Capitol Hill. The company also disclosed a new in-house lobbyist, Meghan Dorn, who worked for five years for Senator Lindsey Graham and started at OpenAI in October. The filing also shows activity related to two new pieces of legislation in the final months of the year: The House\u2019s AI Advancement and Reliability Act, which would set up a government center for AI research, and the Senate\u2019s Future of Artificial Intelligence Innovation Act, which would create shared benchmark tests for AI models.\u00a0 OpenAI did not respond to questions about its lobbying efforts.  But, perhaps more importantly, the disclosure is a clear signal of the company\u2019s arrival as a political player, as its first year of serious lobbying ends and Republican control of Washington begins. While OpenAI\u2019s lobbying spend is still dwarfed by its peers\u2014Meta tops the list of Big Tech spenders, doling out more than $24 million in 2024\u2014the year-on-year uptick comes as it and other AI companies have helped redraw the shape of AI policy.\u00a0 For the past few years, AI policy has been something like a whack-a-mole response to the risks posed by deepfakes and misinformation. But over the last year, AI companies have started to position the success of the technology as pivotal to national security and American competitiveness, in turn arguing that the government must support the industry\u2019s growth. As a result, OpenAI and others now seem poised to gain access to cheaper energy, lucrative national security contracts, and a more lax regulatory environment that\u2019s unconcerned with the minutiae of AI safety.",
    "While the big players in the space seem more or less aligned on this grand narrative, messy divides on other issues are still threatening to break through the harmony on display at President Trump\u2019s inauguration this week. AI regulation really began in earnest after ChatGPT launched in November 2022. At that point, \u201ca lot of the conversation was about responsibility,\u201d says Liana Keesing, campaigns manager for technology reform at Issue One, a democracy nonprofit that tracks Big Tech\u2019s influence.",
    "Companies were asked what they\u2019d do about sexually abusive deepfake images and election disinformation. \u201cSam Altman did a very good job coming in and painting himself early as a supporter of that process,\u201d Keesing says.\u00a0 OpenAI started its official lobbying effort around October 2023, hiring Chan Park\u2014a onetime Senate Judiciary Committee counsel and Microsoft lobbyist\u2014to lead the effort. Lawmakers, particularly then-Senate Majority Leader Chuck Schumer, were vocal about wanting to curb these particular harms; OpenAI hired Schumer\u2019s former legal counsel, Reginald Babin, as a lobbyist, according to data from OpenSecrets. This past summer, the company hired veteran political operative Chris Lehane as its head of global policy.\u00a0 OpenAI\u2019s previous disclosures confirm that the company\u2019s lobbyists subsequently focused much of last year on legislation like the NO FAKES Act and the Protect Elections from Deceptive AI Act. The bills did not materialize into law. But as the year went on, the regulatory goals of AI companies began to change. \u201cOne of the biggest shifts that we've seen,\u201d Keesing says, \u201cis that they\u2019ve really started to focus on energy.\u201d\u00a0 In September, Altman, along with leaders from Nvidia, Anthropic, and Google, visited the White House and pitched the vision that US competitiveness in AI will depend on subsidized energy infrastructure to train the best models. Altman proposed to the Biden administration the construction of multiple 5-gigawatt data centers, which would each consume as much electricity as New York City.\u00a0  Around the same time, companies like Meta and Microsoft started to say that nuclear energy will provide the path forward for AI, announcing deals aimed at firing up new nuclear power plants.\u00a0 It seems likely OpenAI\u2019s policy team was already planning for this particular shift. In April, the company hired lobbyist Matthew Rimkunas, who worked for Bill Gates\u2019 sustainable energy effort Breakthrough Energies and, before that, spent 16 years working for Senator Lindsey Graham, a South Carolina Republican who serves on the Senate subcommittee that manages nuclear safety.\u00a0 Related StoryAI\u2019s emissions are about to skyrocket even furtherData center emissions have tripled since 2018. As more complex AI models like OpenAI\u2019s Sora see broad release, those figures will likely go through the roof.",
    "This new AI energy race is inseparable from the positioning of AI as essential for national security and US competitiveness with China. OpenAI laid out its position in a blog post in October, writing, \u201cAI is a transformational technology that can be used to strengthen democratic values or to undermine them. That\u2019s why we believe democracies should continue to take the lead in AI development.\u201d Then in December, the company went a step further and reversed its policy against working with the military, announcing it would develop AI models with defense-tech company Anduril to help take down drones around military bases.\u00a0 That same month, Sam Altman said during an interview with The Free Press that the Biden administration was \u201cnot that effective\u201d in shepherding AI: \u201cThe things that I think should have been the administration\u2019s priorities, and I hope will be the next administration\u2019s priorities, are building out massive AI infrastructure in the US, having a supply chain in the US, things like that.\u201d",
    "That characterization glosses over the CHIPS Act, a $52-billion stimulus to the domestic chips industry that is, at least on paper, aligned with Altman\u2019s vision. (It also preceded an executive order Biden issued just last week, to lease federal land to host the type of gigawatt-scale data centers that Altman had been asking for.) Intentionally or not, Altman\u2019s posture aligned him with the growing camaraderie between President Trump and Silicon Valley. Mark Zuckerberg, Elon Musk, Jeff Bezos, and Sundar Pichai all sat directly behind Trump\u2019s family at the inauguration on Monday, and Altman also attended. Many of them had also made sizable donations to Trump\u2019s inaugural fund, with Altman throwing in a $1 million personal donation. It\u2019s easy to view the inauguration as evidence that this cadre of tech leaders are aligned with each other, and with Trump\u2019s orbit. But there are still some key dividing lines here that will be worth watching. Notably, there\u2019s the clash over H-1B visas, which allow many non-citizen AI researchers to work in the US. Musk and Vivek Ramaswamy (who is, as of this week, no longer a part of the Department of Government Efficiency) have been pushing for those visas to be expanded. This sparked backlash from some allies of the Trump administration, perhaps most loudly Steve Bannon.\u00a0 Another fault line is the battle between open- or closed-source AI. Google and OpenAI prevent anyone from knowing exactly what\u2019s in their most powerful models, often arguing that this keeps them from being used improperly by bad actors. Musk has sued OpenAI and Microsoft over the issue, alleging that closed-source models are antithetical to OpenAI\u2019s hybrid nonprofit structure. Meta, whose LLaMA model is open-source, recently sided with Musk in that lawsuit. Venture capitalist and Trump ally Marc Andreessen echoed these criticisms of OpenAI on X just hours after the inauguration. (Andreessen has also said that making AI models open-source \u201cmakes overbearing regulations unnecessary.\u201d)\u00a0 Finally, there are the battles of bias and free speech. As social media companies have taken vastly different approaches to moderating content\u2014including Meta\u2019s recent announcement to end its US fact checking program\u2014it raises the question whether the way AI models are moderated will continue to splinter too. Musk has lamented what he calls the \u201cwokeness\u201d of many leading AI models, and Andreessen said on Tuesday that \u201cChinese LLMs are much less censored than American LLMs\u201d (though that\u2019s not quite true, given that many Chinese AI models have government-mandated censorship in place that forbids particular topics). Altman has been more equivocal: \u201cNo two people are ever going to agree that one system is perfectly unbiased,\u201d he told The Free Press. It\u2019s only the start of a new era in Washington, but the White House has been busy. It has repealed many executive orders signed by President Biden, including the landmark order on AI that imposed rules for how the government would use the technology (while it appears to have kept Biden\u2019s order on leasing land for more data centers). Altman is busy as well. OpenAI, Oracle, and SoftBank reportedly plan to spend up to $500 billion on a joint venture for new data centers; the new project was announced by President Trump, with Altman standing alongside. And, according to Axios, Altman will also be part of a closed-door briefing on January 30 with government officials, reportedly about OpenAI\u2019s development of a powerful new AI agent. hide"
  ]
}