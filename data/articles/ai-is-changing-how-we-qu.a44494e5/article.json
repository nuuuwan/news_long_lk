{
  "url": "https://www.technologyreview.com/2025/10/15/1125116/ai-is-changing-how-we-quantify-pain/",
  "title": "AI is changing how we quantify pain",
  "ut": 1760488200.0,
  "body_paragraphs": [
    "For years at Orchard Care Homes, a 23\u2011facility dementia-care chain in northern England, Cheryl Baird watched nurses fill out the Abbey Pain Scale, an observational methodology used to evaluate pain in those who can\u2019t communicate verbally. Baird, a former nurse who was then the facility\u2019s director of quality, describes it as \u201ca tick\u2011box exercise where people weren\u2019t truly considering pain indicators.\u201d As a result, agitated residents were assumed to have behavioral issues, since the scale does not always differentiate well between pain and other forms of suffering or distress. They were often prescribed psychotropic sedatives, while the pain itself went untreated.  Then, in January 2021, Orchard Care Homes began a trial of PainChek, a smartphone app that scans a resident\u2019s face for microscopic muscle movements and uses artificial intelligence to output an expected pain score. Within weeks, the pilot unit saw fewer prescriptions and had calmer corridors. \u201cWe immediately saw the benefits: ease of use, accuracy, and identifying pain that wouldn\u2019t have been spotted using the old scale,\u201d Baird recalls.  In nursing homes, neonatal units, and ICU wards, researchers are racing to turn pain into something a camera or sensor can score as reliably as blood pressure.  This kind of technology-assisted diagnosis hints at a bigger trend. In nursing homes, neonatal units, and ICU wards, researchers are racing to turn pain\u2014medicine\u2019s most subjective vital sign\u2014into something a camera or sensor can score as reliably as blood pressure. The push has already produced PainChek, which has been cleared by regulators on three continents and has logged more than 10 million pain assessments. Other startups are beginning to make similar inroads in care settings.",
    "The way we assess pain may finally be shifting, but when algorithms measure our suffering, does that change the way we understand and treat it? Science already understands certain aspects of pain. We know that when you stub your toe, for example, microscopic alarm bells called nociceptors send electrical impulses toward your spinal cord on \u201cexpress\u201d wires, delivering the first stab of pain, while a slower convoy follows with the dull throb that lingers. At the spinal cord, the signal meets a microscopic switchboard scientists call the gate. Flood that gate with friendly touches\u2014say, by rubbing the bruise\u2014or let the brain return an instruction born of panic or calm, and the gate might muffle or magnify the message before you even become aware of it.",
    "Related StoryWhy is it so hard to create new types of pain relievers?Read next The gate can either let pain signals pass through or block them, depending on other nerve activity and instructions from your brain. Only the signals that succeed in getting past this gate travel up to your brain\u2019s sensory map to help locate the damage, while others branch out to emotion centers that decide how bad it feels. Within milliseconds, those same hubs in the brain shoot fresh orders back down the line, releasing built-in painkillers or stoking the alarm. In other words, pain isn\u2019t a straightforward translation of damage or sensation but a live negotiation between the body and the brain. But much of how that negotiation plays out is still a mystery. For instance, scientists cannot predict what causes someone to slip from a routine injury into years-long hypersensitivity; the molecular shift from acute to chronic pain is still largely unknown. Phantom-limb pain remains equally puzzling: About two-thirds of amputees feel agony in a part of their body that no longer exists, yet competing theories\u2014cortical remapping, peripheral neuromas, body-schema mismatch\u2014do not explain why they suffer while the other third feel nothing. The first serious attempt at a system for quantifying pain was introduced in 1921. Patients marked their degree of pain as a point on a blank 10\u2011centimeter line and clinicians scored the distance in millimeters, converting lived experience into a 0\u2013100 ladder. By 1975, psychologist Ronald\u202fMelzack\u2019s McGill Pain Questionnaire offered 78 adjectives like \u201cburning,\u201d \u201cstabbing,\u201d and \u201cthrobbing,\u201d so that pain\u2019s texture could join intensity in the chart. Over the past few decades, hospitals have ultimately settled on the 0\u201310 Numeric Rating Scale. Yet pain is stubbornly subjective. Feedback from the brain in the form of your reaction can send instructions back down the spinal cord, meaning that expectation and emotion can change how much the same injury hurts. In one trial, volunteers who believed they had received a pain relief cream reported a stimulus as 22% less painful than those who knew the cream was inactive\u2014and a functional magnetic resonance image of their brains showed that the drop corresponded with decreased activity in the parts of the brain that report pain, meaning they really did feel less hurt.  What\u2019s more, pain can also be affected by a slew of external factors. In one study, experimenters applied the same calibrated electrical stimulus to volunteers from Italy, Sweden, and Saudi Arabia, and the ratings varied dramatically. Italian women recorded the highest scores on the 0\u201310 scale, while Swedish and Saudi participants judged the identical burn several points lower, implying that culture can amplify or dampen the felt intensity of the same experience. Bias inside the clinic can drive different responses even to the same pain score. A 2024 analysis of discharge notes found that women\u2019s scores were recorded 10% less often than men\u2019s. At a large pediatric emergency department, Black children presenting with limb fractures were roughly 39% less likely to receive an opioid analgesic than their white non-Hispanic peers, even after the researchers controlled for pain score and other clinical factors. Together these studies make clear that an \u201c8 out of 10\u201d does not always result in the same reaction or treatment. And many patients cannot self-report their pain at all\u2014for example, a review of bedside studies concludes that about 70% of intensive-care patients have pain that goes unrecognized or undertreated, a problem the authors link to their impaired communication due to sedation or intubation. These issues have prompted a search for a better, more objective way to understand and assess pain. Progress in artificial intelligence has brought a new dimension to that hunt. Research groups are pursuing two broad routes. The first listens underneath the skin. Electrophysiologists strap electrode nets to volunteers and look for neural signatures that rise and fall with administered stimuli. A 2024 machine-learning study reported that one such algorithm could tell with over 80% accuracy, using a few minutes of resting-state EEG, which subjects experienced chronic pain and which were pain-free control participants. Other researchers combine EEG with galvanic skin response and heart-rate variability, hoping a multisignal \u201cpain fingerprint\u201d will provide more robust measurements.",
    "Related StoryThe pain is real. The painkillers are virtual reality.Read next One example of this method is the PMD-200 patient monitor from Medasense, which uses AI-based tools to output pain scores. The device uses physiological patterns like heart rate, sweating, or peripheral temperature changes as the input and focuses on surgical patients, with the goal of helping anesthesiologists adjust doses during operations. In a 2022 study of 75 patients undergoing major abdominal surgery, use of the monitor resulted in lower self-reported pain scores after the operation\u2014a median score of 3 out of 10, versus 5 out of 10 in controls\u2014without an increase in opioid use. The device is authorized by the US Food and Drug Administration and is in use in the United States, the European Union, Canada, and elsewhere. The second path is behavioral. A grimace, a guarded posture, or a sharp intake of breath correlates with various levels of pain. Computer-vision teams have fed high-speed video of patients\u2019 changing expressions into neural networks trained on the Face Action Coding System (FACS), which was introduced in the late 1970s with the goal of creating an objective and universal system to analyze such expressions\u2014it\u2019s the Rosetta stone of 44 facial micro-movements. In lab tests, those models can flag frames indicating pain from the data set with over 90% accuracy, edging close to the consistency of expert human assessors. Similar approaches mine posture and even sentence fragments in clinical notes, using natural-language processing, to spot phrases like \u201ccurling knees to chest\u201d that often correlate with high pain. PainChek is one of these behavioral models, and it acts like a camera\u2011based thermometer, but for pain: A care worker opens the app and holds a phone 30\u202fcentimeters from a person\u2019s face. For three seconds, a neural network looks for nine particular microscopic movements\u2014upper\u2011lip raise, brow pinch, cheek tension, and so on\u2014that research has linked most strongly to pain. Then the screen flashes a score of\u202f0 to\u202f42. \u201cThere\u2019s a catalogue of \u2018action\u2011unit codes\u2019\u2014facial expressions common to all humans. Nine of those are associated with pain,\u201d explains Kreshnik\u202fHoti, a senior research scientist with PainChek and a co-inventor of the device. This system is built directly on the foundation of FACS. After the scan, the app walks the user through a yes\u2011or\u2011no checklist of other signs, like groaning, \u201cguarding,\u201d and sleep disruption, and stores the result on a cloud dashboard that can show trends. Linking the scan to a human\u2011filled checklist was, Hoti admits, a late design choice. \u201cInitially, we thought AI should automate everything, but now we see [that] hybrid use\u2014AI plus human input\u2014is our major strength,\u201d he says. Care aides, not nurses, complete most assessments, freeing clinicians to act on the data rather than gather it.  PainChek was cleared by Australia\u2019s Therapeutic Goods Administration in 2017, and national rollout funding from Canberra helped embed it in hundreds of nursing homes in the country. The system has also won authorization in the UK\u2014where expansion began just before covid-19 started spreading and resumed as lockdowns eased\u2014and in Canada and New\u202fZealand, which are running pilot programs. In the US, the FDA recently granted PainChek\u00a0De Novo\u00a0clearance, which applies to novel medical\u00a0devices. Company\u2011wide data show \u201cabout a 25% drop in anti\u00adpsychotic use and, in Scotland, a 42% reduction in falls,\u201d Hoti says.  PainChek is a mobile app that estimates pain scores by applying artificial intelligence to facial scans.COURTESY OF PAINCHEK   Orchard Care Homes is one of its early adopters. Baird, then the facility\u2019s director of quality, remembers the pre\u2011AI routine that was largely done \u201cto prove compliance,\u201d she says. PainChek added an algorithm to that workflow, and the hybrid approach has paid off. Orchard\u2019s internal study of four care homes tracked monthly pain scores, behavioral incidents, and prescriptions. Within weeks, psychotropic scripts fell and residents\u2019 behavior calmed. The ripple effects went beyond pharmacy tallies. Residents who had skipped meals because of undetected dental pain \u201cbegan eating again,\u201d Baird notes, and \u201cthose who were isolated due to pain began socializing.\u201d Inside Orchard facilities, a cultural shift is underway. When Baird trained new staff, she likened pain \u201cto measuring blood pressure or oxygen,\u201d she says. \u201cWe wouldn\u2019t guess those, so why guess pain?\u201d The analogy lands, but getting people fully on board is still a slog. Some nurses insist their clinical judgment is enough; others balk at another login and audit trail. \u201cThe sector has been slow to adopt technology, but it\u2019s changing,\u201d Baird says. That\u2019s helped by the fact that administering a full Abbey Pain Scale takes 20\u202fminutes, while a PainChek scan and checklist take less than five.",
    "Engineers at PainChek are now adapting the code for the very youngest patients. PainChek\u202fInfant targets babies under one year, whose grimaces flicker faster than adults\u2019. The algorithm, retrained on neonatal faces, detects six validated facial action units based on the well-established Baby Facial Action Coding System. PainChek Infant is starting limited testing in Australia while the company pursues a separate regulatory pathway. Skeptics raise familiar red flags about these devices. Facial\u2011analysis AI has a history of skin\u2011tone bias, for example. Facial analysis may also misread grimaces stemming from nausea or fear. The tool is only as good as the yes\u2011or\u2011no answers that follow the scan; sloppy data entry can skew results in either direction. Results lack the broader clinical and interpersonal context a caregiver is likely to have from interacting with individual patients regularly and understanding their medical history. It\u2019s also possible that clinicians might defer too strongly to the algorithm, over-relying on outside judgment and eroding their own.",
    "PainChek is just one part of a broader effort to create a system of new pain measurement technology. Other startups are pitching EEG headbands for neuropathic pain, galvanic skin sensors that flag breakthrough cancer pain, and even language models that comb nursing notes for evidence of hidden distress. Still, quantifying pain with an external device could be rife with hidden issues, like bias or inaccuracies, that we will uncover only after significant use. For Baird, the issue is fairly straightforward nonetheless. \u201cI\u2019ve lived with chronic pain and had a hard time getting people to believe me. [PainChek] would have made a huge difference,\u201d she says. If artificial intelligence can give silent sufferers a numerical voice\u2014and make clinicians listen\u2014then adding one more line to the vital\u2011sign chart might be worth the screen time. This story has been updated to reflect the FDA\u2019s\u00a0decision\u00a0on PainChek\u2019s adult app in October 2025.\u00a0 Deena Mousa is a researcher, grantmaker, and journalist focused on global health, economic development, and scientific and technological progress. Mousa is employed as lead researcher by Open Philanthropy, a funder and adviser focused on high-impact causes, including global health and the potential risks posed by AI. The research team investigates new causes of focus and is not involved in work related to pain management. Mousa has not been involved with any grants related to pain management, although Open Philanthropy has funded research in this area in the past. hide"
  ]
}