{
  "url": "https://www.technologyreview.com/2024/07/05/1094711/what-are-ai-agents/",
  "title": "What are AI agents?",
  "ut": 1720140978.0,
  "body_paragraphs": [
    "MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what's coming next. You can read more from the series here. When ChatGPT was first released, everyone in AI was talking about the new generation of AI assistants. But over the past year, that excitement has turned to a new target: AI agents.\u00a0  Agents featured prominently in Google\u2019s annual I/O conference in May, when the company unveiled its new AI agent called Astra, which allows users to interact with it using audio and video. OpenAI\u2019s new GPT-4o model has also been called an AI agent.\u00a0\u00a0 And it\u2019s not just hype, although there is definitely some of that too. Tech companies are plowing vast sums into creating AI agents, and their research efforts could usher in the kind of useful AI we have been dreaming about for decades. Many experts, including Sam Altman, say they are the next big thing.",
    "But what are they? And how can we use them?\u00a0 How are they defined?\u00a0 It is still early days for research into AI agents, and the field does not have a definitive definition for them. But simply, they are AI models and algorithms that can autonomously make decisions in a dynamic world, says Jim Fan, a senior research scientist at Nvidia who leads the company\u2019s AI agents initiative.",
    "The grand vision for AI agents is a system that can execute a vast range of tasks, much like a human assistant. In the future, it could help you book your vacation, but it will also remember if you prefer swanky hotels, so it will only suggest hotels that have four stars or more and then go ahead and book the one you pick from the range of options it offers you. It will then also suggest flights that work best with your calendar, and plan the itinerary for your trip according to your preferences. It could make a list of things to pack based on that plan and the weather forecast. It might even send your itinerary to any friends it knows live in your destination and invite them along. In the workplace, it\u00a0 could analyze your to-do list and execute tasks from it, such as sending calendar invites, memos, or emails.\u00a0 One vision for agents is that they are multimodal, meaning they can process language, audio, and video. For example, in Google\u2019s Astra demo, users could point a smartphone camera at things and ask the agent questions. The agent could respond to text, audio, and video inputs.\u00a0 These agents could also make processes smoother for businesses and public organizations, says David Barber, the director of the University College London Centre for Artificial Intelligence. For example, an AI agent might be able to function as a more sophisticated customer service bot. The current generation of language-model-based assistants can only generate the next likely word in a sentence. But an AI agent would have the ability to act on natural-language commands autonomously and process customer service tasks without supervision. For example, the agent would be able to analyze customer complaint emails and then know to check the customer\u2019s reference number, access databases such as customer relationship management and delivery systems to see whether the complaint is legitimate, and process it according to the company\u2019s policies, Barber says.\u00a0 Broadly speaking, there are two different categories of agents, says Fan: software agents and embodied agents.\u00a0  Software agents run on computers or mobile phones and use apps, much as in the travel agent example above. \u201cThose agents are very useful for office work or sending emails or having this chain of events going on,\u201d he says.\u00a0 Embodied agents are agents that are situated in a 3D world such as a video game, or in a robot. These kinds of agents might make video games more engaging by letting people play with nonplayer characters controlled by AI. These sorts of agents could also help build more useful robots that could help us with everyday tasks at home, such as folding laundry and cooking meals.\u00a0 Fan was part of a team that built an embodied AI agent called MineDojo in the popular computer game Minecraft. Using a vast trove of data collected from the internet, Fan\u2019s AI agent was able to learn new skills and tasks that allowed it to freely explore the virtual 3D world and complete complex tasks such as encircling llamas with fences or scooping lava into a bucket. Video games are good proxies for the real world, because they require agents to understand physics, reasoning, and common sense.\u00a0 In a new paper, which has not yet been peer-reviewed, researchers at Princeton say that AI agents tend to have three different characteristics. AI systems are considered \u201cagentic\u201d if they can pursue difficult goals without being instructed in complex environments. They also qualify if they can be instructed in natural language and act autonomously without supervision. And finally, the term \u201cagent\u201d can also apply to systems that are able to use tools, such as web search or programming, or are capable of planning.",
    "Are they a new thing? The term \u201cAI agents\u201d has been around for years and has meant different things at different times, says Chirag Shah, a computer science professor at the University of Washington.\u00a0 There have been two waves of agents, says Fan. The current wave is thanks to the language model boom and the rise of systems such as ChatGPT.\u00a0 The previous wave was in 2016, when Google DeepMind introduced AlphaGo, its AI system that can play\u2014and win\u2014the game Go. AlphaGo was able to make decisions and plan strategies. This relied on reinforcement learning, a technique that rewards AI algorithms for desirable behaviors.\u00a0 \u201cBut these agents were not general,\u201d says Oriol Vinyals, vice president of research at Google DeepMind. They were created for very specific tasks\u2014in this case, playing Go. The new generation of foundation-model-based AI makes agents more universal, as they can learn from the world humans interact with.\u00a0  \u201cYou feel much more that the model is interacting with the world and then giving back to you better answers or better assisted assistance or whatnot,\u201d says Vinyals.\u00a0 What are the limitations?\u00a0 There are still many open questions that need to be answered. Kanjun Qiu, CEO and founder of the AI startup Imbue, which is working on agents that can reason and code, likens the state of agents to where self-driving cars were just over a decade ago. They can do stuff, but they\u2019re unreliable and still not really autonomous. For example, a coding agent can generate code, but it sometimes gets it wrong, and it doesn\u2019t know how to test the code it\u2019s creating, says Qiu. So humans still need to be actively involved in the process. AI systems still can\u2019t fully reason, which is a critical step in operating in a complex and\u00a0 ambiguous human world.\u00a0 \u201cWe\u2019re nowhere close to having an agent that can just automate all of these chores for us,\u201d says Fan. Current systems \u201challucinate and they also don\u2019t always follow instructions closely,\u201d Fan says. \u201cAnd that becomes annoying.\u201d \u00a0 Another limitation is that after a while, AI agents lose track of what they are working on. AI systems are limited by their context windows, meaning the amount of data they can take into account at any given time.",
    "\u201cChatGPT can do coding, but it\u2019s not able to do long-form content well. But for human developers, we look at an entire GitHub repository that has tens if not hundreds of lines of code, and we have no trouble navigating it,\u201d says Fan.\u00a0 To tackle this problem, Google has increased its models\u2019 capacity to process data, which allows users to have longer interactions with them in which they remember more about past interactions. The company said it is working on making its context windows infinite in the future.",
    "For embodied agents such as robots, there are even more limitations. There is not enough training data to teach them, and researchers are only just starting to harness the power of foundation models in robotics.\u00a0 So amid all the hype and excitement, it\u2019s worth bearing in mind that research into AI agents is still in its very early stages, and it will likely take years until we can experience their full potential.\u00a0 That sounds cool. Can I try an AI agent now?\u00a0 Sort of. You\u2019ve most likely tried their early prototypes, such as OpenAI\u2019s ChatGPT and GPT-4. \u201cIf you\u2019re interacting with software that feels smart, that is kind of an agent,\u201d says Qiu.\u00a0 Right now the best agents we have are systems with very narrow and specific use cases, such as coding assistants, customer service bots, or workflow automation software like Zapier, she says. But these are a far cry from a universal AI agent that can do complex tasks.\u00a0 \u201cToday we have these computers and they\u2019re really powerful, but we have to micromanage them,\u201d says Qiu.\u00a0 OpenAI\u2019s ChatGPT plug-ins, which allow people to create AI-powered assistants for web browsers, were an attempt at agents, says Qiu. But these systems are still clumsy, unreliable, and not capable of reasoning, she says.\u00a0 Despite that, these systems will one day change the way we interact with technology, Qiu believes, and it is a trend people need to pay attention to.\u00a0 \u201cIt\u2019s not like, \u2018Oh my God, all of a sudden we have AGI\u2019 ... but more like \u2018Oh my God, my computer can do way more than it did five years ago,\u2019\u201d she says. hide"
  ]
}