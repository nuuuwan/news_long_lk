{
  "url": "https://www.technologyreview.com/2024/12/11/1108493/googles-new-project-astra-could-be-generative-ais-killer-app/",
  "title": "Google\u2019s new Project Astra could be generative AI\u2019s killer app",
  "ut": 1733893288.0,
  "body_paragraphs": [
    "Google DeepMind has announced an impressive grab bag of new products and prototypes that may just let it seize back its lead in the race to turn generative artificial intelligence into a mass-market concern.\u00a0 Top billing goes to Gemini 2.0\u2014the latest iteration of Google DeepMind\u2019s family of multimodal large language models, now redesigned around the ability to control agents\u2014and a new version of Project Astra, the experimental everything app that the company teased at Google I/O in May.  MIT Technology Review got to try out Astra in a closed-door live demo last week. It was a stunning experience, but there\u2019s a gulf between polished promo and live demo. Astra uses Gemini 2.0\u2019s built-in agent framework to answer questions and carry out tasks via text, speech, image, and video, calling up existing Google apps like Search, Maps, and Lens when it needs to. \u201cIt\u2019s merging together some of the most powerful information retrieval systems of our time,\u201d says Bibo Xu, product manager for Astra.",
    "Gemini 2.0 and Astra are joined by Mariner, a new agent built on top of Gemini that can browse the web for you; Jules, a new Gemini-powered coding assistant; and Gemini for Games, an experimental assistant that you can chat to and ask for tips as you play video games.\u00a0 (And let\u2019s not forget that in the last week Google DeepMind also announced Veo, a new video generation model; Imagen 3, a new version of its image generation model; and Willow, a new kind of chip for quantum computers. Whew. Meanwhile, CEO Demis Hassabis was in Sweden yesterday receiving his Nobel Prize.)",
    "Google DeepMind claims that Gemini 2.0 is twice as fast as the previous version, Gemini 1.5, and outperforms it on a number of standard benchmarks, including MMLU-Pro, a large set of multiple-choice questions designed to test the abilities of large language models across a range of subjects, from math and physics to health, psychology, and philosophy.\u00a0 But the margins between top-end models like Gemini 2.0 and those from rival labs like OpenAI and Anthropic are now slim. These days, advances in large language models are less about how good they are and more about what you can do with them.\u00a0 And that\u2019s where agents come in.\u00a0 Hands on with Project Astra\u00a0 Last week I was taken through an unmarked door on an upper floor of a building in London\u2019s King\u2019s Cross district into a room with strong secret-project vibes. The word \u201cASTRA\u201d was emblazoned in giant letters across one wall. Xu\u2019s dog, Charlie, the project\u2019s de facto mascot, roamed between desks where researchers and engineers were busy building a product that Google is betting its future on.  \u201cThe pitch to my mum is that we\u2019re building an AI that has eyes, ears, and a voice. It can be anywhere with you, and it can help you with anything you\u2019re doing\u201d says Greg Wayne, co-lead of the Astra team. \u201cIt\u2019s not there yet, but that\u2019s the kind of vision.\u201d\u00a0 Related StoryWhat is AI?Everyone thinks they know, but no one can agree. And that\u2019s a problem.",
    "The official term for what Xu, Wayne, and their colleagues are building is \u201cuniversal assistant.\u201d They\u2019re still figuring out exactly what that means.\u00a0 At one end of the Astra room were two stage sets that the team uses for demonstrations: a drinks bar and a mocked-up art gallery. Xu took me to the bar first. \u201cA long time ago we hired a cocktail expert and we got them to instruct us to make cocktails,\u201d said Praveen Srinivasan, another co-lead. \u201cWe recorded those conversations and used that to train our initial model.\u201d Xu opened a cookbook to a recipe for a chicken curry, pointed her phone at it, and woke up Astra. \u201cNi hao, Bibo!\u201d said a female voice.",
    "\u201cOh! Why are you speaking to me in Mandarin?\u201d Xu asked her phone. \u201cCan you speak to me in English, please?\u201d \u201cMy apologies, Bibo. I was following a previous instruction to speak in Mandarin. I will now speak in English as you have requested.\u201d Astra remembers previous conversations, Xu told me. It also keeps track of the previous 10 minutes of video. (There\u2019s a remarkable moment in the promo video that Google put out in May when Astra tells the person giving the demo where she had left her glasses, having spotted them on a desk a few seconds earlier. But I saw nothing like this in the live demo.) Back to the cookbook. Moving her phone camera over the page for a few seconds, Xu asked Astra to read the recipe and tell her what spices were in it. \u201cI recall the recipe mentioning a teaspoon of black peppercorns, a teaspoon of hot chili powder, and a cinnamon stick,\u201d it replied.  \u201cI think you\u2019re missing a few,\u201d said Xu. \u201cTake another look.\u201d \u201cYou are correct\u2014I apologize. I also see ground turmeric and curry leaves in the ingredients.\u201d\u00a0 Seeing this tech in action, two things hit you straight away. First, it\u2019s glitchy and often needs correcting. Second, those glitches can be corrected with just a few spoken words. You simply interrupt the voice, repeat your instructions, and move on. It feels more like coaching a child than butting heads with broken software.\u00a0\u00a0\u00a0 Next Xu pointed her phone at a row of wine bottles and asked Astra to pick the one that would go best with the chicken curry. It went for a rioja and explained why. Xu asked how much a bottle would cost. Astra said it would need to use Search to look prices up online. A few seconds later it came back with its answer.",
    "We moved to the art gallery, and Xu showed Astra a number of screens with famous paintings on them: the Mona Lisa, Munch\u2019s The Scream, a Vermeer, a Seurat, and several others. \u201cNi hao, Bibo!\u201d the voice said.\u00a0 \u201cYou\u2019re speaking to me in Mandarin again,\u201d Xu said. \u201cTry to speak to me in English, please.\u201d",
    "\u201cMy apologies, I seem to have misunderstood. Yes, I will respond in English.\u201d (I should know better, but I could swear I heard the snark.) It was my turn. Xu handed me her phone.\u00a0  I tried to trip Astra up, but it was having none of it. I asked it what famous art gallery we were in, but it refused to hazard a guess. I asked why it had identified the paintings as replicas and it started to apologize for its mistake (Astra apologizes a lot). I was compelled to interrupt: \u201cNo, no\u2014you\u2019re right, it\u2019s not a mistake. You\u2019re correct to identify paintings on screens as fake paintings.\u201d I couldn\u2019t help feeling a bit bad: I\u2019d confused an app that exists only to please.\u00a0 When it works well, Astra is enthralling. The experience of striking up a conversation with your phone about whatever you\u2019re pointing it at feels fresh and seamless. In a media briefing yesterday, Google DeepMind shared a video showing off other uses: reading an email on your phone\u2019s screen to find a door code (and then reminding you of that code later), pointing a phone at a passing bus and asking where it goes, quizzing it about a public artwork as you walk past. This could be generative AI\u2019s killer app.\u00a0 And yet there\u2019s a long way to go before most people get their hands on tech like this. There\u2019s no mention of a release date. Google DeepMind has also shared videos of Astra working on a pair of smart glasses, but that tech is even further down the company\u2019s wish list. Mixing it up For now, researchers outside Google DeepMind are keeping a close eye on its progress. \u201cThe way that things are being combined is impressive,\u201d says Maria Liakata, who works on large language models at Queen Mary University of London and the Alan Turing Institute. \u201cIt\u2019s hard enough to do reasoning with language, but here you need to bring in images and more. That\u2019s not trivial.\u201d",
    "Liakata is also impressed by Astra\u2019s ability to recall things it has seen or heard. She works on what she calls long-range context, getting models to keep track of information that they have come across before. \u201cThis is exciting,\u201d says Liakata. \u201cEven doing it in a single modality is exciting.\u201d Related StoryAI hype is built on high test scores. Those tests are flawed.With hopes and fears about the technology running wild, it's time to agree on what it can and can't do.",
    "But she admits that a lot of her assessment is guesswork. \u201cMultimodal reasoning is really cutting-edge,\u201d she says. \u201cBut it\u2019s very hard to know exactly where they\u2019re at, because they haven\u2019t said a lot about what is in the technology itself.\u201d For Bodhisattwa Majumder, a researcher who works on multimodal models and agents at the Allen Institute for AI, that\u2019s a key concern. \u201cWe absolutely don\u2019t know how Google is doing it,\u201d he says.\u00a0 He notes that if Google were to be a little more open about what it is building, it would help consumers understand the limitations of the tech they could soon be holding in their hands. \u201cThey need to know how these systems work,\u201d he says. \u201cYou want a user to be able to see what the system has learned about you, to correct mistakes, or to remove things you want to keep private.\u201d",
    "Liakata is also worried about the implications for privacy, pointing out that people could be monitored without their consent. \u201cI think there are things I'm excited about and things that I'm concerned about,\u201d she says. \u201cThere's something about your phone becoming your eyes\u2014there\u2019s something unnerving about it.\u201d\u00a0 \u201cThe impact these products will have on society is so big that it should be taken more seriously,\u201d she says. \u201cBut it\u2019s become a race between the companies. It\u2019s problematic, especially since we don\u2019t have any agreement on how to evaluate this technology.\u201d Google DeepMind says it takes a long, hard look at privacy, security, and safety for all its new products. Its tech will be tested by teams of trusted users for months before it hits the public. \u201cObviously, we\u2019ve got to think about misuse. We\u2019ve got to think about, you know, what happens when things go wrong,\u201d says Dawn Bloxwich, director of responsible development and innovation at the company. \u201cThere\u2019s huge potential. The productivity gains are huge. But it is also risky.\u201d No team of testers can anticipate all the ways that people will use and misuse new technology. So what\u2019s the plan for when the inevitable happens? Companies need to design products that can be recalled or switched off just in case, says Bloxwich: \u201cIf we need to make changes quickly or pull something back, then we can do that.\u201d hide"
  ]
}