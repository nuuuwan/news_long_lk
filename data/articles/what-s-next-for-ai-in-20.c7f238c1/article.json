{
  "url": "https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/",
  "title": "What\u2019s next for AI in 2025",
  "ut": 1736292600.0,
  "body_paragraphs": [
    "MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them\u00a0here. For the last couple of years we\u2019ve had a go at predicting what\u2019s coming next in AI. A fool\u2019s game given how fast this industry moves. But we\u2019re on a roll, and we\u2019re doing it again.  How did we score last time round? Our four hot trends to watch out for in 2024 included what we called customized chatbots\u2014interactive helper apps powered by multimodal large language models (check: we didn\u2019t know it yet, but we were talking about what everyone now calls agents, the hottest thing in AI right now); generative video (check: few technologies have improved so fast in the last 12 months, with OpenAI and Google DeepMind releasing their flagship video generation models, Sora and Veo, within a week of each other this December); and more general-purpose robots that can do a wider range of tasks (check: the payoffs from large language models continue to trickle down to other parts of the tech industry, and robotics is top of the list).\u00a0 We also said that AI-generated election disinformation would be everywhere, but here\u2014happily\u2014we got it wrong. There were many things to wring our hands over this year, but political deepfakes were thin on the ground.",
    "So what\u2019s coming in 2025? We\u2019re going to ignore the obvious here: You can bet that agents and smaller, more efficient, language models will continue to shape the industry. Instead, here are five alternative picks from our AI team. 1. Generative virtual playgrounds\u00a0 If 2023 was the year of generative images and 2024 was the year of generative video\u2014what comes next? If you guessed generative virtual worlds (a.k.a. video games), high fives all round.",
    "We got a tiny glimpse of this technology in February, when Google DeepMind revealed a generative model called Genie that could take a still image and turn it into a side-scrolling 2D platform game that players could interact with. In December, the firm revealed Genie 2, a model that can spin a starter image into an entire virtual world. Other companies are building similar tech. In October, the AI startups Decart and Etched revealed an unofficial Minecraft hack in which every frame of the game gets generated on the fly as you play. And World Labs, a startup cofounded by Fei-Fei Li\u2014creator of ImageNet, the vast data set of photos that kick-started the deep-learning boom\u2014is building what it calls large world models, or LWMs. One obvious application is video games. There\u2019s a playful tone to these early experiments, and generative 3D simulations could be used to explore design concepts for new games, turning a sketch into a playable environment on the fly. This could lead to entirely new types of games.\u00a0 But they could also be used to train robots. World Labs wants to develop so-called spatial intelligence\u2014the ability for machines to interpret and interact with the everyday world. But robotics researchers lack good data about real-world scenarios with which to train such technology. Spinning up countless virtual worlds and dropping virtual robots into them to learn by trial and error could help make up for that.\u00a0\u00a0\u00a0  \u2014Will Douglas Heaven 2. Large language models that \u201creason\u201d   The buzz was justified. When OpenAI revealed o1 in September, it introduced a new paradigm in how large language models work. Two months later, the firm pushed that paradigm forward in almost every way with o3\u2014a model that just might reshape this technology for good.  Most models, including OpenAI\u2019s flagship GPT-4, spit out the first response they come up with. Sometimes it\u2019s correct; sometimes it\u2019s not. But the firm's new models are trained to work through their answers step by step, breaking down tricky problems into a series of simpler ones. When one approach isn\u2019t working, they try another. This technique, known as \u201creasoning\u201d (yes\u2014we know exactly how loaded that term is), can make this technology more accurate, especially for math, physics, and logic problems. Related StoryWhat are AI agents?\u00a0The next big thing is AI tools that can do more complex tasks. Here\u2019s how they will work.",
    "It\u2019s also crucial for agents. In December, Google DeepMind revealed an experimental new web-browsing agent called Mariner. In the middle of a preview demo that the company gave to MIT Technology Review, Mariner seemed to get stuck. Megha Goel, a product manager at the company, had asked the agent to find her a recipe for Christmas cookies that looked like the ones in a photo she\u2019d given it. Mariner found a recipe on the web and started adding the ingredients to Goel\u2019s online grocery basket.  Then it stalled; it couldn\u2019t figure out what type of flour to pick. Goel watched as Mariner explained its steps in a chat window: \u201cIt says, \u2018I will use the browser\u2019s Back button to return to the recipe.\u2019\u201d",
    "It was a remarkable moment. Instead of hitting a wall, the agent had broken the task down into separate actions and picked one that might resolve the problem. Figuring out you need to click the Back button may sound basic, but for a mindless bot it\u2019s akin to rocket science. And it worked: Mariner went back to the recipe, confirmed the type of flour, and carried on filling Goel\u2019s basket. Google DeepMind is also building an experimental version of Gemini 2.0, its latest large language model, that uses this step-by-step approach to problem solving, called Gemini 2.0 Flash Thinking.   But OpenAI and Google are just the tip of the iceberg. Many companies are building large language models that use similar techniques, making them better at a whole range of tasks, from cooking to coding. Expect a lot more buzz about reasoning (we know, we know) this year. \u2014Will Douglas Heaven  3. It\u2019s boom time for AI in science\u00a0   One of the most exciting uses for AI is speeding up discovery in the natural sciences. Perhaps the greatest vindication of AI\u2019s potential on this front came last October, when the Royal Swedish Academy of Sciences awarded the Nobel Prize for chemistry to Demis Hassabis and John M. Jumper from Google DeepMind for building the AlphaFold tool, which can solve protein folding, and to David Baker for building tools to help design new proteins. Expect this trend to continue next year, and to see more data sets and models that are aimed specifically at scientific discovery. Proteins were the perfect target for AI, because the field had excellent existing data sets that AI models could be trained on.\u00a0  The hunt is on to find the next big thing. One potential area is materials science. Meta has released massive data sets and models that could help scientists use AI to discover new materials much faster, and in December, Hugging Face, together with the startup Entalpic, launched LeMaterial, an open-source project that aims to simplify and accelerate materials research. Their first project is a data set that unifies, cleans, and standardizes the most prominent material data sets.\u00a0 AI model makers are also keen to pitch their generative products as research tools for scientists. OpenAI let scientists test its latest o1 model and see how it might support them in research. The results were encouraging.\u00a0  Having an AI tool that can operate in a similar way to a scientist is one of the fantasies of the tech sector. In a manifesto published in October last year, Anthropic founder Dario Amodei highlighted science, especially biology, as one of the key areas where powerful AI could help. Amodei speculates that in the future, AI could be not only a method of data analysis but a \u201cvirtual biologist who performs all the tasks biologists do.\u201d We\u2019re still a long way away from this scenario. But next year, we might see important steps toward it.\u00a0 \u2014Melissa Heikkil\u00e4  4. AI companies get cozier with national security   There is a lot of money to be made by AI companies willing to lend their tools to border surveillance, intelligence gathering, and other national security tasks.\u00a0 The US military has launched a number of initiatives that show it\u2019s eager to adopt AI, from the Replicator program\u2014which, inspired by the war in Ukraine, promises to spend $1 billion on small drones\u2014to the Artificial Intelligence Rapid Capabilities Cell, a unit bringing AI into everything from battlefield decision-making to logistics. European militaries are under pressure to up their tech investment, triggered by concerns that Donald Trump\u2019s administration will cut spending to Ukraine. Rising tensions between Taiwan and China weigh heavily on the minds of military planners, too.",
    "Related StoryWhat\u2019s next for our privacy?The US still has no federal privacy law. But recent enforcement actions against data brokers may offer some new protections for Americans\u2019 personal information.",
    "In 2025, these trends will continue to be a boon for defense-tech companies like Palantir, Anduril, and others, which are now capitalizing on classified military data to train AI models.\u00a0 The defense industry\u2019s deep pockets will tempt mainstream AI companies into the fold too. OpenAI in December announced it is partnering with Anduril on a program to take down drones, completing a year-long pivot away from its policy of not working with the military. It joins the ranks of Microsoft, Amazon, and Google, which have worked with the Pentagon for years.",
    "Other AI competitors, which are spending billions to train and develop new models, will face more pressure in 2025 to think seriously about revenue. It\u2019s possible that they\u2019ll find enough non-defense customers who will pay handsomely for AI agents that can handle complex tasks, or creative industries willing to spend on image and video generators.\u00a0  But they\u2019ll also be increasingly tempted to throw their hats in the ring for lucrative Pentagon contracts. Expect to see companies wrestle with whether working on defense projects will be seen as a contradiction to their values. OpenAI\u2019s rationale for changing its stance was that \u201cdemocracies should continue to take the lead in AI development,\u201d the company wrote, reasoning that lending its models to the military would advance that goal. In 2025, we\u2019ll be watching others follow its lead.\u00a0 \u2014James O\u2019Donnell  5. Nvidia sees legitimate competition   For much of the current AI boom, if you were a tech startup looking to try your hand at making an AI model, Jensen Huang was your man. As CEO of Nvidia, the world\u2019s most valuable corporation, Huang helped the company become the undisputed leader of chips used both to train AI models and to ping a model when anyone uses it, called \u201cinferencing.\u201d A number of forces could change that in 2025. For one, behemoth competitors like Amazon, Broadcom, AMD, and others have been investing heavily in new chips, and there are early indications that these could compete closely with Nvidia\u2019s\u2014particularly for inference, where Nvidia\u2019s lead is less solid.\u00a0 A growing number of startups are also attacking Nvidia from a different angle. Rather than trying to marginally improve on Nvidia\u2019s designs, startups like Groq are making riskier bets on entirely new chip architectures that, with enough time, promise to provide more efficient or effective training. In 2025 these experiments will still be in their early stages, but it\u2019s possible that a standout competitor will change the assumption that top AI models rely exclusively on Nvidia chips. Underpinning this competition, the geopolitical chip war will continue. That war thus far has relied on two strategies. On one hand, the West seeks to limit exports to China of top chips and the technologies to make them. On the other, efforts like the US CHIPS Act aim to boost domestic production of semiconductors. Donald Trump may escalate those export controls and has promised massive tariffs on any goods imported from China. In 2025, such tariffs would put Taiwan\u2014on which the US relies heavily because of the chip manufacturer TSMC\u2014at the center of the trade wars. That\u2019s because Taiwan has said it will help Chinese firms relocate to the island to help them avoid the proposed tariffs. That could draw further criticism from Trump, who has expressed frustration with US spending to defend Taiwan from China.\u00a0 It\u2019s unclear how these forces will play out, but it will only further incentivize chipmakers to reduce reliance on Taiwan, which is the entire purpose of the CHIPS Act. As spending from the bill begins to circulate, next year could bring the first evidence of whether it\u2019s materially boosting domestic chip production.\u00a0 \u2014James O\u2019Donnell hide"
  ]
}