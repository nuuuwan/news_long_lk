{
  "url": "https://www.technologyreview.com/2025/08/05/1121092/openai-has-finally-released-open-weight-language-models/",
  "title": "OpenAI has finally released open-weight language models",
  "ut": 1754379000.0,
  "body_paragraphs": [
    "OpenAI has finally released its first open-weight large language models since 2019\u2019s GPT-2. These new \u201cgpt-oss\u201d models are available in two different sizes and score similarly to the company\u2019s o3-mini and o4-mini models on several benchmarks. Unlike the models available through OpenAI\u2019s web interface, these new open models can be freely downloaded, run, and even modified on laptops and other local devices. In the company\u2019s many years without an open LLM release, some users have taken to referring to it with the pejorative \u201cClosedAI.\u201d That sense of frustration had escalated in the past few months as these long-awaited models were delayed twice\u2014first in June and then in July. With their release, however, OpenAI is reestablishing itself as a presence for users of open models.  That\u2019s particularly notable at a time when Meta, which had previously dominated the American open-model landscape with its Llama models, may be reorienting toward closed releases\u2014and when Chinese open models, such as DeepSeek\u2019s offerings, Kimi K2, and Alibaba\u2019s Qwen series, are becoming more popular than their American competitors. Related StoryHow to run an LLM on your laptopIt\u2019s now possible to run useful models from the safety and comfort of your own computer. Here\u2019s how.",
    "\u201cThe vast majority of our [enterprise and startup] customers are already using a lot of open models,\u201d said Casey Dvorak, a research program manager at OpenAI, in a media briefing about the model release. \u201cBecause there is no [competitive] open model from OpenAI, we wanted to plug that gap and actually allow them to use our technology across the board.\u201d",
    "The new models come in two different sizes, the smaller of which can theoretically run on 16 GB of RAM\u2014the minimum amount that Apple currently offers on its computers. The larger model requires a high-end laptop or specialized hardware. Open models have a few key use cases. Some organizations may want to customize models for their own purposes or save money by running models on their own equipment, though that equipment comes at a substantial upfront cost. Others\u2014such hospitals, law firms, and governments\u2014might need models that they can run locally for data security reasons.",
    "OpenAI has facilitated such activity by releasing its open models under a permissive Apache 2.0 license, which allows the models to be used for commercial purposes. Nathan Lambert, post-training lead at the Allen Institute for AI, says that this choice is commendable: Such licenses are typical for Chinese open-model releases, but Meta released its Llama models under a bespoke, more restrictive license. \u201cIt\u2019s a very good thing for the open community,\u201d he says. Researchers who study how LLMs work also need open models, so that they can examine and manipulate those models in detail. \u201cIn part, this is about reasserting OpenAI\u2019s dominance in the research ecosystem,\u201d says Peter Henderson, an assistant professor at Princeton University who has worked extensively with open models. If researchers do adopt gpt-oss as new workhorses, OpenAI could see some concrete benefits, Henderson says\u2014it might adopt innovations discovered by other researchers into its own model ecosystem. More broadly, Lambert says, releasing an open model now could help OpenAI reestablish its status in an increasingly crowded AI environment. \u201cIt kind of goes back to years ago, where they were seen as the AI company,\u201d he says. Users who want to use open models will now have the option to meet all their needs with OpenAI products, rather than turning to Meta\u2019s Llama or Alibaba\u2019s Qwen when they need to run something locally. The rise of Chinese open models like Qwen over the past year may have been a particularly salient factor in OpenAI\u2019s calculus. An employee from OpenAI emphasized at the media briefing that the company doesn\u2019t see these open models as a response to actions taken by any other AI company, but OpenAI is clearly attuned to the geopolitical implications of China\u2019s open-model dominance. \u201cBroad access to these capable\u202c\u202d open-weights models created in the US helps expand democratic AI rails,\u201d the company wrote in a blog post announcing the models\u2019 release.\u00a0 Since DeepSeek exploded onto the AI scene at the start of 2025, observers have noted that Chinese models often refuse to speak about topics that the Chinese Communist Party has deemed verboten, such as Tiananmen Square. Such observations\u2014as well as longer-term risks, like the possibility that agentic models could purposefully write vulnerable code\u2014have made some AI experts concerned about the growing adoption of Chinese models. \u201cOpen models are a form of soft power,\u201d Henderson says. Lambert released a report on Monday documenting how Chinese models are overtaking American offerings like Llama and advocating for a renewed commitment to domestic open models. Several prominent AI researchers and entrepreneurs, such as HuggingFace CEO Clement Delangue, Stanford\u2019s Percy Liang, and former OpenAI researcher Miles Brundage, have signed on. The Trump administration, too, has emphasized development of open models in its AI Action Plan. With both this model release and previous statements, OpenAI is aligning itself with that stance. \u201cIn their filings about the action plan, [OpenAI] pretty clearly indicated that they see US\u2013China as a key issue and want to position themselves as very important to the US system,\u201d says Rishi Bommasani, a senior research scholar at the Stanford Institute for Human-Centered Artificial Intelligence.\u00a0 And OpenAI may see concrete political advantages from aligning with the administration\u2019s AI priorities, Lambert says. As the company continues to build out its extensive computational infrastructure, it will need political support and approvals, and sympathetic leadership could go a long way.  hide"
  ]
}