{
  "url": "https://www.technologyreview.com/2025/12/15/1129174/the-great-ai-hype-correction-of-2025/",
  "title": "The great AI hype correction of 2025",
  "ut": 1765755000.0,
  "body_paragraphs": [
    "Some disillusionment was inevitable. When OpenAI released a free web app called ChatGPT in late 2022, it changed the course of an entire industry\u2014and several world economies. Millions of people started talking to their computers, and their computers started talking back. We were enchanted, and we expected more. We got it. Technology companies scrambled to stay ahead, putting out rival products that outdid one another with each new release: voice, images, video. With nonstop one-upmanship, AI companies have presented each new product drop as a major breakthrough, reinforcing a widespread faith that this technology would just keep getting better. Boosters told us that progress was exponential. They posted charts plotting how far we\u2019d come since last year\u2019s models: Look how the line goes up! Generative AI could do anything, it seemed.  Well, 2025 has been a year of reckoning.\u00a0  This story is part of MIT Technology Review\u2019s Hype Correction package, a series that resets expectations about what AI is, what it makes possible, and where we go next. Advertisement  For a start, the heads of the top AI companies made promises they couldn\u2019t keep. They told us that generative AI would replace the white-collar workforce, bring about an age of abundance, make scientific discoveries, and help find new cures for disease. FOMO across the world\u2019s economies, at least in the Global North, made CEOs tear up their playbooks and try to get in on the action. That\u2019s when the shine started to come off. Though the technology may have been billed as a universal multitool that could revamp outdated business processes and cut costs, a number of studies published this year suggest that firms are failing to make the AI pixie dust work its magic. Surveys and trackers from a range of sources, including the US Census Bureau and Stanford University, have found that business uptake of AI tools is stalling. And when the tools do get tried out, many projects stay stuck in the pilot stage. Without broad buy-in across the economy it is not clear how the big AI companies will ever recoup the incredible amounts they've already spent in this race.",
    "At the same time, updates to the core technology are no longer the step changes they once were. Related StoryWhat is AI?Read next The highest-profile example of this was the botched launch of GPT-5 in August. Here was OpenAI, the firm that had ignited (and to a large extent sustained) the current boom, set to release a brand-new generation of its technology. OpenAI had been hyping GPT-5 for months: \u201cPhD-level expert in anything,\u201d CEO Sam Altman crowed. On another occasion Altman posted, without comment, an image of the Death Star from Star Wars, which OpenAI stans took to be a symbol of ultimate power: Coming soon! Expectations were huge.",
    "And yet, when it landed, GPT-5 seemed to be\u2014more of the same? What followed was the biggest vibe shift since ChatGPT first appeared three years ago. \u201cThe era of boundary-breaking advancements is over,\u201d Yannic Kilcher, an AI researcher and popular YouTuber, announced in a video posted two days after GPT-5 came out: \u201cAGI is not coming. It seems very much that we\u2019re in the Samsung Galaxy era of LLMs.\u201d A lot of people (me included) have made the analogy with phones. For a decade or so, smartphones were the most exciting consumer tech in the world. Today, new products drop from Apple or Samsung with little fanfare. While superfans pore over small upgrades, to most people this year\u2019s iPhone now looks and feels a lot like last year\u2019s iPhone. Is that where we are with generative AI? And is it a problem? Sure, smartphones have become the new normal. But they changed the way the world works, too.  To be clear, the last few years have been filled with genuine \u201cWow\u201d moments, from the stunning leaps in the quality of video generation models to the problem-solving chops of so-called reasoning models to the world-class competition wins of the latest coding and math models. But this remarkable technology is only a few years old, and in many ways it is still experimental. Its successes come with big caveats. Perhaps we need to readjust our expectations. The big reset Let\u2019s be careful here: The pendulum from hype to anti-hype can swing too far. It would be rash to dismiss this technology just because it has been oversold. The knee-jerk response when AI fails to live up to its hype is to say that progress has hit a wall. But that misunderstands how research and innovation in tech work. Progress has always moved in fits and starts. There are ways over, around, and under walls. Take a step back from the GPT-5 launch. It came hot on the heels of a series of remarkable models that OpenAI had shipped in the previous months, including o1 and o3 (first-of-their-kind reasoning models that introduced the industry to a whole new paradigm) and Sora 2, which raised the bar for video generation once again. That doesn\u2019t sound like hitting a wall to me.",
    "Advertisement AI is really good! Look at Nano Banana Pro, the new image generation model from Google DeepMind that can turn a book chapter into an infographic, and much more. It\u2019s just there\u2014for free\u2014on your phone. And yet you can\u2019t help but wonder: When the wow factor is gone, what\u2019s left? How will we view this technology a year or five from now? Will we think it was worth the colossal costs, both financial and environmental?\u00a0 With that in mind, here are four ways to think about the state of AI at the end of 2025: The start of a much-needed hype correction. 01: LLMs are not everything In some ways, it is the hype around large language models, not AI as a whole, that needs correcting. It has become obvious that LLMs are not the doorway to artificial general intelligence, or AGI, a hypothetical technology that some insist will one day be able to do any (cognitive) task a human can.",
    "Even an AGI evangelist like Ilya Sutskever, chief scientist and cofounder at the AI startup Safe Superintelligence and former chief scientist and cofounder at OpenAI, now highlights the limitations of LLMs, a technology he had a huge hand in creating. LLMs are very good at learning how to do a lot of specific tasks, but they do not seem to learn the principles behind those tasks, Sutskever said in an interview with Dwarkesh Patel in November. It\u2019s the difference between learning how to solve a thousand different algebra problems and learning how to solve any algebra problem. \u201cThe thing which I think is the most fundamental is that these models somehow just generalize dramatically worse than people,\u201d Sutskever said. Related StoryHow AGI became the most consequential conspiracy theory of our timeRead next It\u2019s easy to imagine that LLMs can do anything because their use of language is so compelling. It is astonishing how well this technology can mimic the way people write and speak. And we are hardwired to see intelligence in things that behave in certain ways\u2014whether it\u2019s there or not. In other words, we have built machines with humanlike behavior and cannot resist seeing a humanlike mind behind them. That\u2019s understandable. LLMs have been part of mainstream life for only a few years. But in that time, marketers have preyed on our shaky sense of what the technology can really do, pumping up expectations and turbocharging the hype. As we live with this technology and come to understand it better, those expectations should fall back down to earth.",
    "02:  AI is not a quick fix to all your problems In July, researchers at MIT published a study that became a tentpole talking point in the disillusionment camp. The headline result was that a whopping 95% of businesses that had tried using AI had found zero value in it.\u00a0\u00a0 The general thrust of that claim was echoed by other research, too. In November,\u00a0a study by researchers at Upwork, a company that runs an online marketplace for freelancers, found that agents powered by top LLMs from OpenAI, Google DeepMind, and Anthropic failed to complete many straightforward workplace tasks by themselves. Advertisement This is miles off Altman\u2019s prediction: \u201cWe believe that, in 2025, we may see the first AI agents \u2018join the workforce\u2019 and materially change the output of companies,\u201d he wrote on his personal blog in January. But what gets missed in that MIT study is that the researchers\u2019 measure of success was pretty narrow. That 95% failure rate accounts for companies that had tried to implement bespoke AI systems but had not yet scaled them beyond the pilot stage after six months. It shouldn\u2019t be too surprising that a lot of experiments with experimental technology don\u2019t pan out straight away.  That number also does not include the use of LLMs by employees outside of official pilots. The MIT researchers found that around 90% of the companies they surveyed had a kind of AI shadow economy where workers were using personal chatbot accounts. But the value of that shadow economy was not measured.\u00a0\u00a0 When the Upwork study looked at how well agents completed tasks together with people who knew what they were doing, success rates shot up. The takeaway seems to be that a lot of people are figuring out for themselves how AI might help them with their jobs.",
    "That fits with something the AI researcher and influencer (and coiner of the term \u201cvibe coding\u201d) Andrej Karpathy has noted: Chatbots are better than the average human at a lot of different things (think of giving legal advice, fixing bugs, doing high school math), but they are not better than an expert human. Karpathy suggests this may be why chatbots have proved popular with individual consumers, helping non-experts with everyday questions and tasks, but they have not upended the economy, which would require outperforming skilled employees at their jobs. That may change. For now, don\u2019t be surprised that AI has not (yet) had the impact on jobs that boosters said it would. AI is not a quick fix, and it cannot replace humans. But there\u2019s a lot to play for. The ways in which AI could be integrated into everyday workflows and business pipelines are still being tried out.",
    "03: Are we in a bubble? (If so, what kind of bubble?) If AI is a bubble, is it like the subprime mortgage bubble of 2008 or the internet bubble of 2000? Because there\u2019s a big difference. The subprime bubble wiped out a big part of the economy, because when it burst it left nothing behind except debt and overvalued real estate. The dot-com bubble wiped out a lot of companies, which sent ripples across the world, but it left behind the infant internet\u2014an international network of cables and a handful of startups, like Google and Amazon, that became the tech giants of today.\u00a0\u00a0 Then again, maybe we\u2019re in a bubble unlike either of those. After all, there\u2019s no real business model for LLMs right now. We don\u2019t yet know what the killer app will be, or if there will even be one.\u00a0 And many economists are concerned about the unprecedented amounts of money being sunk into the infrastructure required to build capacity and serve the projected demand. But what if that demand doesn\u2019t materialize? Add to that the weird circularity of many of those deals\u2014with Nvidia paying OpenAI to pay Nvidia, and so on\u2014and it\u2019s no surprise everybody\u2019s got a different take on what\u2019s coming.\u00a0 Advertisement Some investors remain sanguine. In an interview with the Technology Business Programming Network podcast in November, Glenn Hutchins, cofounder of Silver Lake Partners, a major international private equity firm, gave a few reasons not to worry. \u201cEvery one of these data centers\u2014almost all of them\u2014has a solvent counterparty that is contracted to take all the output they\u2019re built to suit,\u201d he said. In other words, it\u2019s not a case of \u201cBuild it and they\u2019ll come\u201d\u2014the customers are already locked in.\u00a0 And, he pointed out, one of the biggest of those solvent counterparties is Microsoft. \u201cMicrosoft has the world\u2019s best credit rating,\u201d Hutchins said. \u201cIf you sign a deal with Microsoft to take the output from your data center, Satya is good for it.\u201d Many CEOs will be looking back at the dot-com bubble and trying to learn its lessons. Here\u2019s one way to see it: The companies that went bust back then didn\u2019t have the money to last the distance. Those that survived the crash thrived. Related StoryThese six questions will dictate the future of generative AIRead next With that lesson in mind, AI companies today are trying to pay their way through what may or may not be a bubble. Stay in the race; don\u2019t get left behind. Even so, it\u2019s a desperate gamble.",
    "But there\u2019s another lesson too. Companies that might look like sideshows can turn into unicorns fast. Take Synthesia, which makes avatar generation tools for businesses. Nathan Benaich, cofounder of the VC firm Air Street Capital, admits that when he first heard about the company a few years ago, back when fear of deepfakes was rife, he wasn\u2019t sure what its tech was for and thought there was no market for it. \u201cWe didn\u2019t know who would pay for lip-synching and voice cloning,\u201d he says. \u201cTurns out there\u2019s a lot of people who wanted to pay for it.\u201d Synthesia now has around 55,000 corporate customers and brings in around $150 million a year. In October, the company was valued at $4 billion. 04: ChatGPT was not the beginning, and it won\u2019t be the end ChatGPT was the culmination of a decade\u2019s worth of progress in deep learning, the technology that underpins all of modern AI. The seeds of deep learning itself were planted in the 1980s. The field as a whole goes back at least to the 1950s. If progress is measured against that backdrop, generative AI has barely got going. Meanwhile, research is at a fever pitch. There are more high-quality submissions to the world\u2019s major AI conferences than ever before. This year, organizers of some of those conferences resorted to turning down papers that reviewers had already approved, just to manage numbers. (At the same time, preprint servers like arXiv have been flooded with AI-generated research slop.)  \u201cIt\u2019s back to the age of research again,\u201d Sutskever said in that Dwarkesh interview, talking about the current bottleneck with LLMs. That\u2019s not a setback; that\u2019s the start of something new. \u201cThere\u2019s always a lot of hype beasts,\u201d says Benaich. But he thinks there\u2019s an upside to that: Hype attracts the money and talent needed to make real progress. \u201cYou know, it was only like two or three years ago that the people who built these models were basically research nerds that just happened on something that kind of worked,\u201d he says. \u201cNow everybody who\u2019s good at anything in technology is working on this.\u201d AdvertisementWhere do we go from here? The relentless hype hasn\u2019t come just from companies drumming up business for their vastly expensive new technologies. There\u2019s a large cohort of people\u2014inside and outside the industry\u2014who want to believe in the promise of machines that can read, write, and think. It\u2019s a wild decades-old dream.\u00a0 But the hype was never sustainable\u2014and that\u2019s a good thing. We now have a chance to reset expectations and see this technology for what it really is\u2014assess its true capabilities, understand its flaws, and take the time to learn how to apply it in valuable (and beneficial) ways. \u201cWe\u2019re still trying to figure out how to invoke certain behaviors from this insanely high-dimensional black box of information and skills,\u201d says Benaich. This hype correction was long overdue. But know that AI isn\u2019t going anywhere. We don\u2019t even fully understand what we\u2019ve built so far, let alone what\u2019s coming next."
  ]
}