{
  "url": "https://www.technologyreview.com/2024/11/15/1106935/how-this-grassroots-effort-could-make-ai-voices-more-diverse/",
  "title": "How this grassroots effort could make AI voices more diverse",
  "ut": 1731628485.0,
  "body_paragraphs": [
    "We are on the cusp of a voice AI boom, with tech companies such as Apple and OpenAI rolling out the next generation of artificial-intelligence-powered assistants. But the default voices for these assistants are often white American\u2014British, if you\u2019re lucky\u2014and most definitely speak English. They represent only a tiny proportion of the many dialects and accents in the English language, which spans many regions and cultures. And if you\u2019re one of the billions of people who don\u2019t speak English, bad luck: These tools don\u2019t sound nearly as good in other languages. This is because the data that has gone into training these models is limited. In AI research, most data used to train models is extracted from the English-language internet, which reflects Anglo-American culture. But there is a massive grassroots effort underway to change this status quo and bring more transparency and diversity to what AI sounds like: Mozilla\u2019s Common Voice initiative.\u00a0  The data set Common Voice has created over the past seven years is one of the most useful resources for people wanting to build voice AI. It has seen a massive spike in downloads, partly thanks to the current AI boom; it recently hit the 5 million mark, up from 38,500 in 2020. Creating this data set has not been easy, mainly because the data collection relies on an army of volunteers. Their numbers have also jumped, from just under 500,000 in 2020 to over 900,000 in 2024. But by giving its data away, some members of this community argue, Mozilla is encouraging volunteers to effectively do free labor for Big Tech.\u00a0 Since 2017, volunteers for the Common Voice project have collected a total of 31,000 hours of voice data in around 180 languages as diverse as Russian, Catalan, and Marathi. If you\u2019ve used a service that uses audio AI, it\u2019s likely been trained at least partly on Common Voice.",
    "Mozilla\u2019s cause is a noble one. As AI is integrated increasingly into our lives and the ways we communicate, it becomes more important that the tools we interact with sound like us. The technology could break down communication barriers and help convey information in a compelling way to, for example, people who can\u2019t read. But instead, an intense focus on English risks entrenching a new colonial world order and wiping out languages entirely. \u201cIt would be such an own goal if, rather than finally creating truly multimodal, multilingual, high-performance translation models and making a more multilingual world, we actually ended up forcing everybody to operate in, like, English or French,\u201d says EM Lewis-Jong, a director for Common Voice.",
    "Common Voice is open source, which means anyone can see what has gone into the data set, and users can do whatever they want with it for free. This kind of transparency is unusual in AI data governance. Most large audio data sets simply aren\u2019t publicly available, and many consist of data that has been scraped from sites like YouTube, according to research conducted by a team from the University of Washington, and Carnegie Mellon andNorthwestern universities.\u00a0 Related StoryArtificial intelligence is creating a new colonial world orderAn MIT Technology Review series investigates how AI is enriching a powerful few by dispossessing communities that have been dispossessed before.",
    "The vast majority of language data is collected by volunteers such as B\u00fclent \u00d6zden, a researcher from Turkey. Since 2020, he has been not only donating his voice but also raising awareness around the project to get more people to donate. He recently spent two full-time months correcting data and checking for typos in Turkish. For him, improving AI models is not the only motivation to do this work.\u00a0 \u201cI\u2019m doing it to preserve cultures, especially low-resource [languages],\u201d \u00d6zden says. He tells me he has recently started collecting samples of Turkey\u2019s smaller languages, such as Circassian and Zaza. However, as I dug into the data set, I noticed that the coverage of languages and accents is very uneven. There are only 22 hours of Finnish voices from 231 people. In comparison, the data set contains 3,554 hours of English from 94,665 speakers. Some languages, such as Korean and Punjabi, are even less well represented. Even though they have tens of millions of speakers, they account for only a couple of hours of recorded data.\u00a0  This imbalance has emerged because data collection efforts are started from the bottom up by language communities themselves, says Lewis-Jong.\u00a0 \u201cWe\u2019re trying to give communities what they need to create their own AI training data sets. We have a particular focus on doing this for language communities where there isn\u2019t any data, or where maybe larger tech organizations might not be that interested in creating those data sets,\u201d Lewis-Jong says. They hope that with the help of volunteers and various bits of grant funding, the Common Voice data set will have close to 200 languages by the end of the year. Common Voice\u2019s permissive license means that many companies rely on it\u2014for example, the Swedish startup Mabel AI, which builds translation tools for health-care providers. One of the first languages the company used was Ukrainian; it built a translation tool to help Ukrainian refugees interact with Swedish social services, says Karolina Sj\u00f6berg, Mabel AI\u2019s founder and CEO. The team has since expanded to other languages, such as Arabic and Russian.\u00a0 The problem with a lot of other audio data is that it consists of people reading from books or texts. The result is very different from how people really speak, especially when they are distressed or in pain, Sj\u00f6berg says. Because anyone can submit sentences to Common Voice for others to read aloud, Mozilla\u2019s data set also includes sentences that are more colloquial and feel more natural, she says.",
    "Not that it is perfectly representative. The Mabel AI team soon found out that most voice data in the languages it needed was donated by younger men, which is fairly typical for the data set.\u00a0 \u201cThe refugees that we intended to use the app with were really anything but younger men,\u201d Sj\u00f6berg says. \u201cSo that meant that the voice data that we needed did not quite match the voice data that we had.\u201d The team started collecting its own voice data from Ukrainian women, as well as from elderly people.\u00a0 Unlike other data sets, Common Voice asks participants to share their gender and details about their accent. Making sure different genders are represented is important to fight bias in AI models, says Rebecca Ryakitimbo, a Common Voice fellow who created the project's gender action plan. More diversity leads not only to better representation but also to better models. Systems that are trained on narrow and homogenous data tend to spew stereotyped and harmful results. \u201cWe don\u2019t want a case where we have a chatbot that is named after a woman but does not give the same response to a woman as it would a man,\u201d she says.\u00a0 Related StoryWhat Africa needs to do to become a major AI playerInadequate funding, infrastructure issues, and fights over regulation mean the sector's future remains uncertain.",
    "Ryakitimbo has collected voice data in Kiswahili in Tanzania, Kenya, and the Democratic Republic of Congo. She tells me she wanted to collect voices from a socioeconomically diverse set of Kiswahili speakers and has reached out to women young and old living in rural areas, who might not always be literate or even have access to devices.\u00a0 This kind of data collection is challenging. The importance of collecting AI voice data can feel abstract to many people, especially if they aren\u2019t familiar with the technologies. Ryakitimbo and volunteers would approach women in settings where they felt safe to begin with, such as presentations on menstrual hygiene, and explain how the technology could, for example, help disseminate information about menstruation. For women who did not know how to read, the team read out sentences that they would repeat for the recording.\u00a0 The Common Voice project is bolstered by the belief that languages form a really important part of identity. \u201cWe think it\u2019s not just about language, but about transmitting culture and heritage and treasuring people\u2019s particular cultural context,\u201d says Lewis-Jong. \u201cThere are all kinds of idioms and cultural catchphrases that just don\u2019t translate,\u201d they add.\u00a0 Common Voice is the only audio data set where English doesn\u2019t dominate, says Willie Agnew, a researcher at Carnegie Mellon University who has studied audio data sets. \u201cI\u2019m very impressed with how well they've done that and how well they've made this data set that is actually pretty diverse,\u201d Agnew says. \u201cIt feels like they\u2019re way far ahead of almost all the other projects we looked at.\u201d",
    "I spent some time verifying the recordings of other Finnish speakers on the Common Voice platform. As their voices echoed in my study, I felt surprisingly touched. We had all gathered around the same cause: making AI data more inclusive, and making sure our culture and language was properly represented in the next generation of AI tools.\u00a0 But I had some big questions about what would happen to my voice if I donated it. Once it was in the data set, I would have no control about how it might be used afterwards. The tech sector isn\u2019t exactly known for giving people proper credit, and the data is available for anyone\u2019s use.",
    "\u201cAs much as we want it to benefit the local communities, there\u2019s a possibility that also Big Tech could make use of the same data and build something that then comes out as the commercial product,\u201d says Ryakitimbo. Though Mozilla does not share who has downloaded Common Voice, Lewis-Jong tells me Meta and Nvidia have said that they have used it. Open access to this hard-won and rare language data is not something all minority groups want, says Harry H. Jiang, a researcher at Carnegie Mellon University, who was part of the team doing audit research. For example, Indigenous groups have raised concerns.\u00a0 \u201cExtractivism\u201d is something that Mozilla has been thinking about a lot over the past 18 months, says Lewis-Jong. Later this year the project will work with communities to pilot alternative licenses including Nwulite Obodo Open Data License, which was created by researchers at the University of Pretoria for sharing African data sets more equitably. For example, people who want to download the data might be asked to write a request with details on how they plan to use it, and they might be allowed to license it only for certain products or for a limited time. Users might also be asked to contribute to community projects that support poverty reduction, says Lewis-Jong.\u00a0\u00a0 Lewis-Jong says the pilot is a learning exercise to explore whether people will want data with alternative licenses, and whether they are sustainable for communities managing them. The hope is that it could lead to something resembling \u201copen source 2.0.\u201d In the end, I decided to donate my voice. I received a list of phrases to say, sat in front of my computer, and hit Record. One day, I hope, my effort will help a company or researcher build voice AI that sounds less generic, and more like me.\u00a0 This story has been updated. hide"
  ]
}