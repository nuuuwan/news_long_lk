{
  "url": "https://www.technologyreview.com/2025/09/23/1123897/ai-models-are-using-material-from-retracted-scientific-papers/",
  "title": "AI models are using material from retracted scientific papers",
  "ut": 1758583800.0,
  "body_paragraphs": [
    "Some AI chatbots rely on flawed research from retracted scientific papers to answer questions, according to recent studies. The findings, confirmed by MIT Technology Review, raise questions about how reliable AI tools are at evaluating scientific research and could complicate efforts by countries and industries seeking to invest in AI tools for scientists. AI search tools and chatbots are already known to fabricate links and references. But answers based on the material from actual papers can mislead as well if those papers have been retracted.\u00a0The chatbot is \u201cusing a real paper, real material, to tell you something,\u201d says Weikuan Gu, a medical researcher at the University of Tennessee in Memphis and an author of one of the recent studies. But, he says, if people only look at the content of the answer and do not click through to the paper and see that it\u2019s been retracted, that\u2019s really a problem.\u00a0  Gu and his team asked OpenAI\u2019s ChatGPT, running on the GPT-4o model, questions based on information from 21 retracted papers about medical imaging. The chatbot\u2019s answers referenced retracted papers in five cases but advised caution in only three. While it cited non-retracted papers for other questions, the authors note that it may not have recognized the retraction status of the articles. In a study from August, a different group of researchers used ChatGPT-4o mini to evaluate the quality of 217 retracted and low-quality papers from different scientific fields; they found that none of the chatbot\u2019s responses mentioned retractions or other concerns. (No similar studies have been released on GPT-5, which came out in August.) The public uses AI chatbots to ask for medical advice and diagnose health conditions. Students and scientists increasingly use science-focused AI tools to review existing scientific literature and summarize papers. That kind of usage is likely to increase. The US National Science Foundation, for instance, invested $75 million in building AI models for science research this August.",
    "Related StoryThe looming crackdown on AI companionshipThe risks posed when kids form bonds with chatbots have turned AI safety from an abstract worry into a political flashpoint. What happens now?",
    "\u201cIf [a tool is] facing the general public, then using retraction as a kind of quality indicator is very important,\u201d says Yuanxi Fu, an information science researcher at the University of Illinois Urbana-Champaign. There\u2019s \u201ckind of an agreement that retracted papers have been struck off the record of science,\u201d she says, \u201cand the people who are outside of science\u2014they should be warned that these are retracted papers.\u201d OpenAI did not provide a response to a request for comment about the paper results. The problem is not limited to ChatGPT. In June, MIT Technology Review tested AI tools specifically advertised for research work, such as Elicit, Ai2 ScholarQA (now part of the Allen Institute for Artificial Intelligence\u2019s Asta tool), Perplexity, and Consensus, using questions based on the 21 retracted papers in Gu\u2019s study. Elicit referenced five of the retracted papers in its answers, while Ai2 ScholarQA referenced 17, Perplexity 11, and Consensus 18\u2014all without noting the retractions.",
    "Some companies have since made moves to correct the issue. \u201cUntil recently, we didn\u2019t have great retraction data in our search engine,\u201d says Christian Salem, cofounder of Consensus. His company has now started using retraction data from a combination of sources, including publishers and data aggregators, independent web crawling, and Retraction Watch, which manually curates and maintains a database of retractions. In a test of the same papers in August, Consensus cited only five retracted papers.\u00a0 Elicit told MIT Technology Review that it removes retracted papers flagged by the scholarly research catalogue OpenAlex from its database and is \u201cstill working on aggregating sources of retractions.\u201d Ai2 told us that its tool does not automatically detect or remove retracted papers currently. Perplexity said that it \u201c[does] not ever claim to be 100% accurate.\u201d\u00a0 However, relying on retraction databases may not be enough. Ivan Oransky, the cofounder of Retraction Watch, is careful not to describe it as a comprehensive database, saying that creating one would require more resources than anyone has: \u201cThe reason it\u2019s resource intensive is because someone has to do it all by hand if you want it to be accurate.\u201d Further complicating the matter is that publishers don\u2019t share a uniform approach to retraction notices. \u201cWhere things are retracted, they can be marked as such in very different ways,\u201d says Caitlin Bakker from University of Regina, Canada, an expert in research and discovery tools. \u201cCorrection,\u201d \u201cexpression of concern,\u201d \u201cerratum,\u201d and \u201cretracted\u201d are among some labels publishers may add to research papers\u2014and these labels can be added for many reasons, including concerns about the content, methodology, and data or the presence of conflicts of interest.\u00a0 Some researchers distribute their papers on preprint servers, paper repositories, and other websites, causing copies to be scattered around the web. Moreover, the data used to train AI models may not be up to date. If a paper is retracted after the model\u2019s training cutoff date, its responses might not instantaneously reflect what's going on, says Fu. Most academic search engines don\u2019t do a real-time check against retraction data, so you are at the mercy of how accurate their corpus is, says Aaron Tay, a librarian at Singapore Management University. Oransky and other experts advocate making more context available for models to use when creating a response. This could mean publishing information that already exists, like peer reviews commissioned by journals and critiques from the review site PubPeer, alongside the published paper.\u00a0\u00a0 Many publishers, such as Nature and the BMJ, publish retraction notices as separate articles linked to the paper, outside paywalls. Fu says companies need to effectively make use of such information, as well as any news articles in a model\u2019s training data that mention a paper\u2019s retraction.\u00a0 The users and creators of AI tools need to do their due diligence. \u201cWe are at the very, very early stages, and essentially you have to be skeptical,\u201d says Tay. Ananya is a freelance science and technology journalist based in Bengaluru, India. hide"
  ]
}