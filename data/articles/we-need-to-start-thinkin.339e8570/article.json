{
  "url": "https://www.technologyreview.com/2025/04/29/1115928/is-ai-normal/",
  "title": "We need to start thinking of AI as \u201cnormal\u201d",
  "ut": 1745883000.0,
  "body_paragraphs": [
    "Right now, despite its ubiquity, AI is seen as anything but a normal technology. There is talk of AI systems that will soon merit the term \u201csuperintelligence,\u201d and the former CEO of Google recently suggested we control AI models the way we control uranium and other nuclear weapons materials. Anthropic is dedicating time and money to study AI \u201cwelfare,\u201d including what rights AI models may be entitled to. Meanwhile, such models are moving into disciplines that feel distinctly human, from making music to providing therapy. No wonder that anyone pondering AI's future tends to fall into either a utopian or a dystopian camp. While OpenAI\u2019s Sam Altman muses that AI\u2019s impact will feel more like the Renaissance than the Industrial Revolution, over half of Americans are more concerned than excited about AI\u2019s future. (That half includes a few friends of mine, who at a party recently speculated whether AI-resistant communities might emerge\u2014modern-day Mennonites, carving out spaces where AI is limited by choice, not necessity.)\u00a0  So against this backdrop, a recent essay by two AI researchers at Princeton felt quite provocative. Arvind Narayanan, who directs the university\u2019s Center for Information Technology Policy, and doctoral candidate Sayash Kapoor wrote a 40-page plea for everyone to calm down and think of AI as a normal technology. This runs opposite to the \u201ccommon tendency to treat it akin to a separate species, a highly autonomous, potentially superintelligent entity.\u201d Related StoryThe AI Hype Index: AI agent cyberattacks, racing robots, and musical modelsMIT Technology Review\u2019s highly subjective take on the latest buzz about AI.",
    "Instead, according to the researchers, AI is a general-purpose technology whose application might be better compared to the drawn-out adoption of electricity or the internet than to nuclear weapons\u2014though they concede this is in some ways a flawed analogy.",
    "The core point, Kapoor says, is that we need to start differentiating between the rapid development of AI methods\u2014the flashy and impressive displays of what AI can do in the lab\u2014and what comes from the actual applications of AI, which in historical examples of other technologies lag behind by decades.\u00a0 \u201cMuch of the discussion of AI\u2019s societal impacts ignores this process of adoption,\u201d Kapoor told me, \u201cand expects societal impacts to occur at the speed of technological development.\u201d In other words, the adoption of useful artificial intelligence, in his view, will be less of a tsunami and more of a trickle.",
    "In the essay, the pair make some other bracing arguments: terms like \u201csuperintelligence\u201d are so incoherent and speculative that we shouldn\u2019t use them; AI won\u2019t automate everything but will birth a category of human labor that monitors, verifies, and supervises AI; and we should focus more on AI\u2019s likelihood to worsen current problems in society than the possibility of it creating new ones. \u201cAI supercharges capitalism,\u201d Narayanan says. It has the capacity to either help or hurt inequality, labor markets, the free press, and democratic backsliding, depending on how it's deployed, he says.\u00a0 There\u2019s one alarming deployment of AI that the authors leave out, though: the use of AI by militaries. That, of course, is picking up rapidly, raising alarms that life and death decisions are increasingly being aided by AI. The authors exclude that use from their essay because it\u2019s hard to analyze without access to classified information, but they say their research on the subject is forthcoming.\u00a0 One of the biggest implications of treating AI as \u201cnormal\u201d is that it would upend the position that both the Biden administration and now the Trump White House have taken: Building the best AI is a national security priority, and the federal government should take a range of actions\u2014limiting what chips can be exported to China, dedicating more energy to data centers\u2014to make that happen. In their paper, the two authors refer to US-China \u201cAI arms race\u201d rhetoric as \u201cshrill.\u201d \u201cThe arms race framing verges on absurd,\u201d Narayanan says. The knowledge it takes to build powerful AI models spreads quickly and is already being undertaken by researchers around the world, he says, and \u201cit is not feasible to keep secrets at that scale.\u201d\u00a0 So what policies do the authors propose? Rather than planning around sci-fi fears, Kapoor talks about \u201cstrengthening democratic institutions, increasing technical expertise in government, improving AI literacy, and incentivizing defenders to adopt AI.\u201d\u00a0 By contrast to policies aimed at controlling AI superintelligence or winning the arms race, these recommendations sound totally boring. And that\u2019s kind of the point. This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,\u00a0sign up here. hide"
  ]
}