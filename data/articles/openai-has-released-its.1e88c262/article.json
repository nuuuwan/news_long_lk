{
  "url": "https://www.technologyreview.com/2025/03/21/1113635/openai-has-released-its-first-research-into-how-using-chatgpt-affects-peoples-emotional-wellbeing/",
  "title": "OpenAI has released its first research into how using ChatGPT affects people\u2019s emotional wellbeing",
  "ut": 1742544865.0,
  "body_paragraphs": [
    "OpenAI says over 400 million people use ChatGPT every week. But how does interacting with it affect us? Does it make us more or less lonely? These are some of the questions OpenAI set out to investigate, in partnership with the MIT Media Lab, in a pair of new studies.\u00a0 They found that only a small subset of users engage emotionally with ChatGPT. This isn\u2019t surprising given that ChatGPT isn\u2019t marketed as an AI companion app like Replika or Character.AI, says Kate Devlin, a professor of AI and society at King\u2019s College London, who did not work on the project. \u201cChatGPT has been set up as a productivity tool,\u201d she says. \u201cBut we know that people are using it like a companion app anyway.\u201d In fact, the people who do use it that way are likely to interact with it for extended periods of time, some of them averaging about half an hour a day.\u00a0  \u201cThe authors are very clear about what the limitations of these studies are, but it\u2019s exciting to see they\u2019ve done this,\u201d Devlin says. \u201cTo have access to this level of data is incredible.\u201d\u00a0 Related StoryThe AI relationship revolution is already hereChatbots are rapidly changing how we connect to each other\u2014and ourselves. We\u2019re never going back.",
    "The researchers found some intriguing differences between how men and women respond to using ChatGPT. After using the chatbot for four weeks, female study participants were slightly less likely to socialize with people than their male counterparts who did the same. Meanwhile, participants who interacted with ChatGPT\u2019s voice mode in a gender that was not their own for their interactions reported significantly higher levels of loneliness and more emotional dependency on the chatbot at the end of the experiment. OpenAI plans to submit both studies to peer-reviewed journals.Chatbots powered by large language models are still a nascent technology, and it\u2019s difficult to study how they affect us emotionally. A lot of existing research in the area\u2014including some of the new work by OpenAI and MIT\u2014relies upon self-reported data, which may not always be accurate or reliable. That said, this latest research does chime with what scientists so far have discovered about how emotionally compelling chatbot conversations can be. For example, in 2023 MIT Media Lab researchers found that chatbots tend to mirror the emotional sentiment of a user\u2019s messages, suggesting a kind of feedback loop where the happier you act, the happier the AI seems, or on the flipside, if you act sadder, so does the AI.",
    "OpenAI and the MIT Media Lab used a two-pronged method. First they collected and analyzed real-world data from close to 40 million interactions with ChatGPT. Then they asked the 4,076 users who\u2019d had those interactions how they made them feel. Next, the Media Lab recruited almost 1,000 people to take part in a four-week trial. This was more in-depth, examining how participants interacted with ChatGPT for a minimum of five minutes each day. At the end of the experiment, participants completed a questionnaire to measure their perceptions of the chatbot, their subjective feelings of loneliness, their levels of social engagement, their emotional dependence on the bot, and their sense of whether their use of the bot was problematic. They found that participants who trusted and \u201cbonded\u201d with ChatGPT more were likelier than others to be lonely, and to rely on it more.\u00a0 This work is an important first step toward greater insight into ChatGPT\u2019s impact on us, which could help AI platforms enable safer and healthier interactions, says Jason Phang, an OpenAI safety researcher who worked on the project.",
    "\u201cA lot of what we\u2019re doing here is preliminary, but we\u2019re trying to start the conversation with the field about the kinds of things that we can start to measure, and to start thinking about what the long-term impact on users is,\u201d he says. Although the research is welcome, it\u2019s still difficult to identify when a human is\u2014and isn\u2019t\u2014engaging with technology on an emotional level, says Devlin. She says the study participants may have been experiencing emotions that weren\u2019t recorded by the researchers. \u201cIn terms of what the teams set out to measure, people might not necessarily have been using ChatGPT in an emotional way, but you can\u2019t divorce being a human from your interactions [with technology],\u201d she says. \u201cWe use these emotion classifiers that we have created to look for certain things\u2014but what that actually means to someone\u2019s life is really hard to extrapolate.\" Correction: An earlier version of this article misstated that study participants set the gender of ChatGPT's voice, and that OpenAI did not plan to publish either study. Study participants were assigned the voice mode gender, and OpenAI plans to submit both studies to peer-reviewed journals. The article has since been updated. hide"
  ]
}